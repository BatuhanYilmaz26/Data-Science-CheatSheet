{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = [\"preg\", \"plas\", \"pres\", \"skin\", \"test\", \"mass\", \"pedi\", \"age\", \"class\"]\n",
    "data = read_csv(url, names = names)\n",
    "\n",
    "veri = data.values\n",
    "X = veri[:, 0:8] #Girdi\n",
    "Y = veri[:, 8] #Çıktı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPLULUK ÖĞRENMESİ (ENSEMBLE) İLE PERFORMANS GELİŞTİRME\n",
    "# Birden çok yöntemin sonuçlarını birleştirir. Böylece veri setinde birden fazla model kullanılır ve bunların güçlü yönlerinden faydalanılır.(Knime'daki fusion predictor)\n",
    "# Sınıflandırma verilerinde kullanılır.\n",
    "#Knime'daki Fusion predictor düğümünün Python'daki karşılığı --> VotingClassifier fonksiyonu \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier(n_estimators = 250)\n",
    "model2 = RandomForestClassifier(n_estimators = 450)\n",
    "model3 = GradientBoostingClassifier()\n",
    "model4 = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test verisi için doğruluk:  0.7835497835497836\n",
      "Eğitim verisi için doğruluk:  0.9851024208566108\n"
     ]
    }
   ],
   "source": [
    "Oylama_modeli = VotingClassifier(estimators = [(\"rf1\", model1), (\"rf2\", model2), (\"gbc\", model3), (\"xgb\", model4)], voting = \"soft\")\n",
    "#Modelleri birleştirdik.\n",
    "Oylama_modeli.fit(x_train, y_train)\n",
    "y_pred = Oylama_modeli.predict(x_test)\n",
    "\n",
    "print(\"Test verisi için doğruluk: \", accuracy_score(y_pred, y_test))\n",
    "print(\"Eğitim verisi için doğruluk: \", Oylama_modeli.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test verisi için doğruluk:  0.7878787878787878\n",
      "Eğitim verisi için doğruluk:  0.9795158286778398\n"
     ]
    }
   ],
   "source": [
    "Oylama_modeli2 = VotingClassifier(estimators = [(\"rf1\", model1), (\"rf2\", model2), (\"gbc\", model3), (\"xgb\", model4)], weights = [1,3,2,4], voting = \"soft\")\n",
    "#Modelleri birleştirdik ve modellere farklı ağırlık değerleri atayarak önem derecelerini belirledik.\n",
    "\n",
    "Oylama_modeli2.fit(x_train, y_train)\n",
    "y_pred = Oylama_modeli2.predict(x_test)\n",
    "\n",
    "print(\"Test verisi için doğruluk: \", accuracy_score(y_pred, y_test))\n",
    "print(\"Eğitim verisi için doğruluk: \", Oylama_modeli2.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETRE OPTİMİZASYONU\n",
    "import pandas\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = [\"preg\", \"plas\", \"pres\", \"skin\", \"test\", \"mass\", \"pedi\", \"age\", \"class\"]\n",
    "data = read_csv(url, names = names)\n",
    "\n",
    "veri = data.values\n",
    "X = veri[:, 0:8] #Girdi\n",
    "Y = veri[:, 8] #Çıktı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler() #Veriyi normalize ettik.\n",
    "X_train_std = sc.fit_transform(x_train)\n",
    "X_test_std = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performansları;\n",
      "Doğruluk:  0.7705627705627706\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.5675675675675675\n",
      "F1 puanı: 0.6131386861313869\n",
      "\n",
      "\n",
      "Sınıflandırma Tablosu: \n",
      "[[136  21]\n",
      " [ 32  42]]\n"
     ]
    }
   ],
   "source": [
    "# 1. GRID SEARCH  Bir parametre uzayı belirlenir ve model o uzaydaki bütün olasılıkları deneyerek en iyi parametre değerlerini bulur.\n",
    "# (Knime'daki parametre optimizasyon düğümünün python'daki karşılığıdır.)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter = 3000, solver = \"lbfgs\").fit(X_train_std, y_train)\n",
    "y_pred = clf.predict(X_test_std)\n",
    "print(\"Test Performansları;\")\n",
    "print(\"Doğruluk: \", (accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"F1 puanı: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"\\n\")\n",
    "print(\"Sınıflandırma Tablosu: \\n\" + str(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "C:\\Users\\batuh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=3000, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.0001, 0.009, 0.01, 0.05, 0.09, 1, 5, 10, 25,\n",
       "                               100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regresyonda 2 temel gösterge kullanılabilir: Birincisi ceza fonksiyonu (L1 veya L2), bir diğeri ise düzenlileştirme parametresi->lambda( C parametresi)\n",
    "grid_değerleri = {\"C\": [0.0001, 0.009, 0.01, 0.05, 0.09, 1, 5, 10, 25, 100]}\n",
    "clf = LogisticRegression(max_iter = 3000, solver = \"lbfgs\")\n",
    "grid_model = GridSearchCV(clf, param_grid = grid_değerleri, cv = 10, scoring = \"recall\", verbose = 1) # cv = 10 herbir parametre değeri için 10 deneme yapar.(Grid değerlerindeki parametreler)\n",
    "#Parametre optimizasyonunu gerçekleştirecek fonksiyon --> GridSearch fonkisoynu,  CV = Cross validation(Çapraz doğrulama)\n",
    "grid_model.fit(X_train_std, y_train)\n",
    "# verbose ekrana bilgilendirme mesajı yazdırır.\n",
    "#10 değer için 10 deneme ile 100 öğrenme gerçekleştirdiğini ve ne kadar sürdüğünü ekrana yazdırdı.\n",
    "#Öğrenme süreci bitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "#Bulduğumuz en iyi değerleri yazdıralım.\n",
    "best_parameters = grid_model.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performansları;\n",
      "Doğruluk:  0.7705627705627706\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.5675675675675675\n",
      "F1 puanı: 0.6131386861313869\n",
      "\n",
      "\n",
      "Sınıflandırma Tablosu: \n",
      "[[136  21]\n",
      " [ 32  42]]\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = grid_model.predict(X_test_std)\n",
    "print(\"Test Performansları;\")\n",
    "print(\"Doğruluk: \", (accuracy_score(y_test, y_pred1)))\n",
    "print(\"Precision: \" + str(precision_score(y_test, y_pred1)))\n",
    "print(\"Recall: \" + str(recall_score(y_test, y_pred1)))\n",
    "print(\"F1 puanı: \" + str(f1_score(y_test, y_pred1)))\n",
    "print(\"\\n\")\n",
    "print(\"Sınıflandırma Tablosu: \\n\" + str(confusion_matrix(y_test, y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk: 0.7445887445887446\n",
      "Sınıflandırma Tablosu: \n",
      "[[135  22]\n",
      " [ 37  37]]\n"
     ]
    }
   ],
   "source": [
    "# Aynı veri setini farklı bir model ile deneyelim.\n",
    "#2. Karar Destek Makineleri (Support Vector Machines (SVC))\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = \"rbf\", random_state = 0)\n",
    "classifier.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_std)\n",
    "print(\"Doğruluk: \" + str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Sınıflandırma Tablosu: \\n\" + str(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 133 candidates, totalling 1330 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1330 out of 1330 | elapsed:  3.6min finished\n",
      "C:\\Users\\batuh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Modeli iyileştirmeye çalışalım\n",
    "model = SVC()\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1, 10, 20]\n",
    "parameters = [{\"C\": param_range, \"kernel\": [\"linear\"]},\n",
    "              {\"C\": param_range, \"kernel\": [\"rbf\"], \"gamma\": [0.1, 0.2, 0.4, 0.6, 0.8, 0.9]} ,\n",
    "              {\"C\": param_range, \"kernel\": [\"poly\"], \"degree\": [2, 3], \"gamma\": [0.1, 0.2, 0.4, 0.5, 0.7, 0.9]}]\n",
    "grid_search = GridSearchCV(model,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = \"accuracy\",\n",
    "                          cv = 10, verbose = 1,\n",
    "                          n_jobs = -1)#İşlemcide birden fazla çekirdek varsa ve hepsini kullanmak istiyorsak -1 değeri verilir.\n",
    "grid_search = grid_search.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler:  {'C': 0.01, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "print(\"En iyi parametreler: \", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performansları;\n",
      "Doğruluk:  0.7662337662337663\n",
      "Precision: 0.6785714285714286\n",
      "Recall: 0.5135135135135135\n",
      "F1 puanı: 0.5846153846153848\n",
      "\n",
      "\n",
      "Sınıflandırma Tablosu: \n",
      "[[139  18]\n",
      " [ 36  38]]\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = grid_search.predict(X_test_std)\n",
    "print(\"Test Performansları;\")\n",
    "print(\"Doğruluk: \", (accuracy_score(y_test, y_pred3)))\n",
    "print(\"Precision: \" + str(precision_score(y_test, y_pred3)))\n",
    "print(\"Recall: \" + str(recall_score(y_test, y_pred3)))\n",
    "print(\"F1 puanı: \" + str(f1_score(y_test, y_pred3)))\n",
    "print(\"\\n\")\n",
    "print(\"Sınıflandırma Tablosu: \\n\" + str(confusion_matrix(y_test, y_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Verisi için Doğruluk:  0.7359307359307359\n",
      "Test Verisi için Sınıflandırma Tablosu: \n",
      " [[123  34]\n",
      " [ 27  47]]\n"
     ]
    }
   ],
   "source": [
    "#3. Karar ağaçları kullanarak deneyelim.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ml = DecisionTreeClassifier()\n",
    "ml.fit(x_train, y_train)\n",
    "\n",
    "y_pred = ml.predict(x_test)\n",
    "print(\"Test Verisi için Doğruluk: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Test Verisi için Sınıflandırma Tablosu: \\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "C:\\Users\\batuh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, 5, 7, 9, 12]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kriter = [\"gini\", \"entropy\"]\n",
    "derinlik = [3, 5, 7, 9, 12]\n",
    "\n",
    "parametre = dict(criterion= kriter, max_depth = derinlik)\n",
    "\n",
    "yeni_model = GridSearchCV(estimator = ml, cv = 10, param_grid = parametre, n_jobs = -1, verbose = 1, scoring = \"recall\")\n",
    "yeni_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5665147505635597\n",
      "{'criterion': 'entropy', 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "print(yeni_model.best_score_)\n",
    "print(yeni_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performansları;\n",
      "Doğruluk:  0.7532467532467533\n",
      "Precision: 0.6164383561643836\n",
      "Recall: 0.6081081081081081\n",
      "F1 puanı: 0.6122448979591837\n",
      "\n",
      "\n",
      "Sınıflandırma Tablosu: \n",
      "[[129  28]\n",
      " [ 29  45]]\n"
     ]
    }
   ],
   "source": [
    "y_tahmin = yeni_model.predict(x_test)\n",
    "print(\"Test Performansları;\")\n",
    "print(\"Doğruluk: \", (accuracy_score(y_test, y_tahmin)))\n",
    "print(\"Precision: \" + str(precision_score(y_test, y_tahmin)))\n",
    "print(\"Recall: \" + str(recall_score(y_test, y_tahmin)))\n",
    "print(\"F1 puanı: \" + str(f1_score(y_test, y_tahmin)))\n",
    "print(\"\\n\")\n",
    "print(\"Sınıflandırma Tablosu: \\n\" + str(confusion_matrix(y_test, y_tahmin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 750 candidates, totalling 7500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7500 out of 7500 | elapsed: 14.9min finished\n",
      "C:\\Users\\batuh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 7, 9, 11, 13, 15],\n",
       "                         'min_samples_leaf': [3, 5, 7, 9, 11],\n",
       "                         'min_samples_split': [5, 7, 10, 12, 15],\n",
       "                         'n_estimators': [150, 200, 250, 300, 350]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rastgele Ormanlar algoritmasını kullanarak deneyelim\n",
    "# 4. RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfr = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\"n_estimators\": [150, 200, 250, 300, 350],\n",
    "              \"max_depth\": [5, 7, 9, 11, 13 ,15],\n",
    "              \"min_samples_leaf\": [3, 5, 7, 9, 11],\n",
    "              \"min_samples_split\": [5, 7, 10, 12, 15]}\n",
    "\n",
    "yeni_model = GridSearchCV(rfr, param_grid, cv = 10, n_jobs = -1, verbose = 1, scoring = \"recall\")\n",
    "yeni_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871263353915515\n",
      "{'max_depth': 13, 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(yeni_model.best_score_)\n",
    "print(yeni_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performansları;\n",
      "Doğruluk:  0.7878787878787878\n",
      "Precision: 0.7272727272727273\n",
      "Recall: 0.5405405405405406\n",
      "F1 puanı: 0.6201550387596899\n",
      "\n",
      "\n",
      "Sınıflandırma Tablosu: \n",
      "[[142  15]\n",
      " [ 34  40]]\n"
     ]
    }
   ],
   "source": [
    "y_tahmin = yeni_model.predict(x_test)\n",
    "\n",
    "print(\"Test Performansları;\")\n",
    "print(\"Doğruluk: \", (accuracy_score(y_test, y_tahmin)))\n",
    "print(\"Precision: \" + str(precision_score(y_test, y_tahmin)))\n",
    "print(\"Recall: \" + str(recall_score(y_test, y_tahmin)))\n",
    "print(\"F1 puanı: \" + str(f1_score(y_test, y_tahmin)))\n",
    "print(\"\\n\")\n",
    "print(\"Sınıflandırma Tablosu: \\n\" + str(confusion_matrix(y_test, y_tahmin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
