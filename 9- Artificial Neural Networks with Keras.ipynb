{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "third-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-czech",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "### The Perceptron\n",
    "- The Perceptron is one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. \n",
    "- It is based on a slightly different artificial neuron called a **threshold logic unit (TLU)**, or sometimes a **linear threshold unit (LTU).** \n",
    "- The inputs and output are numbers (instead of binary on/off values), and each input connection is associated with a weight. \n",
    "- The TLU computes a weighted sum of its inputs, then applies a step function to that sum and outputs the result.\n",
    "- The most common step function used in Perceptrons is the **Heaviside step function** (see Equation 10-1). \n",
    "    - Sometimes the **sign function** is used instead.\n",
    "\n",
    "\n",
    "<img src=\"10-1.png\">\n",
    "\n",
    "- A single TLU can be used for simple linear binary classification. \n",
    "- It computes a linear combination of the inputs, and if the result exceeds a threshold, it outputs the positive class. \n",
    "- Otherwise it outputs the negative class (just like a Logistic Regression or linear SVM classifier). \n",
    "- You could, for example, use a single TLU to classify iris flowers based on petal length and width (also adding an extra bias feature x = 1). \n",
    "- Training a TLU in this case means finding the right values for $w_0$ , $w_1$ , and $w_2$(the training algorithm is discussed shortly).\n",
    "***\n",
    "- A Perceptron is simply composed of a single layer of TLUs, with each TLU connected to all the inputs. \n",
    "- When all the neurons in a layer are connected to every neuron in the previous layer (i.e., its input neurons), the layer is called a **fully connected layer**, or a **dense layer**. \n",
    "- The inputs of the Perceptron are fed to special passthrough neurons called input neurons: they output whatever input they are fed. \n",
    "- All the input neurons form the input layer. \n",
    "- Moreover, an extra bias feature is generally added (x = 1): it is typically represented using a special type of neuron called a **bias neuron**, which **outputs 1 all the time.**\n",
    "- **The Perceptron is fed one training instance at a time, and for each instance it makes its predictions.**\n",
    "    - **For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed to the correct prediction.**\n",
    "- **The decision boundary of each output neuron is linear, so Perceptrons are incapable of learning complex patterns (just like Logistic Regression classifiers).**\n",
    "\n",
    "Scikit-Learn provides a **Perceptron class** that implements a single-TLU network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enabling-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radical-brook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "split-colonial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-banana",
   "metadata": {},
   "source": [
    "- You may have noticed that the Perceptron learning algorithm strongly resembles Stochastic Gradient Descent. \n",
    "    - In fact, Scikit-Learn’s Perceptron class is equivalent to using an **SGDClassifier** with the following hyperparameters: **loss=\"perceptron\", learning_rate=\"constant\", eta0=1 (the learning rate), and penalty=None** (no regularization).\n",
    "- Note that contrary to Logistic Regression classifiers, Perceptrons do not output a class probability; rather, they make predictions based on a hard threshold. \n",
    "    - **This is one reason to prefer Logistic Regression over Perceptrons.**\n",
    "- In their 1969 monograph Perceptrons, Marvin Minsky and Seymour Papert highlighted a number of serious weaknesses of Perceptrons—in particular, the fact that they are incapable of solving some trivial problems (e.g., the Exclusive OR (XOR) classification problem; see the left side of Figure 10- 6). \n",
    "    - This is true of any other linear classification model (such as Logistic Regression classifiers), but researchers had expected much more from Perceptrons, and some were so disappointed that they dropped neural networks altogether in favor of higher-level problems such as logic, problem solving, and search.\n",
    "- It turns out that some of the limitations of Perceptrons can be eliminated **by stacking multiple Perceptrons.** \n",
    "- The resulting ANN is called a **Multilayer Perceptron (MLP)**. \n",
    "    - An MLP can solve the XOR problem, as you can verify by computing the output of the MLP represented on the right side of Figure 10-6: with inputs (0, 0) or (1, 1), the network outputs 0, and with inputs (0, 1) or (1, 0) it outputs 1. \n",
    "    - All connections have a weight equal to 1, except the four connections where the weight is shown.\n",
    "\n",
    "<img src=\"10-6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-toddler",
   "metadata": {},
   "source": [
    "## The Multilayer Perceptron and Backpropagation\n",
    "- An MLP is composed of **one (passthrough) input layer, one or more layers of TLUs, called hidden layers, and one final layer of TLUs called the output layer** (see Figure 10-7). \n",
    "- The layers close to the input layer are usually called the lower layers, and the ones close to the outputs are usually called the upper layers. \n",
    "- Every layer **except the output layer** includes a bias neuron and is fully connected to the next layer.\n",
    "<img src=\"10-7.png\">\n",
    "\n",
    "### NOTE\n",
    "The signal flows only in one direction (from the inputs to the outputs), so this architecture is an example of a **feedforward neural network (FNN).**\n",
    "***\n",
    "- When an ANN contains a deep stack of hidden layers(an ANN with more than two hidden layers), it is called a **deep neural network (DNN).** \n",
    "- The field of Deep Learning studies DNNs, and more generally models containing deep stacks of computations. Even so, many people talk about Deep Learning whenever neural networks are involved (even shallow ones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-confirmation",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "- For many years researchers struggled to find a way to train MLPs, without success. \n",
    "- But in 1986, David Rumelhart, Geoffrey Hinton, and Ronald Williams published a groundbreaking paper that introduced the **backpropagation training algorithm**, which is still used today. \n",
    "- In short, it is **Gradient Descent using an efficient technique for computing the gradients automatically: in just two passes through the network (one forward, one backward),** the **backpropagation algorithm** is able to compute the gradient of the network’s error with regard to every single model parameter. \n",
    "    - **In other words, it can find out how each connection weight and each bias term should be tweaked in order to reduce the error.**\n",
    "    - Once it has these gradients, it just performs a regular Gradient Descent step, and **the whole process is repeated until the network converges to the solution.**\n",
    "\n",
    "***\n",
    "### NOTE\n",
    "- Automatically computing gradients is called **automatic differentiation, or autodiff.** \n",
    "- There are various autodiff techniques, with different pros and cons. \n",
    "- **The one used by backpropagation is called reverse-mode autodiff.** \n",
    "    - It is fast and precise, and is well suited when the function to differentiate has many variables (e.g., connection weights) and few outputs (e.g., one loss).\n",
    "***    \n",
    "#### Let’s run through this algorithm(backpropagation) in a bit more detail:\n",
    "- It handles one mini-batch at a time (for example, containing 32 instances each), and it goes through the full training set multiple times. \n",
    "    - Each pass is called an **epoch.**\n",
    "- Each mini-batch is passed to the network’s input layer, which sends it to the first hidden layer. \n",
    "    - The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). \n",
    "    - The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. \n",
    "    - **This is the forward pass: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.**\n",
    "- The algorithm then measures how much of these error contributions came from each connection in the layer below, again using the chain rule, working backward until the algorithm reaches the input layer. \n",
    "    - As explained earlier, this reverse pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network (hence the name of the algorithm).\n",
    "- Finally, the algorithm performs a Gradient Descent step to tweak all the connection weights in the network, using the error gradients it just computed.\n",
    "\n",
    "#### This algorithm is so important that it’s worth summarizing it again:\n",
    "- **for each training instance, the backpropagation algorithm first makes a prediction (forward pass) and measures the error,** \n",
    "- **then goes through each layer in reverse to measure the error contribution from each connection (reverse pass),** \n",
    "- **and finally tweaks the connection weights to reduce the error (Gradient Descent step).**\n",
    "\n",
    "### WARNING\n",
    "#### It is important to initialize all the hidden layers’ connection weights randomly, or else training will fail.\n",
    "- For example, if you initialize all weights and biases to zero, then all neurons in a given layer will be perfectly identical, and thus backpropagation will affect them in exactly the same way, so they will remain identical.\n",
    "- In other words, despite having hundreds of neurons per layer, your model will act as if it had only one neuron per layer: it won’t be too smart. \n",
    "    - If instead you randomly initialize the weights, you break the symmetry and allow backpropagation to train a diverse team of neurons.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-egyptian",
   "metadata": {},
   "source": [
    "## Activation functions\n",
    "- In order for this algorithm to work properly, its authors made a key change to the MLP’s architecture: they replaced the step function with the **logistic (sigmoid) function**, σ(z) = 1 / (1 + exp(–z)). \n",
    "    - This was essential because the **step function contains only flat segments**, so there is no gradient to work with (Gradient Descent cannot move on a flat surface), **while the logistic(sigmoid) function has a well-defined nonzero derivative everywhere, allowing Gradient Descent to make some progress at every step.** \n",
    "- In fact, the backpropagation algorithm works well with many other activation functions, not just the logistic function.\n",
    "    - Here are two other popular choices:\n",
    "\n",
    "\n",
    "#### The hyperbolic tangent function: tanh(z) = 2σ(2z) – 1\n",
    "- Just like the logistic(sigmoid) function, this activation function is **S-shaped, continuous, and differentiable, but its output value ranges from –1 to 1 (instead of 0 to 1 in the case of the logistic function).** \n",
    "- That range tends to make each layer’s output more or less centered around 0 at the beginning of training, which often helps speed up convergence.\n",
    "\n",
    "#### The Rectified Linear Unit function: ReLU(z) = max(0, z)\n",
    "- The ReLU function is **continuous but unfortunately not differentiable at z = 0 **(the slope changes abruptly, which can make Gradient Descent bounce around), and its derivative is 0 for z < 0. \n",
    "- **In practice, however, it works very well and has the advantage of being fast to compute, so it has become the default.**\n",
    "- Most importantly, the fact that it **does not have a maximum output value** helps reduce some issues during Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "designing-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "neither-guatemala",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(sigmoid, z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=12)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-venice",
   "metadata": {},
   "source": [
    "- These popular activation functions and their derivatives are represented above. But wait! Why do we need activation functions in the first place? \n",
    "    - Well, if you chain several linear transformations, all you get is a linear transformation. \n",
    "    - For example, if f(x) = 2x + 3 and g(x) = 5x – 1, then chaining these two linear functions gives you another linear function: f(g(x)) = 2(5x – 1) + 3 = 10x + 1. So if you don’t have some nonlinearity between layers, then even a deep stack of layers is equivalent to a single layer, and you can’t solve very complex problems with that. \n",
    "- Conversely, a large enough DNN with nonlinear activations can theoretically approximate any continuous function.\n",
    "OK! You know where neural nets came from, what their architecture is, and how to compute their outputs. You’ve also learned about the backpropagation algorithm. But what exactly can you do with them?\n",
    "## Regression MLPs\n",
    "- First, MLPs can be used for regression tasks. \n",
    "- If you want to predict a single value (e.g., the price of a house, given many of its features), then you just need a single output neuron: its output is the predicted value. \n",
    "- For multivariate regression (i.e., to predict multiple values at once), you need one output neuron per output dimension. \n",
    "    - For example, to locate the center of an object in an image, you need to predict 2D coordinates, so you need two output neurons. \n",
    "    - If you also want to place a bounding box around the object, then you need two more numbers: the width and the height of the object. So, you end up with four output neurons.\n",
    "- In general, when building an MLP for regression, you do not want to use any activation function for the output neurons, so they are free to output any range of values. \n",
    "    - **If you want to guarantee that the output will always be positive**, then you can use the **ReLU** activation function in the output layer.\n",
    "    - Alternatively, you can use the **softplus** activation function, which is a smooth variant of ReLU: softplus(z) = log(1 + exp(z)). \n",
    "        - **It is close to 0 when z is negative, and close to z when z is positive.** \n",
    "    - Finally, **if you want to guarantee that the predictions will fall within a given range of values**, then you can use the **logistic(sigmoid) function or the hyperbolic tangent**, \n",
    "        - **and then scale the labels to the appropriate range: 0 to 1 for the logistic(sigmoid) function** \n",
    "        - **and –1 to 1 for the hyperbolic tangent.**\n",
    "- **The loss function to use during training** is typically the **mean squared error**, \n",
    "    - **but if you have a lot of outliers in the training set**, you may prefer to use the **mean absolute error** instead.\n",
    "    - Alternatively, you can use the **Huber loss**, which is a combination of both.\n",
    "### TIP\n",
    "- The Huber loss is quadratic when the error is smaller than a threshold δ (typically 1) \n",
    "    - but linear when the error is larger than δ. \n",
    "- The linear part makes it less sensitive to outliers than the mean squared error, \n",
    "    - and the quadratic part allows it to converge faster and be more precise than the mean absolute error.\n",
    "\n",
    "#### Table 10-1 summarizes the typical architecture of a regression MLP.\n",
    "<img src=\"t1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-millennium",
   "metadata": {},
   "source": [
    "## Classification MLPs\n",
    "- MLPs can also be used for classification tasks. \n",
    "- **For a binary classification problem, you just need a single output neuron using the logistic(sigmoid) activation function: the output will be a number between 0 and 1, which you can interpret as the estimated probability of the positive class.**\n",
    "    - The estimated probability of the negative class is equal to one minus that number.\n",
    "- MLPs can also easily handle **multilabel binary classification tasks.**\n",
    "- For example, you could have an email classification system that predicts whether each incoming email is ham or spam, and simultaneously predicts whether it is an urgent or nonurgent email. \n",
    "    - In this case, you would need two output neurons, both using the logistic(sigmoid) activation function: the first would output the probability that the email is spam, and the second would output the probability that it is urgent. \n",
    "    - More generally, you would dedicate one output neuron for each positive class.\n",
    "    - Note that the output probabilities do not necessarily add up to 1. \n",
    "    - This lets the model output any combination of labels: you can have nonurgent ham, urgent ham, nonurgent spam, and perhaps even urgent spam (although that would probably be an error).\n",
    "- If each instance can belong only to a single class, out of three or more possible classes (e.g., classes 0 through 9 for digit image classification), **then you need to have one output neuron per class**, and you should use the **softmax activation function** for the whole **output layer**(see Figure 10-9).\n",
    "- The softmax function will ensure that all the estimated probabilities are between 0 and 1 and that they add up to 1 (which is required if the classes are exclusive). \n",
    "    - This is called **multiclass classification.**\n",
    "\n",
    "<img src=\"10-9.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-mexican",
   "metadata": {},
   "source": [
    "- Regarding the **loss function**, since we are predicting probability distributions, the **cross-entropy loss (also called the log loss)** is generally a good choice.\n",
    "#### Table 10-2 summarizes the typical architecture of a classification MLP.\n",
    "\n",
    "<img src=\"t2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-instrument",
   "metadata": {},
   "source": [
    "## Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regulated-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adopted-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "correct-reform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-guitar",
   "metadata": {},
   "source": [
    "## Building an Image Classifier\n",
    "- Let's start by loading the fashion MNIST dataset(70,000 grayscale images of 28 × 28 pixels each, with 10 classes). \n",
    "- Keras has a number of functions to load popular datasets in keras.datasets. \n",
    "- The dataset is already split for you between a training set and a test set, but it can be useful to split the training set further to have a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genetic-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-daniel",
   "metadata": {},
   "source": [
    "- When loading MNIST or Fashion MNIST using Keras rather than Scikit- Learn, one important difference is that **every image is represented as a 28 × 28 array rather than a 1D array of size 784.** \n",
    "- Moreover, the pixel intensities are represented as integers (from 0 to 255) rather than floats (from 0.0 to 255.0). \n",
    "\n",
    "Let’s take a look at the shape and data type of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "qualified-harvey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radical-interaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-roulette",
   "metadata": {},
   "source": [
    "- Note that the dataset is already split into a training set and a test set, but there is no validation set, so we’ll create one now. \n",
    "- Additionally, since we are going to train the neural network using **Gradient Descent, we must scale the input features.** \n",
    "- For simplicity, we’ll scale the pixel intensities down to the 0–1 range by dividing them by 255.0 (this also converts them to floats):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "billion-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-bulletin",
   "metadata": {},
   "source": [
    "#### You can plot an image using Matplotlib's imshow() function, with a 'binary' color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assisted-curve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-kingston",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "broad-workshop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-advertising",
   "metadata": {},
   "source": [
    "- With MNIST, when the label is equal to 5, it means that the image represents the handwritten digit 5. Easy. \n",
    "- For Fashion MNIST, however, **we need the list of class names to know what we are dealing with:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prerequisite-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stuck-facing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-dance",
   "metadata": {},
   "source": [
    "#### The validation set contains 5,000 images, and the test set contains 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indian-gasoline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "optimum-access",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "induced-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAEjCAYAAAAR5ZjkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAADXZElEQVR4nOydd5xdRd3/37M9m83upoeEEAKE3kGKgoB0BMEGCKjoY0H0UZFHsYCKivjwKNafiAoIIiAiUgUbvUnvRSCkkV422ZZsm98fcz5z5557d7PZbDk3zOf12tfee8+5556ZM/Od73y+zVhriYiIiIiIiIiIiMgSykb6BiIiIiIiIiIiIiLSiEpqRERERERERERE5hCV1IiIiIiIiIiIiMwhKqkRERERERERERGZQ1RSIyIiIiIiIiIiMoeopEZERERERERERGQOUUkdARhj5hhjDuvl2IHGmFeG+542FfTVt1mHMcYaY7bZ0GPruebpxpgHNv7uhh+xP/IR+yMiIuKthmFVUo0xpxhjHjfGtBhjFhlj7jDGHLCR17zHGPOJwbrH9fxWS/DXY4xpD96fOhi/Ya2931q73Xruo6gilvTvNcaYLZNFq2Iw7mmgMMYcYIx5yBiz2hiz0hjzoDHmbSN5T8OBZEyuMsZUj/S9DBWMMQcbYxb089zYH/nnxv4Ymt8s6fVlsPFW749knWw3xjQbY5qStegMY0wk5yid8TFsD8sY8yXgJ8D3gcnAFsAvgeOH6x42FtbaOv0B84Djgs/+MNS/3w+l8xjgr0N9H/2BMaYeuA34OTAOmAacD6wbyfvqDzZGuTfGbAkcCFjgPYN1T6WK2B/5iP0xNNgU1pfBROwPj+OstWOAGcAPgHOAy4qdaIwpH84bG0mU1Piw1g75H9AAtAAf7OV4Na7DFiZ/PwGqk2NjccrOMmBV8nrz5NgFQDewNrn+L4ajPclvzwEO6+P4hORem4CVwP1AWfDd/wGeBVYDfwRqkmMHAwtSv3NOcu464FqgB2hP2vyV5LwyYEnyu/Nwi2BL8rd/cvxcYC6wFLgKaEi+u2Vy/qeS/l8EnL2R/bM30NTLsdOBB4AfJs/0DeDo1Hi5LLmPN4HvAeXJsa2Bu4AVwHLgD0BjsecCbJ9c++Tk/bHA08kzeQjYtY9+rhhgu78JPAhcDNyWOvY74P8BtwPNwL+BrYPjFtgmeX0AMB84pMix6qTv5iXP/FfAqD76+kHcZmE18DJwaHB8KnALboy+BnxyffMSGJ2Mv55gjE2N/RH7Y0P7YzD+2ATXl9gfg9IPc0it0cA+ybjcOZlvl+CInVbgsGS8/zlp/xvA51PffRxYk8yri5PPa4CrcWtSE/AYMHmk27+pjI/h6pSjgC56WfiB7wCPAJOAiTgF4rvJsfHA+4FaYAzwJ+Cm4Lv3AJ8YgQddMAFSxy/ELQ6Vyd+BgAm++2gyIcYBLwFnJMcOplBJfRqYTrLQ9DL59gMeTl5viVu0KoLjH8ctMlsBdcCNwO9T51+LW2B2SQZhr+3rR//UJ5P2SuBoYGxw7HSgE/gkUA58JpkM6p+bgEuTe5mU9NWnk2PbAIcnE2kicB/wk/RzAfbELdLHJp/viVPO901+86PJudW99fMA2/0acCawV9LGycGx3+EW+32ACpyCfV1w3CbtOxKngOyTPpa8/glOcRiHmxO3Ahf2cj+n4+beWbhxeBJOGRmXHL8Xt4OuAXZPnvuh/ZiXBxOM09gfsT8G0h+D8ccmuL7E/hiUfphDkTUMty58Jplvq4F34EicWuAJ3EayCrdWzgaOTL73MPDh5HUdsF/y+tPJHKvFrS17AfUj3f5NZXwMV6ecCizu4/jrwDHB+yOBOb2cuzuwaig7pZ9tKjoBUg/6ZpKFo8h3TwveXwT8Knl9MIVK6sfX99vAd4HzktdbUqik/gs4M3i/HW6RrAjO3z51T5dtZB/tkAiCBcmkuAVnWjgdeC04rzb5/SnJ8XUEiiLwIeDuXn7jBOCpVN+cn/zmIcHnl2iiBZ+9AhzUWz8PoL0HJH06IXn/MnBWcPx3wG+D98cALwfvLfA1HNu9S+raUlAMbtcfMmz7A2/0ck+nE2wAks8eBT6MU8i7gTHBsQuB3yWve52X6XEa+yP2x4b2x2D9sQmuL7E/BqUf5lBcSX0E+EYy364KPt8XmJc692vAFcnr+3Bry4TUOR8nZZnL8l+pjY/h8kldAUzow9dvKk7wCnOTzzDG1BpjLjXGzDXGrMENlMYs+Y8YY7YIg6qSj/8Px5r83Rgz2xjz1dTXFgev23A7s94wvx+3sT5/1GJ9XIFTCov9jn8GA4W19iVr7enW2s1x5pWpOJYHgvZba9uSl3U436FKYFHi7N6EY1UnARhjJhljrjPGvJmMh6txLg4hzgAestbeHXw2Azhb10yuOz3Vxv70c1/4KPB3a+3y5P01yWch1vfcvwhcb619rpffmEiy4w/acWfyeW940yYSJIGe7VRgpbW2OXVsWvK613nZT8T+yEfsj6HBJr2+DACxP/rGNJzFAvJl/gxgamqN+Dq5NfK/gG2Bl40xjxljjk0+/z3wN+A6Y8xCY8xFxpjKIW/FwFFS42O4lNSHcX4KJ/RyfCFugAhbJJ8BnI1j/fa11tYD70w+N8n/ULiOCKy182x+UBXW2mZr7dnW2q2A44AvGWMOHehP9PXeGDMF2Ax4spfzoXgfd+F8a4TpqeMLGSRYa1/G7Vx3Xs+p83FM6gRrbWPyV2+t3Sk5fiGufbsm4+E0cmNBOAPYwhjz49R1Lwiu2WitrbXWXhve5sBaB8aYUcCJwEHGmMXGmMU4E+puxpjdNuBSHwROMMZ8sZfjy3H+fjsF7WjQuOsF04wxYR/p2S4ExhljxqSOvZm87mte9tlXsT/yEftjSLFJry8DQOyPXmBcdplpuJgIyG/PfJzFIVwjxlhrjwGw1r5qrf0QjjD5X+AGY8xoa22ntfZ8a+2OwNtxsQ8fGbZGbThKanwMi5JqrV2N8/P4f8aYExJtvNIYc7Qx5iKcL+S5xpiJxpgJyblXJ18fgxO6TcaYccC3UpdfgvMdyRSMMccaY7ZJhP8anNmse5Aun27zMcCdARuyDOccHp5zLXCWMWamMaYOF9X3R2ttV3DOecmz2Qn4GC6ga0AwxmxvjDnbGLN58n46zmz/SF/fs9YuAv4O/MgYU2+MKTPGbG2MOSg5ZQzOKbvJGDMN+HKRyzTj/G7eaYz5QfLZb4AzjDH7GofRxph3pxbgjcEJuOe7I84EsjvO3eF+NkxgLQQOBT5vjDkzfdBa24Nry4+NMWKXpxljjuzjmpOS61UaYz6Y3NdfrbXzcWaqC40xNcaYXXFsgTJV9DUvlwDjjTENvfzmCcT+CHECsT+GBG/F9aUvxP4oRLKWHAtcB1zdiyXiUWCNMeYcY8woY0y5MWbnRLHFGHOaMWZiMseaku90G2MOMcbskrCJa3AuPYO11g86Sm58DKbvwPr+cL4Qj+N8phbjoljfjnPK/xkumntR8lrR7lNxfg4twH9wTsqWxN8S52/1H1yk2c+GsS1z6Nsn9azknFacf+R5vX0X+DZu4kBxn9S0/+nxOOfvJlyWgBuAD6TO+Q5OWW3CBVWV4Qbb/OTzq0mCmSiM7l9MkjVgI/pnGnA9jnVpTf5figuoOh14IHW+JRf40YDzIV2Ac2x/ilyE/k445/YWXKDT2b31Fy5w5BlyTt9H4SIvm5Jx9icSf7v1Pc9+tPdO4EdFPj8x6c8KHJP8veBY+lmHfTATZ2b5RJFjNbhNxmycUHyJIAo19fun46K3f5H05X+AI4Ljm+MiNFfifJHOCI71Oi+T45eTi2idGvsj9kd/+2Mo/tiE1pfYH4PS/jk4hao5GdsPA58llykmb74F7b826a9VOFJF68nVuODbFuAF4ITk8w/h4htacUrazxhgdpg4Pgr/FE0dUaIwzq9kMS5QYvUAr7ElLt1Gpc1nViMiIiIiIiIiRgSx8kLpYxyOpR2QghoRERERERERkUVEJjUiMqkRERERERERmUNUUiMiIiIiIiIiIjKHaO6PiIiIiIiIiIjIHKKSGhERERERERERkTn0VnGgPxhxPwFrLfk5qDcIA/5iL9ig/nj++ecBaG1t5aWXXgLgkksuAeCaa64BYOutt+7zGg884PIRf+973wPgu9/9LuXlrvDDzJkzARg7dmx/b2lE+yODiP2Rj8HuD4h9kkbsj3wMqD9CF7b0+nDMMcdQV+fqGnR1Off7I488kk9/+tN55/X09ABQVrZRPM6I9kdf/XD33XcD8NnPfpbq6moA1q5d67936623AjBr1qy87/X09PhrDWDtzcT4CPGvf/0LwK/BO+ywA9tss03eOU1NTTQ1NQFwww03AHDwwQcDcNRRRzF69OiB/nwmxkex56j50NPTw/HHHw/AypWuSNedd97JsmXLAPjHP/6xQdddD4p+YWN8UgdNoEph+/Of/8y///1vALq7XS7cKVOmsMMOOwBwyCGHALDvvvsOxs+OyAC5+mqXE7elxVVPnThxIttttx0AX/va1wC45557ANh88815+9vfDsCoUaP8sddeew2AdevWAU7IAvzkJz/h2WefBWDJEldIasaMGbznPe/pz61lToCMMGJ/5CMqqYWIYyQfmV10v/xlV/Pj0ksv9UqIFt2qqip+97vfAXh5O0jI3Pj485//DMAHPvABAHbbbTdWrVoF4JWt6upqXnzxRQBuueUWILfG5N3MhisjI9ofra2tAHz1q1/l5ZdfBnLr8JZbbgm4NVfjQ4rY66+/7jc0wpw5c/xrbXruuOOODbz97IyP5ctdpeYPfehDADz44IOAmxvasOk59/T0eDJMn/3qV78C4KSTTiq4dnd3tz9/PciOkqoJ8F//9V8APP7444Db2VZUOHJXO9iysjK/w9Nn2267LQBnn302n/jEJwZ6G8M+QG677TbuuusuAE477TQAFi5cSGNjI4BXVrWLvfjii/3E0sR57rnnmDDBlar/yle+AsApp5wCwGOPPeb7qra2FoDrrruOo446CiguaAJkZsJkBLE/8hGV1ELEMZKPzPTHF77wBQAeffRRILcIjxs3jvnzXbl2yd0xY8bQ3t4OOCUF4POf/zzgmLKNYFWHvT+KWRcvueQS/vSnPwHwn//8B3BtBjjuuOO8Yi5d4E9/+hNPPfUUkGObp093FbPf+9738t///d951+/p6elv34zo+NB9NzU1+TVUkLJaU1PjlU6Nj4qKCk8MCdJTWlpa/Hel+BdT1HrBsPVHsQ3FQw89BDg94umnnwagvr4egEmTJgGwdOlSf74Yd8Azy1OmTAHwc2rs2LF861vfAhiIbla0P6JPakREREREREREROYw5ExqsV3o5MmTgdzutqGhwV3QWiorK4HcDq68vNyb/gWZJzbffHOvwRe9wb7NEcO+q/vFL37Bm2++CcCOO+4IwBZbbOGP19TUALndfE9Pj/f5WLNmDQD77LMPEydOBBwrADB79mwAOjs7fX8vWLDAHxOr+sUvfrGv28sMC5IRxP7IR2RSCxHHSD4y0R+XXHIJF110EQA777wzkFszVq5c6dmitrY2wJm5N9tsMwAWL16cd0wM0wAx7P0Rspq/+c1vAOfqICZU66osdPPnz/frgtaRW265hWnTpgE5NlFr8JtvvslnP/tZAC688MINvf8RGR+K3Tj//PMBxwLKpzRtxhdDCjkz/tq1a72uov7QOKmoqPDfEdv629/+dr3xJAlGpD+uuOIKINcfPT09Xu+S/iBdZPHixcyYMQPIjYHnn3/eM6iaS52dnYDTtaSrKC5G1gwYmE4WmdSIiIiIiIiIiIjMYWOi+9eLYr4qTU1NnkmVti6mb/vtt/f+qtK0J0+e7DX4efPmAfm+RE8++SQAe+65Z97vwkZHZg46nnnmGe932tzcDLhdmoKiqqqqgNyOrL6+3u/45Hjc1dXF6tWuAurChQuBXD9Cbkcjp++amhrvhxSxaSH0P9OYsNbS0dEB5PyE9L6zs9P7FWkOTZo0yc+vtJ/WsmXLPPO/++67D11DIiIGEffee6+XiZKH48ePB5yM1RxQ5pOqqio/BySLJVufeOIJ9tprr+G7+Y1EuOZdf/31gPMb1PqhYFu9nzFjhmdctW5uu+22XmaoX7Q2bbbZZtx7771D3YxBxQEHHADk4jruueeeAmZUrGkI+ZquXbvWjycxr/LJnDBhgo+pEbv67W9/m9///vdD0JLBwXnnnQfk9K7u7m4/bsR0KrZl4sSJvo8UaDhjxgxvxdX40Hiy1npLr9afxx57jLe97W0Dvt9saXERERERERERERERDBGTWozJ3H///QGYO3duQUoDsX61tbX+2Ouvvw449lTso9JESENfunQphx9+eN5vLVu2zL9Oa/kjjZqaGh8tpzYtWrTI+26IXdUOp66uzn+mfpk0aVJBe7Q7XrdunWfUdM7ChQv9dzcif1nm0FdbwmNiUtQHVVVVm0T7Ib/tH/vYxwB44403/GdiAtQHixcv9rtifXfixImeFZDv0d577w3Ascceyx/+8AcALr/88iFqxcCQfv4bYz3ZlObFcGHu3LkA3HTTTXzuc58DsiNn16xZ45kgyUMxqXV1dXnrDTiLnOaA/uv7jz76aEkxqQArVqwAcha5mpoaPz/EIofMlyK5leGgrKzMM4taQ/W/rKzMW1fk57sBubhHBLp3+dJ+9atf9b7KZ5xxBpCzIolhhXz/VMlNjQv5ZM6ZM8dbmTR2fvjDHw5BKwYHHR0dPtWY5F13d7f3UU7P4e7ubt8n0smmTJnifbY1roTOzk5vjdD1//KXv3gmdSAydkiU1PBGzjnnHCA3YbbYYgtPmYtC14OfP3++HzwSLo2Njf54mJsMYKuttvJBV3L6/tSnPsWvf/1rIDtCU+YAa61XtEWdb7XVVr6taruwcOFC30cyv7zwwgs+fYjcJjQ52travODVIJo+fbpXVpRDdbfddhvcBo4AwjEmdwalJvvRj34EOHeJT33qU8N/c8OEzs5O7/Cu3MEvvviiFxL6r3mwyy67eIGtzU9ra6sXxnKn0SLe1tbm80tmDWlhFyqp9913H5BL0TZr1izfbs0/pYDbcccdC67V0tLi3Y4kc7QovfOd7xzklgwftJmtrq7m73//OwCnnnoqkMufub72XXXVVQA+RdEXv/hF7r//fiCX4HykIVM95DZqesabb765nzOaF1VVVT7YQ3JTePDBB/nMZz4z5Pc8mFCwl553ZWWlX0OlbMl8v27duoLUjnPnzvXH1R+aP9Zafy2tJwcddNBQNmejoeccrq9STkOzPeSnWZKeUlFR4T/XeNL5LS0tnH766UDOnUDrchbx0EMP+bGusdDW1ublosaMNiI1NTVeV9FGr6amJs+FDMjTa9IuInfeeSff//73B3zP0dwfERERERERERGROQw5k/rwww8DjjHUMe1QZGaTRl9eXu6PycTy+uuv+92OKk8pXUh7e7unqeXI+9xzzw1FkzYKSs4/ZcoUv4sX+7d69WqfhioMgAKXmku7XDkjT5w4kUWLFgH46lxiRleuXOkZZZnjttpqK99fqoixKTCpIVQVRWYJ9dkrr7zCL3/5SyDXf7NmzeKYY44Bci4o2iGWGsL0cUp5UlNTU2ChCM06YgK0Y66oqPC7Yo1NVSsbP368n3NZQ18met2/2M9Ro0Z5dk3V3JTabauttuK6664D4Gc/+xngqqdovIgpEEuy//77+34qNYSmObkdiUX/5Cc/CbhxJJmqcQG5/lYqI33vH//4ByeccMLQ3ng/IdZPVgLIMV9qU3t7e0FKwwULFvi5IugZv/rqq0N2v0MFsdx6ZqELjPpDzGBZWZnvD1kNOjs7PfuoflF/GGP8nHvkkUeA7DOpxSAmVKyzZEVdXV1ewBS4PpNMlS4inaWlpaWk2n/rrbfmzWtw81w6QmjVBjeGNH5kpYXceBArK/0Lciysvhe6oA0EkUmNiIiIiIiIiIjIHIY0BVV3d7f3Z5B/XH19vdfIpdHrf3V1tWd4wuAqBXLImVu7mdmzZ3sWTDv75cuXe9+6MFH+SEJOw4899pj3dVOZuiOOOMLvQuTwvsceewCOWQ53c+B2Nkr2rz7Vjra2ttYztDfeeCMAH//4x72j9D777DNUTRwxrFixwvepkhSrpGF1dbX39xUztnz5cs+8yndZzPL73vc+3/elBjF9xphe/clqa2v9MfmddnV1+R1vujTkxvgRDTXSDGrof65CFjonDKBTsIfYj5tvvtmnr5NcmT59up+T6hsxB6XKokJOXkAuwbkYIcnbhx9+2PebZGpnZ6cPjtlpp52AnP/ylClTClKXjRTEeq5bt65gfGjtqKio8DI1HDNppqyUn7fSMqaDCiHnZ6ljYR/oM2utlxlqv+ZPVVWVHxdad0oFYSC1xrGYVD336upqb5ETuwq5uaD/Ol++mKUCyb8QlZWVPPjgg0COEdUasHbtWr+GykIxZswYr7Op/c888wzgLMNaa8Xk19fXez0wZFz7iyFVUufOnesbJiHR2dnpH7RMDho8XV1d/jNFHHZ0dHhTjUxUWmjHjh3rvyvlNqwOkRUl9dhjj/X/NUj++te/As5k/653vQvIKRWq0LDLLrv4tkuxX7Vqlb+GBI4Wn8mTJ3sXAC0+5557buajL9PoT7S1nntdXZ3vP32mzAk/+MEPfEUMBZtNmDDBm8Z1nqIWv/3tb3PzzTcPaluGEsWqxdXU1HjFqlj/SbiGefF0ngSPziklhGNGi4sW2NWrV3v3FwVMHXfccYAzV2seKXCkqqqqQDmRAl+KKJblRG5YaqfaN2nSJP+ZxsPatWu9PNEGQCY9uc5kAbqn7u5uPwYkP7WujB492psoJTe7u7v9QqygF50jcqCUoA2EYK31OTzVvlA2aPxLma2srPTzSWNHa06Yc1X9XSoIq1jKjUmfSWfo6uryYyecL+nKVBoXoatL1rIJFUNra2tBVc/W1lavI6hd0tvGjx/v10u5UXV2duYpoJDTvxYvXuz7UspqW1sbL7zwAgAHHnjgBt9zNPdHRERERERERERkDkPKpCqIB3IsYWtrq2dVtbuVRt/e3u53t9Lo29raPPMqBlU7lZaWFr/jlUm7u7vba+1hFaqsQDsWBTF97nOf8ztY7XJfeuklwOWr1Pn6bOrUqZ4y/9e//gXkWMJXX33V7xC/973v5f1eqcBa6/sjzOUH+bt/MdF//OMfeeyxxwAX8AI5U+bo0aP9uNDu7qCDDvKskMaOxqOY1VJBmMcvZFW1qxVbqjrca9eu9bth9UFXV5efV7qejpUSwrEhq4Mc9rfccks/pl555RUgF8jZ3Nzs548CEnt6erwlR2bgrAaQ9QdpRv3VV1/1rkUaG2JOysrKCnILt7e3e1Y1TGOl87MCzfHFixf7vMGSs2KKV69e7dsg2VBTU8Pzzz8PwHvf+17ApeoJr1lKkNwM19f3v//9AD49m55xdXW1Hx+Sf6+88oqXBXru++23H+CsTnrmYbqmUkAoLzUe9JnM211dXb7/xMJXVFR4fUTna7wUY1uzzKS+8cYbBfKgra3NP2flyhYrvGzZMq+7SZdYt26dN9+rjzRP6urqvDuN5EdXV5evUhaZ1IiIiIiIiIiIiE0CQ8qkvvDCC37XJZ+WN998k1122QXI7Ti0q+no6PDat9iNrq4uf1zavXZwITMk5/3y8nLvb/XhD394CFu34Qj9/9T2iooKz+iJtRGz9cgjj3DKKacAOSZ69uzZfhcs528xA7Nnz/Z9FKazKgVfmZAtTd9nuPPTOFIQ2D/+8Q/PiHz7298GcgxJQ0OD9zMUZs+e7ceWGFSdv3LlyswF3fWFsF80BlpaWpg1axaQ2/Xr2LJly7ylQrvdiooKf520FaOUEPaFgik1jkI/+DvvvBOA22+/HXDt13hQu7u6uvz1NO+yEhw0EKTZzptuusn7pWkcaP6FMioMoJIM1liSb2pYQGSkEQaF7LjjjkAu1ZjWlTB5vdijuro6f1zMsorEzJkzx7NFkhNZh1gurQEvv/wy119/PYC3MspHNaxZL8uD1h/IMa6q1nTiiSd61rHUfNdDplOp1AQFUi5ZsiRPlxCkZ0iOqG/DwKmQqc0qFixY4O9TwbOf//znufLKK/M+k0ysrq72Y0DHINduyQiNhRNOOMFbZVTEqLKy0gc3DwSRSY2IiIiIiIiIiMgchlT1X7BgQVH/QjGh2qFKUw+T+Yd+delIW52zdu1afw1p/rW1tbz88stD1qbBgvxPGxoafB/Jr0OFDJ5++ml+/vOfAzl/oeeff97vlLUbFDPQ3d3td8FiBMLjWUFf0fudnZ2evRKbIaa5qqrKp9b629/+BrgobbHNqi8vf7LGxkbP8oh1Xr58uWeWdV31/1VXXeXLRA42kzrQ+vBdXV0FO3TNl3BeXHrppYBL8aHoVLFdof+Q2q5r6DegMM1KWHZ1uLG+/gpT1PV2XpgZQ206+eSTgRxbdP/99/vxpkjV8vJyn9xavmdhOposorf+6unpKZj/11xzjWeL1Ed99SPk5opKn4qBXbZsmfdjG2nIpxhyVgH53oa150P2EHJ9ALkMMmJin3rqKV8IQhaKLGPt2rV+7RTbV1lZ6ddH9YeOrVu3zs/xMMuO1mt9Vqz2eroAQilBMk/l2lUWWDIzRCh/5a8vJrrU2OQ1a9Z4f3tZR3784x/7IidiPCULw7GgMbN06VJ/Da3Rsl7vv//+fvxpjQ6zDg0EQ6qkvvTSS0WFZ3oCpE1PIXp6evyCqsGi71VUVBQEYVVVVfmFJcvQA29sbPSvRaeLLpdbBOTMNEcffbQXwKqZrT4eP368HzRZNj2EQjQ9Pjo7O/040CSS2eD555/nc5/7XN41nn32Wf75z38CuaAAOWcbY7ySqv977723V3CkvEnQHH744Zkz84fPsZhyes011wDOhAtw/PHH+02a2iclpayszI81mS7b29vzqsmE35s3b55PP5IldHd3+3FTbJwrjZjM/vPnz/emXaVFkbwoLy/3C7fGRXd3tw8SCE2fWUZvymWooCqP8Ouvv+6rrWlMac6FFYiEMF/z4YcfDuQ22U8//XRmlFQpmOFrjeVQLmr9Ud+EwXPKm6l8yWVlZT49VSlg3rx5BeulFArIKWHbb7894Ma8xn248dO41+ZEz3vixIkF6ZiWLVvm51WWEcoKyQb1g+RcuIEJg6X0eUiQQekEmWojFhJZYf5cucVpXVB6sZ6eHi9b1Oaqqip/XMHxUmp33313Lw++/OUv+/O10RsIskWxRURERERERERERDDETOpzzz2XF7wgyLwWJhQHt4PTbqcYA5ve8dXU1HiGJNwViJFU9aV08MxIoRjbMWHChILqJjIlrFu3zpsd1VcvvPBCQToY9VllZWXRHe2GmpiHGmFQV1hXHtxOVU7qYsSVPuUXv/iFd9pXSqCFCxfyxBNPAG4XB7lUGRMnTvRjQQEU1dXVnlmYOXMmkOu/KVOmFNR9HyyEzyCdhD8c62EAi/6nqx4JV1xxBd/61rcAx7CDSx+TLnAhFrmrq6vATA75Sbwh9yxeeOGFEWNSw/tLB/6FAQ2SK0pJdvvtt3uzr9ozefJkv/O/9tprgZx70MKFC/2cEYvQ0dHhGST1vQJPlNoo65CMqKqq8q81VnbffXffv7LahPMwnci9oqLCWxtUWUbnX3PNNRx//PFD3Zx+QYx4WNVGDJKecWiZ0zgKgzXFmkqGLF26tKRMuosXL/bPT+3cfPPNvbVJx8Smhax5mLJK/aGxc9111wGOcVTxE42BefPmlQSTGkLpG8UOyjp5wAEH+HN0LGSO0y5Rf/zjH9l5552BbAcmK4XlpEmTvLwPrSxiymWdVX+UlZX5cRFaO/WZ5ovWmjfeeKMgzVR1dbVnnLUeb8h4iUxqRERERERERERE5jCkTOqiRYv8rjb04ZAmr92cdms1NTV+9yfNHCjY2etY6HOo74W7HvlxZoVJLYbRo0f7vlH7xPJYa70vR8g+a0eT9pdbt27dgGrjDjXESskfSmzlkiVLPNsl/5/999/fs2I/+MEPgNzu9mtf+5pnBJS4f8mSJd5/bNdddwVyfVVVVeV9ZfRZyBKo1rfO6enp8YzbbrvtNmjtD9Hd3d1niq2+WG9ZBi677DIAbrnlFp86Zc6cOUB++qg0S71s2bICX86QRdK40/unnnqK97znPRvaxEFBuNtP91dzczN/+ctfgMJk7fX19Z4h1679tdde8yy7dv4KEBg/frwPIlLfVVdXe7ZfjILSGxV7flmC5F8oG1Q2WFaIhoYG3w9p9jxkUjV+wqTtmh/y5Vu2bFlmUtzpedfX13tWPB0UGFrcNN6rqqq8D6vWotCPs5SY1CVLlhQwZWPGjPEyVQxx2mKThq6h8a9g1G222cYzqULoC1wquOGGG4DcuNDcf/755/08kUUzhHxTw/RepQDdZ2jRDtlMFcCR5UFrYnd3t187NadaW1u9pVFzQ3Lk0Ucf5SMf+Ujeb/f09HgZIZ9v+bb3B0OqpIbVS8JKJXrAobkF3ISRUAmDOdKCJvxeWH8W8oWznOWzjO7ubr8IpAPDenp6vCBVP4amcil/YfWXdNDDSOONN97wkX2aFHJh2H333f2icPfddwPOXK3sBsrd9otf/MJfS5NCwiLcgGgi6nfGjx/vFxuNv3HjxhVkU9D75ubmIavRvqELuZ73s88+603NGuNq80EHHVRQc3ncuHEFAWFCZWWlnx+ac2EwVfrewopxQ420YhSaoqR8KLPDvffeW6CMhbk6tbjomtOnT/fmLsmEQw45BHAuSTo/zM2cjpDWWLn33nu90jcSCCuyhYpGmHc5xHHHHefngDJcPP7443kZMyA3P4rliF26dKkfc4p613hraWnxFd9UlWikoLk7efJk5s6dC+TGUbhhk+KlNaatrc0/5/TcmTx5spdRpYDW1lbmz58P5DYSa9asKagaFK4x6blXXl6eJy/BbVjBVWpTn2ocys0i6wjlm5SlbbbZBsiN57q6Oj8WJGPq6ur6zB0tFxgRG1ncyIZEWNq9EHKbz3TO4/Ly8rzKc5Cvd6VdxZ588kn/3XQ+YhhYBbdo7o+IiIiIiIiIiMgchpRJDVNZaGc6ceLEAopdO9v29na/mxO1HFY50DFp+6tWrfI7IbFoZWVlfrco8+hIMh/rQ2VlZR6THKK7u9vvQrTzbWtrKzDzr68iykBzdG4M9Gxra2u9yVhBGnr+TU1N3sygY6NGjfLMq66hXHarVq3ybdQubfny5X7nq92ixtpmm21WUJFs+fLlvqpUuvrSmjVrhoxJ1c56yZIlXHjhhUD+rhNg6tSpvl26j9GjR7P33nsDcNhhhwG5/rj//vvzgqLAsYgy5epa6u/Jkyd7hlZjorm52b9O76LDCj5DjWL15cGxpzLNazw0NjYW7NLV/ubmZt9ePdd169b5Cilih5XWbK+99vLtVL91dXX539J9iZ2/5557hkyehMxo2hxbzD2jGBRs+MlPfhJw1gQx0H/84x8Bl65MjPJzzz0H5KwxY8eO9fNHcnTLLbf0lguxZmKPXnvtNc9SjzSTKrZw8eLFvh8UEBIGZoaWJ3BjKF3t78EHHwTc2FEflQJCxk9jZuHChb5d6YCp3gIUxZBJ3uq5L1iwwPeVzP6S3VlFaMUFl6JO5mr1V2gx0VgPrXY6T+NJaGxs5NZbbwVyTGrWWFTIrSfNzc2+H2TRhFxbwwpa4ORP2sILvafievbZZ73MkvWlqanJy1ZZcDYEkUmNiIiIiIiIiIjIHIaESdWOtry8vGAHHtbATldCCd+HNaXTzv3aCVRXV/tKGKo73NDQ4DV/sTFZQVgXW+3r7Oz0O6+0w3u4c9Gxrq6uglREYZL3tP/IqFGjRiQFVejvpftLt6+rq8un75Cvyquvvup3YjrvHe94B+CYPfnOiD0uKysrqLWs/+3t7XmpZ8CxLGmGUbvA+vr6vEpdQ4GLLrrIz4nPf/7zQI5RXbRokXdYF6s5adIk3z6xzmIDKysrfSCZ2IKOjg7/vLXrF9Oxdu1avwMWkxYW0Eg/n+EsCCG/0N/+9rdAzgpSUVHh2R/N+/b29oI0Qnrf0tLix576pLW11feJmAKlqbrnnnt4+9vfDuQXMxCDpN/W9Temckp/0VeFOGutf54KWHn44Yd9MQelYzvttNMA+N73vsdPfvITAH76058CbryrSpsKhlxyySWAm39ilb7whS8A7tmIOVXwoyxYkydP7jX4Zrihfttvv/3yAj8gv1BD2u85lI+aH2KF77rrLu+rXApYtmyZH/9hYHJfVja1X5aljo6OgjVI11q1apV/LfkwnBaXgSAM/AO4+uqr/fiVVSq0yKaDoSZMmODPk2VOc2SbbbbxsisrAYTFEPqC6nlJ7v3pT38qqAwq2RnGCYXpQcN0ZUCehVNWCCX1X758uR9PAxkrkUmNiIiIiIiIiIjIHIaEKhHL1draWqBpT5o0yadVUuRgWHYuzfqFkWTSxrWLWbBggd/Fa+c8d+5cvysIazlnDYo+7ezsLIjQ1o6spqbG72xCtiLdR+qPsrKyvKT/gPdnHG4oWr++vt6nhlLkrJ5/Y2MjU6dOBfDlSA888EDvZxiywYL6IRwTet5h2jJB15DPzdFHH51XlzhEdXV1nyzWxkB+lYsWLfKs/yuvvALkfIPGjBnjn7fGREVFhbdCaIev3Xx5ebnvG825cMyoH8U+h/624dwQs6v+E2s4XOUgV6xYwXe+8x0gN8eVBqarq8u3P/RlT+/uQ4TpoiA/+l1WHjHmEyZM8M9GVpnu7m7vCy/GQOzUokWL/Fga7JKI4by+9957gdwzV4qxN9980zOp6qvJkyfz3ve+F8glXdf9fvOb3+TnP/85APvssw/gmHWlcBNLr+jt1tZWP6bEwNbV1fnnIcuE5uvf//73zJRFlW8swNlnnw1QULwilKNhJhmNFfnMqWiDSjuWCpqamrwFRfO9vLzcz5N0gY9169YVrCednZ0F1qwwilvH9DtZXmdDqO2vvfaaf/aaX7JIhf7X+h/KG80XvZ8zZ463cKlQiKwYWUIYp6DnJ2varbfe6nWxsIAH5JdF1fcmTpzo1y7pHjpn7Nix3hqmMRZeYyDp3IZESdWNjBo1qsDcstVWWxVUc0lPBMin6HUNNVodM2bMGC9Qday1tdUrIWEd3qwhdCBOC4mwH0JzLLjJoQmSzuHY1dXl+0bmiZFSUlUR6vzzz/dpayTUVMWotrY2r4oFOAVMCpcmjpSU6upq3zdSNqqrq/2CnD42atQoPy60uIZKraDxt3btWi/IBruCyl133QU4E4v6Q8q6UsYsX768IJVadXW1X2zUrjDnq/oobFM6R6SUqe23395vCvS9sWPH+vP1X0pQZWVl0Y3CYEFj+1vf+pbvA0FzvrW1tcCc3Nra6tubDpLq7u4uyKfc3d3t+yJtiuvp6fHt1YI1ZcqUvEAbyG0a2trauOiiiwD4/ve/P8CWF4eCfb70pS/5Mal5ocVxl112Yc8998w7Nn36dL9ofP3rXwdy6dtGjx7t7/3ZZ5/1vyU5ob6VAjtx4kT/zLW5efXVV72Lyb777pv3/XXr1jFr1qxBaf9gQopTX7I1DA4KzZuAD64M3dNKAWHuac2N6urqgpRBQljlLtzE9rZZr6ioKMjTrXGSdcgsv3jxYm/+lo7wyCOPAI740nkKrlq7dq2XL+pTzdUFCxZ4FyK5xGRRSZVrUGVlpZflGgtPPvmkP65xEroupAMNjTFewVWbdc6yZcs8iSI9rKqqyo+tYkTS+hDN/REREREREREREZnDkDCpoalMuzQxh2vXrvU7vbD6gZBmPKqrq/OqLUGOSaqoqCgwkUOO9cmaA3O4q9duo7a2tsA5XaioqOizr9S+YqZPMXIjBZkAL7/8cu/aoLrAYqDq6up8UIL+h0EPYuRDk4J2ZNrJzZ8/3/eb2hwyCNrlqx8bGxsLdnPq//b2dk444YSNb3wRnHnmmYCr3KKgIDGcCl5pb2/PS5IObqzLTSKd6qWystL3ja5VXV3t2YHx48cDORawvLzcjyO1ubm5uaAyla41e/ZsbyYaCib1e9/7HuCes56dnrl2+StXriwoNlBZWVlghg+tKzovTNuWZibVnmKBWQ0NDZ5VFuOs8VZZWemf12AjrOSjfhCDI2bv6aef9sUdhM7Ozrxk/JCfjk79IWaorq7O94fG1qOPPgq4/hAzqmtOmzbNny+5JevNCy+8MGQuMhuDYkFRgtoVjh2dV+z8LAfEpNHU1OTHjuZUaLFKF2+oqqoq6I+wKl86SFe/ATk5WypVl3TfO++8s58nkhs61tLS4plUsa177703d955J5Bzu9E60dTU5OfoV7/61aFuwoChtlRVVRXIiOeff55rrrkGyLHikjcrVqzwKdh0jYaGBu8upUp+stjuvffe3lJ4xhlnAG7+SH4OJMgye9IlIiIiIiIiIiLiLY8hTUFVVVXld3Ahu6NABTEXYeLqNJtojMnb4UFh2hnIlYC77bbbvD9hOjAmSxArVlVVVcBEaOfe0dHh+0NtLsZaaDfY2dnZZxDRSEGsqv6HPjvahSttRVNTk9/FaVcXMqNifs466ywgf6cvxlDsV2Njow8gE1O7Zs0af42wFrHOGapSunpuBxxwAAcccACQe0byTV20aJH3JZblYd26db7f9Gw1JsKk72IGx44d68tfivH73e9+B8DFF1/s2VV9r7KysqA8sXbJS5cuLUjfMphQ2pe5c+d6P2U9k9BZX+M7LK+n+wpTb0F+0IfGTcg4qw/DdFtpv9t169b568q3MXxG8s/UcxwsHH/88f6/Ajn+9a9/ATnfr4qKCs9iqs3GmALfdaGmpsb7m4XWFfW9fEwV3Pjaa69x/vnn552zfPlyzzSpxKrm2MqVK31/KLgqC9Az1ViQTA2ft9ak0AKl88O+GokUfgPFZZddlheUC/DZz37Wr8maB2GsiNqX9lct9tnq1at9ujMxZqVQfhxc6inILy0uyHq0YMECzw5Kf1i+fDkHH3wwkBsr4dgRw/jwww8DcOyxxw7J/W8MJCtqa2u9lS7UJZSSbjAhedrZ2enXrIHoZEOipEoBC80oci42xvhAmK222grImbTWrl3rFx8pEsuXL/fmXy2mYf1xLSIf/vCHAaekpk2AWYQESG1trR/4GkhhQJkealg1Kl1hSf/Ly8u9wFD/ZR3aXOj/YEPK7EgjFPaaExrrM2fO9P+Vuy6EhIrGQJh3tj+BHe9+97sBp8BKAZUS1tPTk1fNCPJdZ6T4DwVOPPFEwG1cpXhp/Cp3bG1trZ/jEnrjx4/3+TqlwKs9DQ0NXqEKq6hoE6SodJ3/5JNP+kAkBRZNmTLFyxiZt7UohRXUhhKqLqb/ITQepHw2NTV5JaQYZOaX0rk+KPuE5EwY8azAO427qVOnZjJwKo1QfoabnfWdD7mFNU2gZBHTpk0ryPXc3d3t25POdhDOdaG8vLzAxSF0iXrnO985NDc/xHj66acBNw9CBRRyY33nnXf2CqnM/i+//LJfn6TM6vtNTU1et/l//+//AdlUUqVTWGv9s5ReBbk1ReMiTVz0hvQmsKenx8+TMOtH2r1og+59g78RERERERERERERMcQY0jypDQ0NPohK9a6nTJniTa9p03Roug0DXdIMUshCStM/9NBD/XfD9DVZR1lZmW9/utJPMfNLV1dXQXWIMB2MUi6Vwq7/rYSNCS7Z2FRqMtEOVVDYQKGxetxxxxUck+l7sPCZz3xmUK83kkjncRxsKH1VKaM3C0NZWVlBTlRjTJ/5VEsJ3d3dBQFeixYtKnDzkTwKWdOQbRbSTNrMmTMLzgvd0rIIra9aJysqKjz7KRcVWWYWL15cUM1O5n/IMam61uabb+7HmljZuXPnZiZ3cBplZWVevwitZHqWxfJOF5sL6UBDfS90wZTlpqqqqujxft/zBn8jIiIiIiIiIiIiYogxJExqmExYWvgee+wBuNrXqm4iPw85shtjPMsasqbpFFTyKWpra/P+WUoUP3HiRL8rzjKTGgaXpatKadfR3d1dwMB1dnYW+AnJt6Strc33W1gsQCi2U46IiIjY1CCfQcm6sOBHeh2pqKgoqFU/EMYnCygm22fOnJm3xkKOJQxZ19BypzUoHehSVlZW8BtZT831iU98Asgl4F+7dq1nPZVSSmxoS0uLTwUn3aKxsdH7pyqgUcn/Q8iy8cUvfpG//OUvQ9GUAUPPLCxMEOoW4Vzo7bv9QTiGNOc6Ojp8PIH86DcEkUmNiIiIiIiIiIjIHIaESdUuNEyL8uqrrwJwxRVX+AhbRfSK8Vy7dq3PDCDtfauttvLaebizAaepv+Md78j77Y6ODr9rDGs5Zw0777wz4CKK06UwtTMNmWgxr52dnd4fJl1bfcWKFd73qL+RvBERERGbArTuVFZW8oEPfACAG2+8Ecj5C5aXlxdNVC+/RaVCC7MqFGOXsorQf1Cs8KpVqzxTpowisrTV1dUVRP6HbGmaJW1vb/frtnwas+6/qywf8i3da6+9uPfeewEKovy7urq44YYbgFx0f1dXF1/84hcB/DGln2tpaeGoo44C4NxzzwVyKf+yBGXgCDNbKOsHDB4bHrKzSic4Y8YMP57CjAL9hdmIAdbrF0Wr/+AHP/B5Kg855BDA5WocSpx//vm+o+Ri0EtKiMG2eQ+4I2VeUKodpWloa2vzyqkETnd3t3dtkLKuAJQJEyZ4ITsAZKY/MoLYH/kYCh+R2Cf5iP2Rjw3qj2LuTFqLHnjgAcDlu3388ceBXArE/fbbzyusCtgTEdDV1bUxSuqw90foziCce+65PpdtWGkOnFIh5VQKW1dXV1E3CXCBQpdffnne9YsFa/WCTMyXuXPnFlTlu+yyywC3OUkHPf33f/+3dxlQXu+TTjrJH1c+byl9G6DwZaI/IDOugEV/PJr7IyIiIiIiIiIiMoeNYVIjIiIiIiIiIiIihgSRSY2IiIiIiIiIiMgcopIaERERERERERGROUQlNSIiIiIiIiIiInOISmpERERERERERETmEJXUiIiIiIiIiIiIzCEqqREREREREREREZlDVFIjIiIiIiIiIiIyh2FRUo0xc4wxh/Vy7EBjzCvDcR8REaUOY8zpxpgH+jh+hzHmo8N5TxHZQRwfERF9Iz1HjDHWGBPriGcUfSqpxpiW4K/HGNMevD91MG7AWnu/tXa79dxHUSXXGHOKMeYaY8yWyUAb8SLLw9FnmzKSZ60+W2WMud0YM32k72u4YYw5wBjzkDFmtTFmpTHmQWPM29b3PWvt0dbaK/u4bp9KTFYQjINmY0xT0hdnGGOi9Yc4PoohWQ8eT2THokQhP2Ajr3mPMeYTg3WPQ4m34pxJrRdLjDFXGGPqRvq+SgWlsN72OXittXX6A+YBxwWf/WGob64fSucxwF+H+j42BP3ts4wo1CN+D73guKT/NgOWAD8f4fsZVhhj6oHbcO0eB0wDzgfWbeR1s/q8e8Nx1toxwAzgB8A5wGXFTjTG9Ltgdqkjjo9CGGO+BPwE+D4wGdgC+CVw/Aje1kjgrThntF7sCbwNOHeE76dPZHCeZXq9HbQdljFmgjHmtmQHt9IYc39qB7e7MebZZOf/R2NMTfK9g40xC4LrzDHGnGOMeRZoNcZcixM4tyba/leS88qAw4E7gfuSrzcl5+xvjCkzxpxrjJlrjFlqjLnKGNOQfFfM66eMMQuTXffZg9UXvfTPwcaYBUnbFgNXGGOqjTE/Se5hYfK6Ojm/gNEwgVnCGHOMMebFZNf8pjHmf4LzjjXGPB3spncNjqX7N2sTxsNauxa4AdgRwBjzbmPMU8aYNcaY+caYb4fnG2M+kjzvFcaY80wfbiYZx7YA1tprrbXd1tp2a+3frbXP6gRjzA+Tne8bxpijg88985OMoQeNMT82xqwE/gj8Ctg/mSdNw9usgcFau9paewtwEvBRY8zOxpjfGWMuMcb81RjTChxijJlqjPmzMWZZ0i+f1zWMMfsYx7KtSRiXi5PPa4wxVydjpskY85gxZvIINbW/iOMjQCLXvwN81lp7o7W21Vrbaa291Vr75fXI2bHGrVvLkv66zRizeXLsAuBA4BdJf/xi5Fq5YXgrzhlr7ZvAHcDOJmVZNf1kxI0xDcbpCsuSteRc43SJ6qStOwfnTjSOhZyUvC/pdTer6+1gmgHOBhYAE3E72a8DNjh+InAUMBPYFTi9j2t9CHg30Git/RD5jORFyTn7ALOttcuBdyafNSbnPJxc/3TgEGAroA5IC5lDgFnAEcBXh0GhmYJjPmYAnwK+AewH7A7shmtTf3eBlwGfTnbNOwN3ARhj9gQuBz4NjAcuBW6RUE4Q9m/XxjVp6GCMqcUJ2UeSj1qBjwCNuPv/jDHmhOTcHXHMyam4HWEDjmEqRfwH6DbGXGmMOdoYMzZ1fF/gFWACcBFwmTHG9HKtfYHZwCTgNOAM4OFknjQOyd0PEay1j+JkzIHJR6cAFwBjgIeAW4FncM/9UOCLxpgjk3N/CvzUWlsPbA1cn3z+UdxYmY6bL2cA7UPemI1DHB/52B+oAf7Sy/G+5GwZcAVOJm+Be/a/ALDWfgO4H/hc0h+fG6L7HzK8leaMcWbqY4BVG3GZn+PathVwEG69+Zi1dh1wI27tFE4E7rXWLt0U1t2srreDqaR24m52RrKLvd9aGyqpP7PWLrTWrsRNjN37uNbPrLXzrbV9Dfx307ep/1TgYmvtbGttC/A14OTUDub8ZNf9HE5QfajYhQYRPcC3rLXrkradCnzHWrvUWrsMZ7L7cD+v1QnsaIypt9austY+mXz+SeBSa+2/E5blSpwZcL/gu/3p35HETQmLswbHlv8fgLX2Hmvtc9banoQ1uhYnSAA+ANxqrX3AWtsBfJP8TVLJwFq7BjgAd/+/AZYZY24J2Iq51trfWGu7gStx8643JmOhtfbn1tquDD/vDcFC3EYP4GZr7YPW2h5gF2CitfY71toOa+1sXN+dnJzbCWxjjJlgrW2x1j4SfD4e2CaZL08k/Z9ZxPFRgPHA8j4W/l7lrLV2hbX2z9baNmttM06BO6iX65QqNvU5o/XiAeBenMvHBsM494eTgK9Za5uttXOAH5Fbk68hX0c4JfkMSnvdzfR6OyAl1RizhQkChJKP/w94Dfi7MWa2Mearqa8tDl634ZjN3jC/H7exPn/UqcDc4P1coIJ8YT0/dXxqP353Y7AsodSFYvfY33t4P64P5hpj7jXG7J98PgM4OzE5NCWDb3rquv3p35HECQmLUw18DrjXGDPFGLOvMebuxBSzGreDn5B8ZypBu6y1bcCKYb7vQYO19iVr7enW2s1xTPlUnM8dBHMpaSf0Pp+y/qw3FNOAlcnrsG0zgKmpcf91cvP9v3Bm8pcT8+Sxyee/B/4GXGecKfgiY0zlkLdiIxHHRx5WABP6MKH2KmeNMbXGmEsTs+UanOtYo9l0/DVh058zJ1hrG621M6y1ZzJwVncCUEXhWBFDeBcwKlmHZuCINrH3pbzuZnq9HZCSaq2dZ/MDhEh2Hmdba7cCjgO+ZIw5dID3ldbI894bY6bg2IEnezkf3O5xRvB+C6AL5xgsTE8dXziQm90ApO+z2D3qHlqBWh1I2py7kLWPWWuPx5npbiJnipkPXJBMWv3VWmuv7eM+MolkR3oj0I1jjq4BbgGmW2sbcP5zMmMuAjbXd40xo3C7/ZKHtfZl4Hc4ZWSDv76e9yUD46LXp+EYE8hvy3zgjdS4H2OtPQbAWvuqda5Dk4D/BW4wxoxOrD7nW2t3BN4OHIszcZUM4vjgYWAtcEIvx/uSs2cD2wH7WmfWluuY5Eop9ofHW3TOtCb/a4PPphQ7MYXlOJY4PVbeBEjY5+txbOopwG0J+w6bwLqb1fV2MAOnjjXGbJP4Pq3BNbR7kC6/BOcjIhwD3GmtdydYhjOlh+dcC5xljJlpXEqK7wN/TJmEzkt20jsBH8MFDgwnrgXONc4BewKOMr86OfYMsJMxZnfjgsy+rS8ZY6qMMacaYxqstZ3k+hucueaMZBdkjDGjjXOAHjNsrRokJPd/PDAWeAnnR7XSWrvWGLMPTlAINwDHGWPeboypwpn0evPDyzSMMdsbY842uQCO6TjB+Ejf3+wXlgCbJ31UEjDG1CcsznXA1da556TxKLDGuOCEUcaYcuOCRd6WXOM0Y8zEZKFpSr7TbYw5xBizS8KcrcEtUoMlt4YEcXzkw1q7Gic7/58x5oREplca5697EX3L2TE45q3JGDMO+Fbq8um1pyTwVp4ziUvHm8BpSZs+jvOpXd/3unFK6AXGmDEJW/olcmMFnOJ2Es6F5Jrg85Jfd7O63g6mT+os4J9AC25n+0tr7T2DdO0LcUKmybgo9jxTf0I1XwA8mJyzH86J+fc4880buJ32f6euey/OReFfwA+ttX8fpPvtL74HPA48CzyHY4a/B2Ct/Q8uYvWfwKvkdsLCh4E5xpmozsAFPWCtfRznH/MLnAP5a/QdpJZF3GqcG8ka3HP9qLX2BeBM4DvGmGbcQiP2mOT4f+OE8iKgGVjKRqblGSE04wJa/m1cFO4jwPM41mdjcRfwArDYGLN8EK43lLg1edbzccEvF+M2kwVIFpjjcCa4N3CsyG9xDv3ggjZfSMbVT4GTE9ebKTiBuwYnmO8lf1HKIuL4SMFaezFOoTgXR1rMx5kub6IPOYtzkRiFGy+P4LLFhPgp8AHjIv9/NqSNGBzEOePwSeDLOBP0Trggsf7gv3FM7GzcmnsNTpcAwFr77+T4VFwmAX1eyutuptdbY22mGegCGOd3tBjYOtlBD+QaW+ImZaXNYJRdxMYjYc+bgFnW2jdG+HYiIiIiIiI2SQzleluKlSjGAecNVEGN2HRhjDkuMfWNBn6IY03mjOxdRUREREREbFoYrvW25JRU69KIXDLS9xGRSRyPC4hYiHM/OdmWmqkgIiIiIiIi+xiW9bbkzP0RERERERERERGbPkqOSY2IiIiIiIiIiNj0EZXUiIiIiIiIiIiIzKG3Ch39wUb7Cfz1ry6L1DHHHNPneatXuxipf/7znwC8//3vL7yZxG3B9FqiugCDndNro/vjgQdclqnnn38egOrqasrLXeGTbbfdFoC2tjZWrXKliQ844AAA/37KlCk0NjYO9OeHvT+stQXPq6Ojg7lzXcGPnp4eAFaudMVS1qxZQ2dnZ975PT09VFS4YaxrjR49GoCZM2dSWekKoUyZUpjLuavLJXbQ91PI3PgYYQxFDryN7pMf//jHADQ3u5zaF198Mfvt5yoRvu997wPg9ddfp6rKpf3UXJkwwRVOOfPMM5k0adJAfz4zY6Q3+bdy5Ur+9a9/AbD55i73dltbm5cTe+21V8F1NkCGppGJ/uju7vZyM40VK1bwhz/8AYAddtgBgJdffpk333wTgB/84AcD+cnekIn+aGtrY/bs2QC+nd3dLq1peXk5tbUu5/2///1vAN797ndz9913A7D99tsDUFbm+Kz99tuPmpqagd5/JvqjGK691uXcf+aZZ6irc8XZ9H/FihVeB7ngggsAGDNmUNKfZrY/RghF+2NjfFI36Iuvv/46AD/60Y944oknAHjjDZepQAtGeXk5u+22G5BTUF566SWWL3fp+nSvs2bNApyQufDCCwFoaGjw39OEWg8yN0A+9alPAfhFZYcddvD9tvPOrpjMmDFjvFL1kY+4Ih8dHR0A1NTU8Pa3v32gPz9s/VFsQb3zTpeecN68ecybNw/AK6stLa7ybk9Pj198pHx2dnb66+gzPf8xY8aw5557Arkxs9VWW7HlllsWvZ/UPY3o+GhtdUVTbr/9dr/APPjggwDssccegBsfc+bMAfDK+9ve9jYWLnTFdNSnEydOBGDPPfdk8mRX8fDd7343QH/nCmRMSX388ccBOPDAAwE45RSXZ7q6uppLLnFxlffff78/R3Ll8MMPB+C3v/0tAJ/5zGf4/vcHVOobRmiMSDb259mdeeaZPPvsswCMG+fKt48fP561a111Zi3O6/u9UpCpffWLFLDTTjvNy4mDDz4YgEWLFvm59eUvfznvf97NlBgR8t3vfheApUuXsmKFq1ipzcmiRYsAJ0OefvppAP//D3/4Az//+c/zzpfS+tnPfpa//92lEz/vvPOA3BzsBzKx5i5YsMDPCSnr3/ueS5vb2dnJLrvsAsBVV10FuDZrzW1vdxVXNXa22WYbdtxxRyBHjmwAMtEfGcLIKKkPP/wwAB//+McBmDNnjt+J1dfXAzkma9y4cYwf7yprSYg2NjZ6JUyLtYRtQ0MDhxxyCOAGEriB0k8hnrkB8ulPfxrA98/o0aO98NSOdp999vHCZPfddwfwimlZWRnbbbfdQH9+yPujmJDXIillfP78+V6AjBo1CsgJ1MbGRq9sPPbYY0BOyECOcd1ss83893Vdsc7HHHOMfz1z5sxe74sRGh9q6w9/+EMAxo4dy4wZrkpfU1MTkGOAOzo6eOqppwDHMkP+giHFVYppeH0J27POOqsoy1wEmVJSX3zxRQAOPdRVXpYsOfXUU/2YWLp0KeBYVvXLFVdckff9yy67jA9+8IMDvY3MyJCXX34ZgDvucPnFpZR1dnZ6i5XkaE9Pj1c+jjrqKADfB4ceeqjf8A8AmemPX/3qVwBcf73LPy7FtKenh0cffRTIKRXWWr+Rk8Lx0ksvAfDe976Xr3/96wCejd8AjEh/aPx/4hOfANx6KUuDnvddd90FwBZbbOFlqRTZiy66iBtuuAHIrTsaV4cddhh/+ctf/HUBrr6633n8R6Q/nnvOFduSJXbdunV+/Gu9fOGFFwBHEInYGDt2LOA2dSJMJGfEsi5cuNDrG1qvzjjjDP96PRi2/gh1opBFT0OM8dve9jbAsfAiEdVn06dP52c/c3Ut1EeDhKL9EX1SIyIiIiIiIiIiMoeN8UktQJqRamlp8T4wYnyWLVvmX2v3/6EPfQhwOxZ9V2b8ww8/3O92xK5OnTrV3XxFhd8pf+xjrvLb9ddfvyEmzExAvqjazcun7umnn/YsWNgm7eL0WVtbG1Dc7zJLSI+P+fPne1cOsel77LGH37WeeOKJAP6cmpoaPv/5zwN4drG8vNyz7+vWuYpsYk0qKyv9LvCZZ54BXB+LKRKTqvvZSH+8QcHtt98O5NwTRo8e7duv+xVr2tnZycknnwzkdvizZ89m8eLFAN7XbIsttgBgyZIlfmypj2+55RbvZlJKEDOQtgRdfPHF7LrrrkDOB7Ozs9Ob9GWlEIsghqmUIBZcJukXX3zRj2mx56GFYZ999gHg1VdfBZxLhJgSyVRda+LEiV6+ysXoC1/4gp9jWcZrr70GwDnnnOPniNjPkAVVX8k/uaWlxc83Ydq0aYBzsTn++OOBXB+9613vGqomDAo0pjU31qxZ49dhtV1WmQkTJngGVevP888/7+WxxodY5yVLlnhLjuZgltHc3OwtCZKf5eXlnumUW9Xee+8NOB9tWSG0vq5YscL7rauPtE6EjKmsVL/+9a/5whe+MHSN2gAUs5QX049kWdppp50AOPLIIwFngVQfyVL5+9//3lt4Zd0WNsA1qN8oLW0uIiIiIiIiIiLiLYEhZVLfeOMNHnroIQDuu+8+wPk+vec97wFywRtiNdauXeuZjtNOOw1wbFt69yLN/rLLLvP+h9oJLF++3LNnA3B0HxGoj7RTUXR/Z2enZ8PCtusz7XIVPFNeXu4ZgCxBzyG9w1qyZInfiWmXW19f7xnRiy++GHA+MOB2rWJS1WZrrb+uWPXPfe5zAGy99db+WmJeW1paPNNY7D5HeqyISZWv9aRJk/x4F/shVqiystIzxJpDEydO9MypfMb0vcbGRj9m1M5nn312fVkOMo00mzNp0iT+85//ALngqsrKSu87pX5S+8VSlxJkeZKs3Hnnnf0cU9Sxxvgdd9zh59ZWW20FOFZM7JLm1gc+8AHAsbRiY2Xp+uQnP8mNN944tI0aBMjPcsWKFd4CJVZRcmDq1KmeFQzZxW222QbIzRXNhcbGRn8NsUdZZ1LFEGv+W2s941ddXQ3k2PjGxka/vqqdHR0d/jz59GusrVu3zrP0kiVr1qzxlpysYc6cOZ491v/u7m5/75IHGh/Nzc2eTZRsqaio8My8ZHHozyn5KbZ1+fLl/nrqx5GC5FxoLSymF8m3X9YnBd0Ww6WXXsrWW28NwLnnngvkAs+GwoodmdSIiIiIiIiIiIjMYVCpkzQL1dDQwDve8Q4g5ze52267eU1+yZIlQC5qbM6cOX6XKx+o+vp6f135zujYcccdxz/+8Q8gF+G+cuVKz6SWChRZmPb7Wrt2rWdGtINbvXp1wc5X/ZlFFhVy/nFppm7hwoV+DChnoTHGv37nO98J5CINv/e97/Htb38bcH5nANdcc41nBX7xi18AOf+p1tZWf0yYMmWK9+lV5gmxKBMnThxR9n3ZsmU+PZbYkLKyMp8jVyyP7nH06NEF0cjhGAjZIHAMiRgBYezYsd6XSqxaKUAsh8aW2L+QNRLjXIz1SMugUsHs2bN9u/S8qqurvXxVf4g9veCCC7yvpo51dHSw//775103ZH5kqZEcnTt3ro+QVnqeLELscXV1tc9kIFkgK1VbW5v3Wda4nzx5smcCNcfCdEJ6nZYlWcXll18O5JjOzs5On8ZP6f00f15//XW/juj/woUL/XlKE3nEEUf4Y1qT1KfXXHMNZ5xxxtA2aoBobW0t8D81xhRkagiZRvWVPquurvbyRZ+JMezu7vbzSp+tXbvWs/SyXow0woj+9P3+/Oc/93PnsMMOy/te6GMaWtyUWegnP/kJkGNShwJDqqS++OKLPkhqwYIFgFOytLDKnCRH/aqqKk+Zy7y0ePFiTjjhBAD+9Kc/Ac4FAFwaIpnxROVfeuml/OhHPyp6P1mFFlEtClKiOjs7vUBQ0MPKlSt9GiaZvKW0SjBnCaELhxDm7NPzDhVuKVeaHEqHsnLlSq+kCs8++6w376v93/zmNwHnHqDFR+mIlixZ4otHyGx35ZVXAi5QSxNRwVfDCc0RyCkN8+fP9/eisa7/HR0deWlBBAlgCdtQoMq9QteYPn26V9RKSUmVIqWxIqWzu7u7YEEJXUIkoHW+NgOlgvnz5xe4PZWVlfn+UDvTaftCTJkyxY+vtOJVUVHhvxvKk1JQUpctWwa4uZvexEi2rly50m+CpdiPHz/e95v6UfOqra3NX0PrTtah9USplHbeeWduueUWAG699VYgl4rqiiuu8G53t912G+BkpeTmQQcdBORcKY499lhPpigVYpaD6tasWVPgblZRUeE3HhrjoWKqNUDrcBhopfkSji+tXZK79fX1PjA1K0pqKAvTZJH0KoAPf/jDecc6Ozt9u0J96jOf+QyQ09NUVOWss87qk+hRv6XdEPpCNPdHRERERERERERkDkMSKaGdyDnnnONNqTKtXHjhhZ75k2lSKaaWL1/uWTalxQnNLjJRKWXTlVde6U3lxx57LJBLNVRK0E5MTstilpcvX+5ZLqXI+OUvf+n7RMEBCh7LImpqavzu85prrgFySaZ/+9vf+iCfsNypmEMlDFbbb7zxRr/bVwDVhz/8YV/+UmzPN77xDcDtnMUqaMf85JNPctxxxwG5AKuQQRwJBlV4+eWX/W5f5qL6+nrPhul5i0EbPXq0N7nJQb+trc0f19gJ06WkzdszZ870u371cykgnYYtTFatZx6mYdpU8Oqrr/oxGqYHSjMSYXCdXDzEHIYFT9Ilha21fq6ELKvM4FmGEpGXl5cXMDYaJ2PHjvUsshLVb7311l7+pAOAwsA8zausI21tglx6LpnxJfNqa2u9FVKM6NSpU71VR+nLxMS++93v9mt6KaC9vb1ARlhrCxhRWfuMMX6eiBEMA2olU8LUUzKVay2rqqrKnIUmtLBINmgs3H///X5NVhVLIQz8Ct2m5BagflMg5llnneX7KnQP2Bg3usikRkREREREREREZA5DwqRqd/7b3/62oI54uLNJl/BsbGz0fj9ikrbddlu/e3nllVeAXDLzuXPn+oTTn/zkJwG3KyillDqdnZ1+Fy//Fe1o586d69lm+Qb9+te/LmBXtUtJ+35mBfIpVjsV7Lb//vv7koMKGBo9erTfpYoRUFDQbbfdxle/+lUg57Q/adIkTj31VKAwCMYYU5CaZ/78+Z45/L//+z8AfvOb3wAuZdF///d/D0aTBwSlToIcK7zffvv5exebpR1tT0+Pf615VllZ6Zl27Vq1c54yZYpn3+TjvOOOOxb1W8w65EMmVkxjv7u7u+huPZ3UekN8orKExYsXexZZbE1XV5eXE+mUdeXl5f75y1JTUVHh+02yUud3dHT4eSrmsK6uzvd3lqF0YqNGjfKWO82F0OdUlivFRlRUVHj2LO3r3NTU5MeWjpUiJHPVH+oDY4xfXzVOVq9e7eWEWHv56D722GOeSS2FFI/t7e2+zRrrbW1tPj2XmMKwCIaesywKoR4hWayxVl1d7eeSfqelpcX330gjXSI+DBgLrc5aAzcUSu0Ypn+T/hIWhCj2+/3FkGhxYVCClE1R4rfccovPgSpndgnDmpoaHzWmhbO5udkPGgkSUc2//vWv+cpXvgLknLhvueUWX1WnFKL8m5qaCqLnJDSWL1/undr14FevXu3dAcKFBXIm0Cyhvb3dK1C6vy9+8YuAywerTYkW0KVLl3oFVN8TvvOd73ihctZZZ/nP5f6h5y5TVllZme/bMM9f2nT561//GnATeiSV1FWrVvn2SSkITYxSSPU/rMOsOTdq1Ci/ACk4SteqqqrygkMC6uSTT/ZCtpSgQLi0Sd9a6z8rVhEnrayWmkvAypUrvaDXQtvc3FygREq5CIPGdE5oqtS1tKi2trb612EwVlYW3b6g9aGhocGbczW2JV9aW1u9LJCcGT16tO8HyVL10erVq/2YkaKWdRRTHvWZAlV1rKmpqaD+ejGZo/6R8g+5+VWsBnxW0NHR4ce/xkR3d7d/zmqD3nd3d/vxUYzk0jU0l2pqavxmUWOmpqamIIvKSKFY3tK//e1vQM4trqamxgfZSe+S68y0adMKzPerV6/2a6zml9xkjj32WC644AIgF5hcjDzbkA1ONPdHRERERERERERkDkNqD9988829OT5Mb/GXv/wFyGnav/3tbwG3q1MqA5mBx40b5/NlKlWQTMNtbW2eVRQjstVWW/ngq1JgUlesWOHZM+0u9L67u5spU6bknT9//nx/XDtg7Qa108kSrLXeDK8dp0wmzz77rN+Fi2mfOXOmfy0Wea+99gLg2muv5aabbgLweflGjRrlq42lqylBoXmhmDn4pJNOAnImsZFCWE1MbGh5ebkfx/osDJxS+7SjfeqppwpS7Gg3XV1dXdD2BQsWlFyuUMi1ty8mNAx8KFbDGui1+lhWsWLFCj9/xNysW7fOP1fNgZCp0GuNh8rKSs8caf6J+enu7vZ9K+bQWuuZlSwjnP+Shem8uKNHj/ZySHK0urras2aSpeqDtWvX+n7Oslm7L3R2dvrgKPWDmK+urq4Cd7GWlhZv9RLbLJkiVynINoMqhHl/xYKWlZXlucNA7tmGQYgaA2FuUfVV6Pqh8/RZa2vriDOpch275JJLALjuuuuA4vJu1KhRPlWooLEgmQG5+TJr1iw/T6SDaI68+eabvnrVAQccALgAell2jjzySCA/UHN98yoyqREREREREREREZnDkDCpp5xyin+txPOqXDF+/HhfHUpOt+effz7gKgBJg1clg7a2Nl8nNp34/WMf+xg//OEPgZxm/tRTT3HHHXcAcO+99w5B6wYXr732WgEbpiIHxZKrH3LIId4fRrsZ7dqymFS5trbWB3Vo1yW/l3/+859+Ry9fp3B3LpZcTOlBBx3kA/Aee+wxwI0ZpaNSGjJVOauvry/wh6murva/qaT+X/7ylwG4+eabB6HFGw49vzFjxvjdqtjSjo4OvyvWLlgVczo7O/2Y0Vh45ZVXPPMs5375b9bX1/vdfug3LqZV95HVOtwhJAOKMalpP6zQN1XtFnMW+tiVAlpaWvw8F3PY3t7u51aYsBzcfBIbonnY1tbmZU7IlICbr2LWwxRXYYq4rCL0w1V/aOzr/5QpU/yYkU8vFDKuutbee+/Ns88+C+SnOxuKGuVDhVWrVnm5mq5g2NzcXJCOqbOz0/eH5pnaWyr+67rPzs5OP8ZDv1ONAf3X8+7p6SmokBgmwNc1NH+6urryWEF9r5g//HDhkksu8QHGkulaB8eOHeur0SkgGXLp2MJUXODWS7GksqzU1dUVMMpPPvkk4Cw9hxxyCJDT+T760Y96a6Dikc4777y83+kLpTPTIiIiIiIiIiIi3jIYVCZVzI1qrX/mM5/xvhCqq77PPvv4iH/5u8jfqaenx5f61E5Yif8B9thjDyAXJf773//es6vyMzrppJN8ybdSwKpVq/wuTe0Sc1aspNree+/tGQ6dr6S8WU1BpftSsmPtupYtW+aZLO3WFi1a5HfxKof6xBNPAHDuuef6MSM/ZcjVqpZfjbICVFRU+HEkVnbhwoU+0jft46lUWcMNjd3HHnvMWw20U+3p6fFJ/LV71/uOjo4C36Cmpib/mdqp71lrvT/3888/739b39V9lAKT2lti9WKJt2tqagqYQDFDpeaTaq0tYNsbGhr8nBFjFvrTqa1hiqZ06djQD0/na37U1taWRCJ7ydGuri4frfzvf/8byPfVFWumcR4WLVC/qI+nTp1a4K8XypBSQFdXl5/bYuFDf22hWPJ6rdX98QHPEsR4hsyvxnNdXZ1fb9LnyXcX8rPtaGyFDC3kzy/1zbp160aESdUcPfPMM/39iv3U+A8zX4TrSjrLh1BRUeHHjtrU1NTk+0lWXc2lHXbYwV9j22239edrbCnyPyy4k06TlcagKql6qMoXNmrUKL71rW8B8N73vheAQw891FPEUjCvvvpqwKUQkklKimtFRYV/+PqeBM+0adN48MEHgZwJ+eKLL/bUtVItyFk3i1i8eLF3e9CD1mSSs3qIsC5wusa9TDlZg1w+NNglAJcsWeKVVE2Y6upqP7E++tGPArnnd/755/Oe97wHyLmUPProo75+sKqiyNw/YcIEb6pTbr+Ojg4/idR/cq9Q9bLhhpSHKVOmeKVJ5pHx48f7/kgHgRljvFIic2Z7e7sXwOka1BMmTMgLCNH56gfdh8ZjlhHWlYd8k77GV7GFIh0wMdIBDv1FGLgh+aDne8ABB/g8hZKpOrZ27Vq/oIY1zDUOJDvUH4sWLfKBDw899JC/VqjIZQ1ql9rZ09PjN6WaM2EeXSmpkj319fV+zqgflKbuHe94R161HnDkSpaV1LQJta2tzSuneo7639XVVRA0VlZW5vtLskem21LJFRua8dPpxUKdQgj7LJ0KMsxHXaxCW9o9IKx4NpyQm2NlZaXPQS/XHY3nrq4u/zp0T5A80NzQ/5qaGr9+qA86Ozt9m9Wn2tSNGjWKZcuWAbm519DQkLfhhdxafcIJJ8TAqYiIiIiIiIiIiNLDoDKpMiHKITdM/SJ2tbOz0wfCyPwrNmPhwoUFtdNfe+01z4JJ45YZ/L777vPnKXXV9OnTiwYcZRWrVq3ylU/SNYPFioQYP368N3lrNyPWLaspQVQX+KqrrgJy9zt37lz/7PV///33998TCyp3hrq6Or87u+yyy4B805RM2ccffzzggohUe1osS0VFhTdViE3UNZ988klfXGA4x5BMJlOnTuVf//oXkGPVp06dWlCLXmadnp6egl1oeXm539WmK1R1dHQUFARYtmyZt15kmS1Loy8GNB3IUCxwSu1PBw5lFWI6jDF+LEum7rLLLj7FX9psF6agkltHR0eHl7M6L2SW5Vb1+OOPA4UFELIGzZ+QHZM1QP2h/2VlZQX9Fwa6iA0L2bF0+0tpnoAb4xrnChaTVausrMyPhbAYgiwzGgtiwrJqrUsjvZZCjvWbOXOmHzM6L6zip/PE+oXMof6Lbe3p6clLiQlurImJHs7ql5LjnZ2dzJo1C8Cn4xTa2to48MADgdy6OmbMGBYsWJB3nxrjzc3N3sqgeVNZWenbpbVG51dWVnq9LnSpkOyRbqg0pJFJjYiIiIiIiIiIKEkMqnqvcqX6D3hmSvj0pz/tX6uU6WuvvQa4Xb9YtkcffRRwmrx2BfpMdc2fffZZvyP8+Mc/DpSOz4xQW1vr/Ufk9xPW006XDxs3bpx3Zk87+YsZyBr23ntvAO6++24gt8MaNWpUAZPV0dFRUJdd7zfbbDN/Xsgmanf/hz/8AciNhXHjxnmWWqxiR0eH71NdX99va2vzacuUKmM4oD6or6/3DKGe7Y477lgwh0LfsXSKmDAZdTqtzpo1a7wvnc5pb28v8IUuBaQZgpA1FSvSFwPYn3OyBPkLV1RU+LEhP8Ntt922KHMkaGzoe8XSSYWlUxV0FDIcWU65JFlQTD6kfe16eno8eyyWcOXKlf78dCL35557zn8mlqkUgshCLFy4MM9fF/J90oXQt1fniRUTg9jQ0FCwJvUnIftwIxzjevbyrdxss828LiGGPQyM0mt9r6Ojw8+vtJWqu7vbM5OSn9XV1b7/tHYNR0nd0Aqp4OG0TrDtttv69VexO4BPS6U1Q+MiXE/Up42NjQWFc7SGTJkyxbdZutmCBQu8/JCFUlbVX/3qV3llmothSDno7u7uPGdbcKYpBVFdf/31QK7iVFgHV8EvlZWVXkCno6+VRQDyldMNqQs70gid9kW/q1IDFLZl66239gMkXYM+iwgd85XP9JxzzgFc9LnaHpoXJDiUT1dmjOuuu85vbGSeWL58OR/5yEeAnMDRRmfKlCl5ASTghK5MD6FyCG68KpJ3OJXUULhJIVW/1NbWeoEnARm6dWjca4PT3NzsBYL6IzRV6bWc26dPn+7dR9I1vLOMtKJQTDkLP1Mf6n8oG6SQqH+zCAWSlpWV+bEsJbW+vr6g2pyec6hwSI7W1NT4MZJegMLP5BbT1NTkr5/FvgoDXMDNCc3jdABLR0eHV1YefvhhwMkXySgtsFrcly1bVuA2Uiq5QoXFixcX5EcNMxuElZggP/AnLSt7enq87CjmjpY1dHZ2+nEvWTlq1Cj/DGWWD91BRBSEzz0dtKr3q1ev9uuTAnDDoE7pM8OhpIZQ+0RKiAisrq7m9ddfB+DVV18F4MADD/QuCwpK1/1OnDjRry163osXL/bzRP2n+fPMM88UuIY888wz/r60Nuv6v/rVrzjrrLP6bEt2t8cRERERERERERFvWQwqk5pm/UITURjcIlZA5haZ7sJdbhhApdfa3YpJev/731/wm2Ft9lJgUisqKjyTJYZEbNp+++1XkEOssrLS59LUzk2sxr777ps5d4cw8ED3KSb1kksu8fernfp//vMfv8u/+OKLgdxu8O677+af//wnkJ8P8utf/zqAz7H7zW9+E3A7YO3wwsA97W71X/0J+VU4hgthTrt0uqnu7m7fRxofYfUXtStMASKoT/X9rq6uAsYtrFqVZguyjN6sCKHMCZmQNNMaygYxLWJEsogwfY7YMLmyhMfTNcbLysr8M1fO6XXr1vn2a4ykg80gZx5dunSpv75YpjB/9UhD8yLMFZtmzzSvOjs7/flhcJTaL/ZHbNCkSZN8Oiul8ymF6lshFAQFOZkn14iwYpIQpunTGAitTbpelpnU0NUpDAgDtxakP5P81FoMOVnS1tbm+yGdRzScS5Lja9as8etT+vyhhBhSyFnKQhcYcBa3I444AsBXJmxpafFsqfpDgYdtbW1+fdBzDy0Pap90kaqqKs++aw7OmTPHu41oPqq/b7zxxsikRkRERERERERElB4GlUlN78jC99qhV1VVeS1cqajEYJSVlfkdiLTwhx9+2PsxyDFYTOxWW23ld7WhT0kpMKhCTU2NT8Kr3UVYTzydVmrp0qW+b3baaScgl6oprJaRZXz/+98HHJOaZi5WrlzpWTI5V2vXu2TJEr7yla8AubYuXrw4z2Ecck7jM2fOLAgQWLhwYUFglnz7Ro8e7Y8NJ3QfFRUV7LLLLkCOsQpTl2gOidUKg0DErlVUVPjjOj9kT9XfYo8XLVrkd7kjWW96QxEyHr1hfX6qQikEwmj8GmMKKrqESCcp7+np8c9V1wh9kzU2xBqF/TNlyhTAyWnJV83NLDGp6Yo44RojuSJrTHV1tZ/jYpKampoKmEPNoQkTJnhWSTEDWQ4iK4ann37ay0s99zBgNUzPB/kFQdJFH2pqarx83XnnnYFsWizVptBfOwww1ljRc9bzb25u9uM+ZNp1XrpQyKpVq/zcEFvf2tpawDQOB1TQCHLWaY1ntWnevHm++I3kXmdnp3++0rX+8Y9/AG6ea30UW7rZZpv58SFdRH01ZswYz7hKPu26665+vKV9dJW2tC+U1myLiIiIiIiIiIh4S2DoM8wmCNM5SMMWqyO/iZ6eHq9pK2ps8eLFPlVCOjJxr7328oyKdgphCppSQFh3W7t+7WagcJdaU1PjI1d33XVXIFeXPos7Wij0Vdb/NWvW+PRbant7e7t/zjfddBOAT3C/cOFCz+CoZOOxxx7rk44rFYgiFSsrK/1va1y1trbmlWuD/Oj34Ui63BuKJdsPy/ql05p0d3f7OaT7rqqq8n4/aVatra3NMwIqQ/v666/78SMLRSkgZBahOEOaTsEVIpwr6RKrWYTaO2bMGO9vFvrQ6rgYpDDiXf0gdr6ysjJvfIXnh2NG8uXqq68uSOWWJWg+6DlPnjzZt1myMvRX1ThXW0JmNB0D0Nzc7K8rRin08SwFLF++3PuPpp9zRUWFZ/vENLa0tHhfdx1TH9TU1Hjf3CxDDLC11st+pT8K2XStFZKfdXV1fv2RXOjs7PSMpMaFdJCmpiY/59THsmwCBTEAQwn5lYa/Kz9VrQk1NTV+7osNraqq8u1Tv6joQ1VVVUG57ObmZj8u0tkRRo0a5dckjbEwTkLrvOZSf8bSsKWgEj7xiU9w5plnArkO1IJx4okn+lQJqio1a9YsTw0rlYE65oYbbuCoo44CckpqqaGxsdFPCk0Y1W8vBmutnzwyu2jyZVVJ1WDVBH/llVcAd78a+GHteQ3yb33rWwC85z3vAeCee+7xbfzqV78KwAc/+EGfh/XCCy8E4NxzzwWcOUrXktBasWKF39hoIko4d3Z2jsg40sQNzc56xk1NTb7f0gKvqqrKL6ppYRQi3BzoWWhe1tbWFtRhLgVI4Spmek0rrutTUjXfZL7MIjR+w0CNsB59uq3ql9CFQwENxcZZuqoZ5HJklpWV+etmsdpSOp1WdXW134SF/QbOfBnmAwWnqGveSGnXOW1tbey2225ALqgynbc46xg3blxBhbVimxIpam1tbb7Ko563+qeiosJvkrIMtau6utq3WZvx0CVQsl8yuKOjw8+rMLduuMkB8lIn6rekeFVXVxe4BQwHwsBXtUEpG6WEVlRU+LbqnJqaGv+c1T6Nha6uLt++YiSG5lDoLpFOa2eMyRs/4bH+pLKL5v6IiIiIiIiIiIjMYUiY1GLMhTTtcePGea1eNPwpp5wCwMEHH+x3rWFKEJlllNxdu/+2tjZvLg5/u5SS+W+11VbeIVnO/drhFENZWZnflYRpabIM7UhlSjj88MMB2GGHHfyuTuaTmpoa7/Stdsns/6c//cnvFsWannbaaZ5hVyUyBWYtWrTIs0cyXZaVlfnd2w477ADknLiXLVtWNBhlqKEd+AsvvODvTQFUq1at8n0jRkDPfdSoUX5HH5prNP7T46K8vNzPQ13/6aef9g73skqUAtKpk9Jm2hDF0tKFFp6+LBdZg7W2gC0Pmb0wFR/ks0b6H7rBhDXLdX1BrjVhCq8sMqmyKMksuXjxYm8R0dwO0xiG6evAsYSSTTqmvuro6PDX0PX7E7SXBaSr10HuOYdWGb3WutPa2lrANksuVVVVeUtYlhEWs5C8DF0C1R6NCz3Turq6goIfofwIrwtO3opZDl3XtE6lKyoOJcLfSheg0H2vW7fOP++wIEGaKdbYgdw6EsqR3nSriooKL4P1m//5z39838uyKVa2P4UxIpMaERERERERERGROQwJBVcsmb92afvvvz9f+tKXADj55JOBnK8I5KcRAVemS7sW7Q60w997770LdvZZZxXTmDRpUl5JUMjtZpqbm/3OQ+jo6CjYjWSpRGExXH755QB84xvfAHIO2LW1tQXBYtZaz4yk/UNPPPHEguTEN9xwQ0GAUOjbK5ZJ42/y5MnesV27Rd3D2rVrvX/rcEL+c21tbd5fUBaFMF2Q2hCmNdEOOEzLlk4bI1RUVHjWUP6Ga9eu9UxDus5zlpGutS4US9wfluaVfAmZ1FLwsdNz7u7uLii6sHz58gImNPQ91mvNhfr6+gIf1LA/0kERZWVlmfZXVnls+a4fccQRvPDCC0BufGhOhO0Ix0K6fLdk6rJly3yJ7tNPPz3v97IOyYTy8vKCORGm2kuzq+vWrSvwUw8DjRTImmWEgVMaz9IbwsCwdHBlQ0NDQfB2WVmZj1/QdWW52n777f16LHlbUVHhGdrhLPwQMqmh1aQ36JmGwbbF0oj2J+VaaL3W+eqX8vJyH6Ss/lC/94dpHlKNLmywbq6srMxHY2tx1sI5ZcoUX5NdJtADDzzQKxFXXnklAJ/73OeA/EoJMutaa0vCzC+MHj3am3PffPNNIBd1Pnv2bK+sCB0dHXnmXuh7II40fvSjH3HLLbcAOZO7FIz29vY8h26ABQsW+E1LmPcN4NZbb/UKqNDZ2ekXJEE1icNzlXv2lVde8ePoRz/6EUBe7tVjjz12gC0dOPQ8t912W/72t78BuUwFXV1dXimR8NRYX7FihRc0GgMzZswomPgSIKFZU0Jp8uTJfoNQSjXJZXrtbyaPtAkvRCkoqVI4rLV50bLglMp0gEZomtOioejj1tZWvwAXq8SlTaKCVxsbGwvMh1mCcv4qYBJykc5pZWH16tUFOWLDSmySQ+qzFStW+Pl2xhlnDGk7BhthMFA6F6pc6MJsKmEgXjrYVTKorq4uL/tM1tHR0VEQTFhXV8fcuXOB/Fyh4OZSsSqWkjdpUuyNN94oKjfTJu/hQEjqhJkJ0veTHuNdXV295nMNc9eH5GMxckBIB652dnbmZaSBnM7Xnyp/0dwfERERERERERGROQwpkxqymtLGly5d6itNpVMBLVmyxGv02rn8+9//5uCDDwbwptibb74ZcIEyCpb54x//CJRGsFQaYeoKyLFcr776agGTWllZ6XOLhRUusop3vetd3H///UDh7q6qqsoHSel5Q44plEn6ne98JwB33HGHZ5He+973As70pjy6H/nIR4BcAFpoFlWfTZgwwZsFxbj+9Kc/BZzrwEhATF53d7cfC+qDNWvWeEYrTIkCbkcr1lRtHTNmjO/ndDqdiooKP9c0H/fff3/PKoipLQXIZUQm7N6CxcJjkGPPQma1FAKnQjNZ2poQsjV69mEFqbDan66V7ocwhVWaiZ80aZKXMWFARVaQDvKpqqoqYLDClFzpdF3hZ2LFirmFCMVSK2YR4bPSs5eZWyzrFlts4dP/yTw7bty4PBY2/P6iRYtKYo3V86yurvaWyfCZKdWl2plmF6FwLoUQo9ra2lowFrq7u/1aXiyIfKgwa9Ys/1q/r3sv5iIWojf3hLBi3cZAup7Warl8fvnLX17vdyOTGhERERERERERkTkMKpPaV+onsaft7e2ccMIJQI79FLszc+ZM7585Z84cAB544AGOOeYYIOfoK3+aGTNmDKvPx1AhnXhaCNlFwRhTkD6mr5RVI4099tjD35929nrGr732mveTk3/oF77whYKE06rvu9lmm/ldnRjV2tpaP360G9T1165d63eSYqTPP/98fvzjHwM5Rj7NTA83xJyPGzfOWw20+w+frXb76pfp06d7FlYsyOjRo/04Sleqqqqq8nNTDPbYsWP9Z+mAnCwjveMPmQD1UzFf7bSvXU1NTSarKKUhX/1169YVPKfm5mYfUJhmScJE/GLKw35JJ/3v7u4uYI6qq6u9T+xwptTpL4qlFdOcKpZiS7JDx6qqqny70il7ivnM9SeQJAuQb/Hq1au977/6RTKvp6fHs4lqV0dHR0GFpTD5vZhXpU4UO5YlqJ0tLS3eOhVCwbyyxBTzWRcbGa65oZzV+7S+09DQ4MeT1rfhwL777gsUZ2+ffPJJAPbcc08/LsQmv+Md78i0ZaA0ZltERERERERERMRbCoPKpKZ3FKFPqtjCiy++2DNd8nOaN28e4CK+5Aci5quxsdH7U4hdVTRnTU2Nj4gvZag9d955J5DzxZSvYIgFCxb4XZrarhJ2WcVpp50G5FJQaYe65ZZbcvfdd+ed++53v9u3S89bDGyYNkW7f8j1l9hB7QobGxt90vqZM2cCro+1C77nnnvyfnukfM2OO+44/1oM4Xe+8x3AMVdPPPEEkOs3sau1tbX+fsMxUyxhNziGRMyIdtOjRo3ikksuGfxGDTHE7Ik1lYyoqKjwrGMxyJ9Tc6izs9MzQlmGmK/m5ua8sQ+uyIki28USagzU19cXpPALy+mKdVd/tLe3+7EkNDU1eavOXXfdBcDHPvaxQWzd4CBMSK7xIZY8ZFK17oTWPY0fMWW6VjqTQilhr732Aty6quer5y1W3Rjj5aza3tPT4+fQP//5T38NyE9XpDU9i9D933///UVTNMpSpf+Dieeee873r3wxjzjiiEH/nQ3Bnnvu6V8re06Y+jPLGLakojLJPvnkk15w6MFpwWxpafGLiBbmJUuWeOVNZioJzGeffdYHyYQopYpTAEcffTSQU8bUV8VMTdttt513f9hjjz2AnDDKKnS/f/7znwH45Cc/CeQqiIWora31DuChI/hgIayqpA2RFrAspPLSPXz3u98F3GKp4EBtWsKKa2nza1VVlRfKMtnJPFxbW+vTlGhjpACtUsNHP/pRICdo1eZ3vetd/OxnPwNygZaTJk3yacc+8IEPAPCrX/0KcPNp//33H74bHyAuuOACwMlK5XsUxo0bx0MPPQTApZdeCuSC8datW+cVeSm3lZWV3pytDZvm2gc/+EE/boTTTjuNe++9F6AgkDNLCDeYhxxyCJBbK+TKU1FR4RUHkSVhLlkpcVJkVZUuRKmsKwoufOmll/x4kNKp3K8nnXSST9elyn1HHHGEX6Nvv/12IFeh7phjjhmRNH0bClV/2n777Yvmf+4toCn8PHzO6bRKIdLj4eijj/Yb35133nkD7zwijWjuj4iIiIiIiIiIyBzMcKZIiIiIiIiIiIiIiOgPIpMaERERERERERGROUQlNSIiIiIiIiIiInOISmpERERERERERETmEJXUiIiIiIiIiIiIzCEqqREREREREREREZlDVFIjIiIiIiIiIiIyh6ikRkREREREREREZA5RSY2IiIiIiIiIiMgcSk5JNcbMMcYcNtL3ERFRCojzJSLirQ1jzOnGmAeC99YYs81I3tNwoy85aIw50BjzynDfU0T/sFFKqjHmAGPMQ8aY1caYlcaYB40xbxusm9uUkEySdmNMszGmKem3M4wxJbdRGCoYY04xxjxujGkxxiwyxtxhjDlgI695jzHmE4N1jxuDOF8KkTxr/fUkc0TvTx3p+8sKovxYPzZ1+QF546DFGLPEGHOFMaZupO9rqDAc8sFae7+1drv13EdRJTcZc9cYY7ZMlP+Kwbin4UJqPK0yxtxujJk+0vcVYsACzhhTD9wG/BwYB0wDzgfWDc6tDR1GcCAdZ60dA8wAfgCcA1xW7ERjTPlw3thIwxjzJeAnwPeBycAWwC+B40fwtgYNcb4Uh7W2Tn/APNwc0Wd/GI576C8ycA9RfvSCTV1+pHBcMl/2BN4GnDvC99MnNmbe9Fc+DBX6ce/HAH8d6vsYYmg8bQYswa1R2YG1dkB/wN5AUy/HTgceAH4IrALeAI4OjjfghOsi4E3ge0B5cmxr4C5gBbAc+APQGHx3DnBY8nr75NonJ++PBZ4GmoCHgF1T3zsHeBanGFQMtO0D7C9/38Fn+wA9wM7A74BLcAO+FTgMmAr8GViWtPPzqe8+DqzBDayLk89rgKuT/msCHgMmD2dbB9A3DUAL8MFejlfjFqCFyd9PgOrk2Fic8rcsGWu3AZsnxy4AuoG1yfV/MYJtjPNlA+YIcDCwILmHxcDv1zMOTgceSF3PAtskr48BXgSakz78n+C8TPXD+vom+CzKD/vWkB+9jQPg/5J7tuHYBO4BPlFsbqTmRQNwVdL+uTiFtyzpsyZg5+B7E4F2YNJIzJticyB1fELSF03ASuB+oCz47v8k97Ma+CNQkxw7GFjQx71fi5tn7ck4+EpyXlkydybgFGibHG8B9k+On5v069KknxuS726ZnP+pZEwuAs7OwHg6BvhP8vrdwFM4GTEf+Hbqux9J2rYCOG99z2fA97gRjatPbu5K4GhgbHDsdKAT+CRQDnwmeRAmOX4TcCkwGpgEPAp8Ojm2DXB4MkkmAvcBP0l3Km4XOQ84Nvl8z2Qg7Jv85keTc6uD7z0NTAdGjfRgCD6fl/TP75LJ845kcNcCTwDfBKqArYDZwJHJ9x4GPpy8rgP2S15/Grg1+X45sBdQP9zt3cC+OQroohdBBnwHeCQZKxNxAvG7ybHxwPuT9o4B/gTcFHz3HhJhPcJtjPNlA+YIbuHoAv43aduo9YyD0+lbSV0EHJi8HgvsmdV+WF/fpD6P8uMtID96mSPTgRdwG7iBKqlXATcnbd8S+A/wX8mxy4ELgu99FrgzeT3s86a3ORAcvxD4FVCZ/B1ITobOwcnNqThL1kvAGcmxgylUUvPuvdhvA/sBDyevtyzyDD4OvIabe3XAjcDvU+dfi5Pru+A2CoOu5G3AeKrFrU9XBf2yC06e7IpTyE9Iju2IU8YPwMmXH+LWsOwoqcmN7oATjgtwQuIWnKnldOC14Lza5IFMSY6vCwcu8CHg7l5+4wTgqVSnnp/85iHB55eQCJ7gs1eAg4LvfXw4B0BvgyH1+SPAN5J+vCr4fF9gXurcrwFXJK/vS/phQuqcj5Pa1Wb9DzgVWNzH8deBY4L3RwJzejl3d2BV8P4eMrLIxPnS/zmCE5AdJGzH+sYB61dS5+EUsPrUOZnrh/X1TerzKD/eIvIjGActOLZwLs6lYQcGoKTilMt1wI7BsU8D9ySvDwNmB8ceBD6SvB72edPbHAiOfwencG/Ty3dPC95fBPwqeX0whUrqx9f328B3gfOS11sWeQb/As4M3m+HU+QqgvO3T93TZSM4nrpw5MguvZz7E+DHyetvAtcGx2px8nrQldSNcrq31r5krT3dWrs5zuQ0NWkIOBOdzmtLXtbh/KkqgUVJAEATjiWaBGCMmWSMuc4Y86YxZg3O9DQh9dNnAA9Za+8OPpsBnK1rJtedntyTMH9j2jtEmIYzTUD+/c0Apqba83Wc0gLwX8C2wMvGmMeMMccmn/8e+BtwnTFmoTHmImNM5ZC3YuOwApjQh//PVJxAFuYmn2GMqTXGXGqMmZuMl/uAxiz65MX5ssFYZq1dG7zvdRz0A+/HmbLmGmPuNcbsn3xeCv3QF6L8eIvIjwAnWGsbrbUzrLVn4szQA8EEHAuW7ptpyeu7gFHGmH2NMTNwCvxfkmMjOm+MMVuEQVXJx/+HYy7/boyZbYz5aupri4PXbTj52hv6c+/r80ctNu4qyM3B9O9siDwbTJxgrW3EWaw+B9xrjJmSPPe7jTHLjDGrceuI1papBPeerFkrhuLmBi0y1Fr7Mm43v/N6Tp2P271NSCZao7W23lq7U3L8QtwOY1drbT1wGmBS1zgD2MIY8+PUdS8Irtlora211l4b3ubAWjc0MC6yexrOHxHy728+8EaqPWOstccAWGtftdZ+CKes/C9wgzFmtLW201p7vrV2R+DtOL+hjwxbowaGh3F+Xyf0cnwhTigKWySfAZyN26Hum4yXdyafa8xk6pkLcb70C+nf72sctOJ28wAYY6bkXcjax6y1x+Pmy03A9cmhUuiHoojyw+MtJz9SaE3+1wafTSl2YgrLccxeum/eBLDW9uDmyYeAU4DbrLXNyXkjOm+stfNsflAV1tpma+3Z1tqtgOOALxljDh3oT/T1PpEvmwFP9nI+FB93XTizuTA9dXwhIwRrbbe19kacH/YBwDU4a990a20DzpVC82IRsLm+a4wZhXOdGXRsTHT/9saYs40xmyfvp+MG8yN9fc9auwj4O/AjY0y9MabMGLO1Meag5JQxJPSzMWYa8OUil2nG+SG90xjzg+Sz3wBnJNq/McaMNsa82xgzZqBtHCok7T4WuA642lr7XJHTHgXWGGPOMcaMMsaUG2N2ThYmjDGnGWMmJoKkKflOtzHmEGPMLgkTsAYnhLqHvlUDh7V2Nc588P+MMSck7EalMeZoY8xFOL+dc40xE40xE5Jzr06+PgbHJDQZY8YB30pdfgnOJ2hEEefLoKCvcfAMsJMxZndjTA3wbX3JGFNljDnVGNNgre3EzQvNiZLrhyg/8vFWkB99wVq7DKdYnpY854/jAirX971unBJ6gTFmTMKWfolc34BTVE7CuVRcE3yeuXljjDnWGLONMcaQm+ODNXbT4+AYnH+ulNNluOCq8JxrgbOMMTONSxP2feCP1tqu4JzzkvG6E/AxXEDXiCB5jsfjfPZfws2NldbatcaYfXAbFeEG4DhjzNuNMVU416E0OTI4GKifAG4Hfz1ucrQm/y/FBYicTt/+YQ04n5YFOGf/p8hFHO+Ec/hvwTkvn02hv4j81sbhFic5wR+Fi0Ztwmn6fwLGpL83En/J77fjFIbVuN3/Z8lFaf8O+F7qO1NxA30xLvL0kaDtV+Mc11twzvMnJJ9/COcb1IqbWD9jhCKSB9BHp+IijluTNt+OY3NqknYsSv5+Ri4ycyrO/6oF5/T/aQLfIFyU5X+S/vvZCLYtzpf+zZG86P7U8V7HQXL8Gzh2aD6OUZbvXRVwZzIG1iRtPiD4Xqb6oY++ifKj7z7aZOVHsTmS+vxoXAaHJuBHwL30L3BqbDIWliXz5pskEfHB+a/hXEqqUp8P67xZ3zWBs5JzWnGy8rzevovbxF6dvD6YXmRm8NnxOL/2JlyWgBuAD6TO+U7Sj024oKqypD/nJ59fTRIwS2F0/2KSrAEjMJ6UtaAZeB44NTn2AZwLQjMua8Iv1GfBuJpHLrr/TZLg1MH8U+RbREREREREREREHzDO93kxsLV1LP5ArrElblNRafOZ1ZJEwhQ3AbOstW8M5rVjtZKIiIiIiIiIiP5hHI6lHZCCuqnAGHNc4qowGpeC6jkcMzuoiEpqREREREREREQ/YK1daq29ZKTvIwM4nlyBjFk4F7RBN81Hc39ERERERERERETmEJnUiIiIiIiIiIiIzKG35Mf9QalTsIOdLmGj+6O93eVkvuGGGwC46667mDlzJgBLly4FYNmyZWy22WYAbLfddgAcf/zxAEydulF5gDPXH8uXLwfg7rtdDvrZs2dTVVUFwNy5LkfytGnTOPzwwwHYaSeXOrSyMpd7XJYCl5Vkg5C5/hhhDEV6kdgn+Rj0/rj66qs56qijAJgwweXhbm1t5S9/cTnZDzrIZTKbPn168QtsGDLbH52dnQBcdtllXk40N7uUnwcccAD19fW930SUIYOFYe+P7u5uysocF1fs+TU1NQHw5S+7zH177703p5ziMi1pfEydOpWf/exnALz22msA/PjHLuV0eflG1XyI4yMfRfsjMqkRERERERERERGZw8b4pG6SWvtGYMD9oV3+XnvtBcBhhx0GQFdXF0899RQAK1a4imONjY0ce6yrYCim8c033wTg8ssvZ/To0QO9jRHpj56eHgC/2503bx5HHnkkAC+//DIADQ0NgGNI1eZx48YB0NbWxtq1a/OuefLJJwNw7bW54icDYEMyMz4ygkwxqd/+9rcB+P73vw/A1lu73OVNTU3+Wbe0uGqJJ510Er/5zW+A3Ni48847AVi8eDG1tWGhng1CZsfIEUccAcAbb7xBV5fLcCMrRFlZmWcOxQQ99NBDg/GzmeuPRx5xtTLUvgceeIBly5YBUFHhDImnnXYap512GuBYZsjJF8jJDqHUZMgDDzzAzTffDMCNN94IwKxZswB429ve5uVrTU0N4Kx29913H5CTzx/4wAcAOProo/13B4Bh64/wmel5iRl97rnnWLnSVRIeM2ZM3rHLLruM7m6X/3/aNFcd9uGHH+aZZ54B4Ne//jUA++67L+DWq8bGRgD22GMPgA1ZgzMxPjKEov0RldTBw0b3x+c+9zkAv2iedNJJ3iynibN48WI++tGPAnD77bcDOVeAK6+8cmN+PhP9MXXqVP7rv/4LwLs1nHPOOQDU1eVKLUvwtLe3e6X2mmtcQRQtvPPnz2fzzV3ltrQy3A9koj8yhEwpqW9/+9sBeOmll4DcRsYYQ1tbG5BTNBYtWuSVj4kTJwKwbt06AB577DG22mrABYUyN0bmz3fltKWkVldX+0U0HPuTJ7vy4Vqc3/Oe9wDwqU99amN+PhP9MXv2bP71r38BcMcddwB4l4fFixd7k6364+STT/Zy4pVXXgFgn332AZwbRKkpqb///e8B+N3vfgfAypUrfRuqq6uBnDzs6urymxehvb3dnydFXkSAMYb99tsPgF/+8pcbev8j0h9PPukql77wwgsAjB071rdZ/SL5MWHCBB5++GEgJ1t6enr4+Mc/DuTWoOeffx5w/SMCSTLl4IMP9uNpPcjEfMkQork/IiIiIiIiIiKiNLAxgVMRg4yOjg4Att12W8CZ6rRr//e//w3A9ttv73fB2v29+uqrw32rQ4ZddtmFf/zjH0CODdJu11rrd8BykWhvb/f9JpOdgkAeeughTjzxRCDHmlhrBxIAUTLo6ekpYIs///nPA3jn/00BaqOYDZkqe3p6/BhRIGJdXZ1n5TWW/vOf/wDOZWYjmNTMQWZMBYRYa71lRn3V1dXl2ebVq10+8o0MuswUbrjhBmbMmAHAgQceCOSsK+985zu59957gRxbuuWWW3oGWky7GNVJkyZ5VrEU0jU+8cQT/O///i+QM2WPHTvWy8u021NZWZlfT4RRo0YVyJBRo0b57z322GNAjnWXCTyruPzyywHYfffdAScXxHoqyHbevHmAc52T65AC7Orr61m0aBGQkxtCR0eH7xuxzTfddJO3ikZsPCKTGhERERERERERkTlEJjVD0G5fTNCLL77I66+/DuR2xWVlZTz++OMA3tcsTLlUqth1110B5z+oHanYY7FkbW1tRXf48ttVv4kxOumkk3j66aeBXIDNps6khmzPE088AeSCJbbffnvOPPNMIOfjvJEpVEYMCqBTUJCYoo6ODt82jZuysjJWrVoFUBAkNX/+fM+obQrYbbfdADzzc/TRR3tfvHTqJYD7779/mO9w6LBw4ULAjWkxybKyaEw0NjZy1113AXhf9s7OTs+GSc4uWbIEcMxaKTHtP/3pT/1rze3W1lYvN+VjqnkDFPhn9vT0eHZVslLHKioqfCqz5557DoDXX3/ds49Zw8svv+zvV21fvXq1f63nHVpiNHckU8rLy/34UF9pXOk7Og+cFUPBeWLmIwaOyKRGRERERERERERkDpFJzRDkByUfqFdeecUzAjvuuCPg/F3EAGjnJka1FKE0UfKrnThxomeGQx86/RcjoGjtioqKAn9D7f4nTZrkWRNhA6L7SxIhSyyfTPXnb37zG5/eTH7PpQr5UmociAkRQwI59sxaW3A8naZqU8WRRx7p0+fI77SmpsbPmU0JGguNjY3ex1BphDTvV65c6aPf5bfa0dHhU3JpfIh5f/311z2TWgoWmNmzZ+dlPgHH/umzkEEF116tI2IOQ2iehAnxNa90rRdeeCGzTOpDDz3k733NmjWAGxNqczp9YXV1tR8D+l5PT49va7qvampq/HXlD15eXs6LL74I5IplDCcuu+wynyGnGMQC63/Y5sEY4+qr2bNnA32vNe973/v49Kc/DeQsG2lkQkntK4dlsUAQ4c9//jPvf//7C65VCsKkGJR/Toqbtda3XWb/8vJyb96Wcvqd73xnmO908KAFQ2aXysrKAmEZpkNRf0jpqKqq8kJT39P55eXlfrGSeVimn00NxYI61Efqn1WrVnHAAQcA8KEPfQjINw+WEtImNs35sMJMmHYsnYJM56cXqU0NTU1Nfj6o7atXr87LAwobVVUpM5CJvqyszJtnJTePOeYYAObMmeM3/FIqampqCnJpKrBs/Pjx/vql0EcrVqzwLi1SUsvLyws2Z2HgVEgCQC5ICgplal1dnSdONKeyHLj7+OOPs+eeewK5sfDQQw/5fMnFXOXUD2pfT0+PJ0wkb8LAK+XglaLe0NDAnDlzgJFRUj/xiU94mV8spdzpp58O4NNk1dfXe0VbCN3B1NZ08F0I9cvq1av9a7kZHX744d7dTlC6zFtvvdUHN/eGTZtWioiIiIiIiIiIKElkgkkttjNNmxnCz0Rlv/TSS/zgBz8A8Gkx+trlhqk2smj2/eIXvwjkdhn19fUF6UG6u7v9rlhJhLfccsthu8fBxhtvvAHkdmI9PT2eAdSONty5FXtu+qzYMZlzVXlG1bo2NWjch+NfqWi0Ex43bpxnDjTGrr/+es+EhMUSwD2LYtfNAtLzohjLpXNCi0QapZBWaGNw4403+uANmcMrKyt59tlngQEVucgsxPCNGjXKvxa7KkyZMsUHZO6///7+c40b9ZECX2bNmuXZdsmlLGP16tXeKqV5393d7Ys3qC1hwKSevT7r6Ojwr3VMAUPGGM82ax3KMpO6cuVK78oxadIkAH7729/6IEKxn2pne3t7QXGDjo4O35caA5KVZWVlnnUPAzZluRsJfOUrX/Fz/n3vex8A73rXuwC33mpuhGypmPK0nO/q6vJtl6zQ98LPQvZZ/Sf3ottvv92PlQceeACAQw45BHDrz/pkcOlLpoiIiIiIiIiIiE0OmWBSi6EYM/KRj3wEyJU73GKLLXw6prPPPhuAiy66qNe0OllnC3bYYQcg52u6bt06z3zp3sNdjHYs8jMsRSiJ9tixYwG3I0s7cYd+h2lmr6yszI+V9A44DLRSCdlNlUkN54uc9lW6T7v+9vZ235fa5a5atcozL3//+98B50ME2Z4v6QAQtT/0aZacWLJkifezS4+t9HU2NbzxxhueLVq8eDHg5Mubb74J4FO0yW+vlCG/uvLycs94yT9TxyZPnuzlq3wU5aMKufEhpvnAAw/0fu2lEGwoP1TIsVzLly/3c0HrRyhHi1nr0inqJFtXrFjhA27EUCr1V5ag5zdz5syCNGS1tbWe6dS6IxlorS3QPcL+0LXUZ2PHjvXWOvV9TU2NH0cvv/wy4NL/DTVUpKK8vJz3vve9AHz3u98F4KqrrgLyi3bo2Yb+qGndqbu7u8DvHwoZVLGt1dXVBTEBW265pWfw1Y8qRHTUUUfxxz/+sc92ZV5JhZwiIyErk8zSpUu94JAJZ/To0V7ZO+WUU4DcYjV16lSOPvroYbj7jUPo+J5+4MYYPzBKwfzUF3p6egpqqq9evbqg1nhfpuZipoKwQpUmmNwKNlWEfaRgKAkCzZuqqiqvwElojBkzxi82qvB12WWXAfh61VmGFs9w8dUzV+WxefPmeSVVxzRGNlUlVTJz3LhxBRHJ5eXlXp4o1+WmoKTOnTsXcJsyBTwpC4Tmx5o1a7xSKkW9q6srLyMIkDdeFixYAGRbSQ3Ny+mNfBiIKuUpPQ+guNtUmgAIc+zq+sormiVog/7aa6+x9957A/DXv/4VcEF0aqPkoNbccE0NqxSmo/tD94BtttkGyFWjmj59unczee2114DhUVKVD3v33Xf3kfV69grK7uzs9MRXGFibViLDjYuuEZr7QwUeckpqQ0ODX3fkQvDGG294RViBZHfeeSfgqiHq/N6QXaokIiIiIiIiIiLiLYvMMqmhuUEsqbR9pRFqaWnxOxxp9jvssIPPjSfKX1r82rVrmTlzJjA8O5uBQjuXsrIy3w/h7ja9iylViOGD/MomaSZgQ4NbwgAAQYEQmxqKBb4oJYoc+rVj7uzsLDi/ubnZm7rECFxwwQWAS2120kknAbkgrKwg7egvpmflypVMmTIFgH333RdwDIrSraTNWWG6nU0JYpLKysp80Iz6rLa21luXxCZuChAb1tzczF577QUUmqKttX5eiFEyxnhZIdcYBZysXr3as0RZRihL0/KyWJBUyBIKobwV45o2c3d1deXlH4ZspnGTFfWII47wbdX4X7dunXf/EnMu+dHT01OQJzV0IQqvAc5dSmkwlXZq33339Z9Jtg4HJPc///nPe51JDLsY8GXLlvlAa7kpWGt9u6RP6ZmGYz808RdzPwS31qSPzZgxw1syJZc0nl566aX1jp/IpEZERERERERERGQOmWNSiwXBaFcgpkfYcsstfZCIdovd3d1+dyTGVbvjVatWZboOs/xY5Ec1atQov7PR7qSrq8szADpP/SPmqFQgvznY8BRHod9pmhUIr6VdcfhbmxLS/Wat9SlGNO5D5kPzRDvrUaNG+T4Sqyg/4ba2Nu/PlTVo5y9WTCzavHnzfHvkf37eeefl1SUPUep+3b1BDGJNTU1B3fGqqqqCNEWlDCXl1zN++9vf7seDoDHR09Pj54DkaJhqTf0hv9V7773X+8uHwSFZg1i80H9SGDt2rGerRo8enXesGHPY09NTME/EfO26664+WFm/I3mRRYTFW8Kg2auvvhrIVRaThXXt2rV5ay3kF5FJpyNbvny5Z+31f6Sg57D11lt7a5gqy8nvc9KkSQVBo62trXmV+kJ0dHQUxMUU8+NXf4RMqvqqsrLSx5nIV/yll14C3LiVHtMbIpMaERERERERERGROWSOSU0zQ48++qiPNlZpO7FA22+/vdfgxai2tLT4iFVp7aE/STpNUZagBOvyFRk9enQBS1hWVub7SDubSy+9FCg9JrU3PyoxHcWS+afPKRaJKoSJhbOYJmUwkGaPn3vuOb+jTpfy6+rq8nNHx0aPHu0/E7MkdnKPPfbggx/84HA0Y4MhJlBzQGyhMcb7W4YR62KT02UQ1xdZWqoQm97R0eHln5jAuro6/zpMWVSqEBOj2IPa2tqC7A2SA52dnQVyxRjjmST1h9YOa63369OxLDKpet7V1dW+XWKTp06d6n0ClXJJbQlTUPUlZyVfNt98c/75z38CuTmXxQwZ4bNNy8i2tjbfD+mSwV1dXXk+/ODGjtoo+RHGikh+hmms0hiOYijhXFamAY3jMI5Fzy1M2yd5IMZ8Q+VCmO0gHS/Q2trq+zIdA1BdXe3T4PWGASupQ1XHWJ0kx+bXX3+db3zjGwD84x//AHIVlubPn+8Hiz7r7Oz0QTKim9N1i7OKX/ziF0COOg/vN3wtoSIhdMUVVwBw+eWXD8t9Dhaam5v9+AkHdjr1VOjQn3b8D81S6bQq5eXlRQMESgnW2oI69X3hjjvu8HNI40ibHmOMN7vomq2trQV9KoEyklVT1geNfSkomuNdXV3exFVMNqU/S9ew31Qg829ra6s3aWpc1NbWehmpDUkpI70Bqa+v94qDlLewIk468CeUIdrgSamdN2+eH09hIGbWoDkeBttqIzphwoSCqlDhmlhsLU+nr9L/FStWFARVZRF96SWVlZV+XCitmJSyMEgqvFboLgL5FRKLbVpGokKfnuOCBQt8WjC5IIRt0jjW/2IV+cI85OFrIM81ID2H1q1bV9D28vJyrwRLbos0Wr58uZdPvSGa+yMiIiIiIiIiIjKHATOpg7lT0O71uuuu8wyqdmlbb72137WILdWucN26dT4RuXYKW2+9ta9pHwYghedkDWJ802baMB1TyBxq96IdnNixuXPnMmPGjGG7743F2rVri7KDaaYjHGthwBS4XVqaJQ13hWlT1MKFC/OqbpQC+mJQ0zvgK664wiexF1sghikMABBz0NPT4z8Tq6bxpETUWYR25Borao+1toAdNcb4ua+5JSjIclNDmNYlPQe6u7v9Z5sCkyozvwKc6urq/BqhQNmQaQ8rA+n7WkcEydbx48f7YKMsu0aIGQ+ZwDB4rFhRGOg9BVX6fJ3X3d1dUBDAGOP7phRSuoXsse5XzHtDQ0Ne0QudL0jehMUe0kFmIwXpOwsWLPD3LHknnaisrMyzmmHQpNpVLJl/MStket3ROR0dHQVpDkePHu3Hoj7TvHz66afXmx4yMqkRERERERERERGZw0YHToU+c335gIXHFDBzww03APDkk08CTovfbrvtgFw6pqeeesrvWqSFKwF1Z2dnXooJcDsA7aiVxFq+F2+88UZBCoksQL628n0qlmA73P2n+1SpuW6//XbOPPPMIb/fwcKqVavyUoeBa1O6feEuL50ouKyszH8mJlpO8VDIQj7//PMlxaSG8yZdTzuEfI96eno88xPubsGxLGm/uvLych88lE4dovmTRYghKJYWRYn7hYaGhrxgxBDp95sKJN9GjRrlgyfCmutiyzeF9otBClNsaf1Q+8LSjqE/Ibg50FuZxx122MEHoaTZoyxBfn01NTV+LogNbm1tLQg0VftC/8KQPQvlMeRkSUNDQ8F3rbV+bJUCk9rV1VVQJlkWhUmTJvn2FYt7SJcI7S1100ggjNXRnBfCYGvdeyg703I0tGb2VVSnmKU3Hay4du1afz2li9O9Pvvss+u1ym90D4e1svuDSy65xEexS7kKq5/I3B9eU+YcDRCdv2jRIj851UnLly/3nSMTjqjlzs5OT3urKlUW8OCDDwK5+z3ggAMAuO+++3zbVSFr7ty5Xnl429veBrjgMoCXX355+G56ELBmzZoChXTdunV51U0gvzpKaObX96RUhZNC/9Pm3aVLlw5Ze4Ya6Xl28803c/LJJwM5s3WogKejkbu6uvJy/4ETRlLu9ZmEdJY2cmmkldRQgKZrrIdZMtKm701BSSsGyY3q6mrfV1LUq6qq/CK9KWQ3kPwTJkyYkBckFqK8vLxAAQtdqOQaIxlijGHu3LlAThmWO02WIHN1RUWFf84ia5qamgoqMwpdXV1FM6WEke2QG0+qAQ/5imxWXemKYe3atX7epzf+Yf8UM+OnTdkjESDVG3bYYQcAHn74Yb8JTSN09SmWlSGtiHZ3dxcQSeFrrRlhzmFB1y8vL/cySONIZOStt97KFlts0We7srs1jIiIiIiIiIiIeMtiULjq9I5DO84333yTBQsWAI4VBGfq33333YEcY6N6rmGKHGnm69at81q7dj9iTzfbbDO23nprAJ555hnA7ShVPULniykaNWpUJtNmyJw0b948AN71rncBjikVO6p65D09Pey2225Azqyt6g1yFygVrFmzJq9+Njg2WTu3NBMYMonhLj6dV1WMdGh6EMQyjCTSaTuK7d6LmZH+9re/AfC5z30OcJYEVYQK8zxqt6q+DU0xaZPlqFGjCmonq7/FzmQRYgA1DsLnLAZJqK+vL0hFlA4s2NSgvJih/JRJs6yszM+tLKdV6i8OPfRQICfny8rKCuaWxnh4LFy30v2g8bLTTjt5uZzlIDu1r7q62qcfkttLZ2enb2s6+MtaW3RNTAeoSqZss802fu7pmlOnTvV9n3a/yyLa2tq8bBQDHFZgS8vnsCqXEDKqWQmcOv300wH40Y9+5PUFWY7DXNhpGRiuq+mUY8VSthVjVEMLXbqv2tvbC/IySxa1trbyzne+s892RSY1IiIiIiIiIiIicxgwkyoN+tvf/nZeHXDI7TLC6h76rLGx0Wvu6d1rRUWFPyZNPmSZxNBqJ7f77rv7XaN8ZXbeeWev8Wt3p/fLly/PZBoR+RFqt6HKUV1dXZ75euGFFwC3kxX78453vAOA3/zmN0DO97YUobYX8zsNof4IfYjSVYRCx3ddS37M60t3MVQoluqlr/YJra2tHHzwwQC+Zrbeb7fddn5HGjJj8iNTP2he1tTU5FXe0ffStZy1ExablEWkg8P6QkNDg29LqRZ12FDMnz8fcONHwQqSlePHj/eBRVku2NBfyHIWIu1rGFagSrNoaeYdcnJihx124CMf+cjg3/QgQ3M99NFXv8yZM6fX/ghZ1hBpNjG0VMhiJ//+ysrKTK6rvaG8vNyPAd13GGSdDhQKg43S8rm7uzsz1tkjjjgCgP/5n/8pSEOm921tbT7WQGNh7dq1fsykA6fC88Jxki78EvokF0tRJkZXDK/kTm1tLZ/61Kf6bFdkUiMiIiIiIiIiIjKHjU7m/9GPftSnkHrllVeA3A4r9HXTjmXNmjV+lypNW9+bNm2aTyAuzbyrq8snqJef1c477ww4Hz0xJIp+D30O5VsnJqmioiKT0azHHXccADfddBOAjybdfvvtueeee4BcW+rr6330svx9tcPJYtv6wty5cz2LoTY0NTX5nV7at6W7u7vorj9MRwU5hj7cDepaDz300GA2od/oTxToihUreOKJJwC48847Abj22mv97lM7ztmzZwMunUd6Z19dXe3brX6QRSH0SQ3nRppd1fdbWlp8ujjdQ1agsV4sxV26TOGYMWMKGFSdr7ZvagjlZ7qOPeQKNmyqzHI6DY4Qyg9ZITo7OwvYs1Lrl7CUttZd+fo9+OCDBfInlI19pdZKF/+orq72DK3Wn1GjRhWNFM8qamtrvWxUv6j/2traiiaqL+bHDPnpm7KC+++/3z/7YgxweoyHGXWKjfti7UtbA8PsEWHWDJ2TLr4iPW/q1Knr9WMesJIqR+qGhgZOPPHEouesXr3a07w6v6WlxU+itJmls7PTBwOFTrrpChDqkNWrV3uHZx2rrKz0gklmcXVQWBkjS9hvv/0A2GeffQC4/PLLATjrrLO8WVPmnLa2Nu8Qf9555wE5YXT22WcP300PAtra2nwN3zA3p9qaTo0SBkKl63XreHh+e3t7gcla+dlGCn/5y1+45JJLgJzJQ3MkFAaauFtuuaUP2HjxxRcBfA685ubmglyoxYSmzgkFVSicpcBrnoWCSv2XNSU1vbkJkVZS6+rqCsyWWU6vNRgI81VKoVfAaV1dnZ9vm2oKrrQLSxgsotdaC7q7u4tWt4PiwYZZRLih12ul+YFCxaTY5k4olqta35szZ44nje666y7AyekNSUM50mhtbfWug0rbpPlQrIJhmIYpbfouKyvLXPBhQ0OD1yEUTKU1o1iu7M7Ozj7HeF/BUcVS+xVz15OckR4o+fuvf/1rve3J/uyLiIiIiIiIiIh4y2HATKrYyblz53rztLRjpQAaO3asZ65CTV1mewVcifksKyvzn4WJ3NOafJhINp3ov62trVdH5u7ubu/0vf/++w+w5YOPOXPmALnKW+9///sBl6Ran73vfe8DnOlGu6JTTz0VgFtuuQWAO+64g6OPPnrY7ntj8fe//51LL70UgA9+8IMAfOITn+Dmm28G8El+i1VCEXp6egpMD2Etb7FHMu2lk3sPF2TG/9a3vuWd9NU+uaqErI2YsGXLlnn3GX2mlGXjxo3Lq1kPjlFNp5QKd8CaJ9pNhylX0s72ZWVlmUpWHUJzIB3gAYVMam1tbcF56XM2Nah93d3dnsXQ+KmqqvKyelPtB1lY0gxiV1dXXiELHUszjMXM/r2xrVlCGBgmSB4WgzGmoLiBMaZgvuiaixYtKpq2LUuVl9aHYq4JkplhAFDYH2pfunBMeF6WoAqEX//61wE499xzAaeb6fn1lTYqTPt41FFH+e8CPProo95cr/VK46OiosKPmbBSpNK4KcD9z3/+c7/bEpnUiIiIiIiIiIiIzGHA2x/tJGbNmuV3XWJBxV4tX77c16EPtXalRNF/7fBHjRpVUJ4sTBchbT/c7YoR0GcTJ0701wiZA52TxbrtO+64I5Ar5yimbNasWXzoQx8CckxgmHZILKt2f6VQNzmNT3/603nv586dW1DSLQyM0hgId8N6rXGiMaGUOzByDKrw8MMPA44ZFQsof08FNlVWVvqdupjOcGeaLgG8ZMmSAn/tsrIyvwsuloBax8I0cWnWRP2d5fGklGJp30MoTO1VUVFRwHaUWpDhhiJMv5dmDnt6evw4K7UAof4i7XcXBomki4N0d3cXDdIMv5d1hD7XitMQFi1a5GM9iqUYEsLy0+kypzq2dOlSb/kROjo6Mhnr0Rs6Ozu9TqDnHqbPTMuPyspKf57WFn0/SymowgIWknfSH6RbnH/++b5AUBignF53wjiGX/3qV0DOrzRk69VXkjejR48uKBZQWVnpS7hfddVVefccWjZ6w6Bw9GG1oPB/RP+QVq6kvMyZM8dT81JQxo8f7zcDUvIVZLO+yg1ZQ7GghDAnXVj1Ano3q4TVySA3cfR+fb85HDjmmGMAuO6663zO23QWg6qqKv9aC2lVVVVBRH76P5Dn2F/MnKn/aTNmWVmZv74Ejfp5+vTpPPXUU0B+EEYWICVVi0WoTKTNnWG+XPWJXC42VYgcaGho8DlR9V9yA3KZWDY1yMSt5xy6tKQVz46OjoKAmKwoHv1FqGQVq9ueDoQqFugUniPZos90zaamJp9dR+ju7vYBsLvuuutGtmToEW7kJSs0XsL1R3K0o6PDnycZGX4/K0FjfQXDyfx/yy238NxzzwG5wLeXXnrJK6dpdzBrbV4WDHBtT5NFofuQXDxVGfOoo47qtbJff9xEork/IiIiIiIiIiIicygdb+e3AMQOKddre3s7Tz/9NADvfe97AfjHP/7h0+/IrCOn5FJIlRKi2P1uvvnmPpAsTD0F+ali+qrgpGPFKnCNlPlO9/LAAw/4wLArr7wSyLkCzJkzp1/3p/aGgVCDidDtRI7uWYPMl2nWdPPNNy8wd1ZXVxfk7uttZ7+pIEy9pDYXS1MmlqSUkQ5oamlpKXCDCc3h6bRl4ftSZ1I7Ozt9ikLhiSee8C5GcnMJ26d+C8396tN0err77ruPyy67DMiZf3t6evz1s4i0O1h5ebnvBzGAakvIqoeVycScSm5onIwZMyYzwYf9DeDaZZdd8v5nHaWl1URERERERERERLwlEJnUDGHvvfcG8I7NnZ2d7L777kDOj2y77bbzAUHaDR955JHDfKdDh7CWeDGGNExXJqSry8gJfPHixd5/V+xaFgIhjj/++Lz/IeTbJZ/CRYsW8frrrwPFfY7kKxZWVRMDoP4Id/rp3XYYmJh2hp8wYQLTpk0bUBuHGrImiOlR4EZHR0dB0Ez4WTqlzqaO0aNH+7Ehtqi2tragYlcpI82kdnV1+TGcLlARVuASWlpafB+l/dtLpX9C/3NZ5ISHH37YFwxRvIjmS09PT0F/hNYZMYeaP2HQlGRqW1tbgfUiy1i2bJm3IOg5hxWoJC91zpgxY7x1U+epvUuXLi1YYyIGF5FJjYiIiIiIiIiIyBwik5ohKHJQu/qamhofSSnmsKyszJ8XFjUoVaRLmc6aNcv7pKp0nXavvaU5SUfJa0d76KGHFuxusxKJ2RuUIi2LqdKyBD1HFRKRxeHpp58u8Detr6/3hRPEEqkc4qaKMHuD5IXmx8qVK7015oADDhiZGxxEFCtlqgwpaqf6QMdD1NTU5GXTgFw6xbAkZpYh1q+pqalATiqye6iwcuVKX7I5nZ4qC0jHPjQ2Nnp/TJV7Vp+1trb6SH99b/bs2WyzzTZATu7IErHZZptt8iWWRxpmI8yfI2833TgMth1no/vjtttuA+DOO+8EnBlKQlaK2ujRo705R4vOu971LgBOO+20jfn5zPXH888/D8AjjzwCOIVEpvwwBYhe77nnngAcccQRhTez4dViMtcfI4yhsHsOXPik5NYImWUzO0akpH3ta1/zJl7lVT7ssMO8i5AW30EKJMtMfzzwwAPuAql5H9aZl0ytqqoqcI3R/2LBlxuAYeuPxx57DIDbb7/du40de+yx7kvWFqTxKxZ42h+ECp/G0+LFi32lw/VcKzPjoy8oVZvSly1YsKAgGG2QUBL9MYwo2h/R3B8REREREREREZE5bAyTGhERERERERERETEkiExqRERERERERERE5hCV1IiIiIiIiIiIiMwhKqkRERERERERERGZQ1RSIyIiIiIiIiIiMoeopEZERERERERERGQOUUmNiIiIiIiIiIjIHKKSGhERERERERERkTmUpJJqjLHGmG36cd6WybmlWze0HyjV/ujrvvvbpiLfO90Y88DG313EpopSnS8Rw4dSHCNRnvYOY8wcY8xhvRw70BjzynDfU0T/MKhKqjHmAGPMQ8aY1caYlcaYB40xbxvM3yglvFX6wxhzjzFmlTGmeqTvZahgjDnYGLNgEK7TEvz1GGPag/enDsa9lireKvNlIEgW2XZjTLMxpinppzOMMSVJNAwUb4UxEuVp3nlDLi+ttfdba7dbz30UVXKNMacYY67J0malN5SqDBm0mzPG1AO3AT8HxgHTgPOBdYP1G6WEt0p/GGO2BA7E1Q1+z8jeTfZhra3THzAPOC747A86LwvCbjjv4a0yXzYSx1lrxwAzgB8A5wCXFTvRGFM+nDc2HHgrjJEoT/PRX3k5VOiHDDwG+OtQ38cgovRkiLV2UP6AvYGmXo5tDdwFrACWA38AGoPjc4D/AZ4FVgN/BGqC418GFgELgY/jJvA2ybF3A08Ba4D5wLeD722ZnFsxWO2M/VHQlm8CDwIXA7eljv0O+H/A7UAz8G9g6+B4eN8HJPd7SJFj1cAPcUJqCfArYFQv93N6cj8/T/ruZeDQ4PhU4BZgJfAa8MngWDXwk6RfFyavq4HRQDvQA7Qkf1MHoe/mAIclrw8GFuCExmLg973dT9DOB1LXC/vsGODFpN/fBP4nOO9Y4GmgCXgI2DV1T+ckY2/dYI6VOF8GZ6wEn+2TjMmdcXPtEtyC2Qocloz1PwPLgDeAz6e++3jS7iXAxcnnNcDVSV83AY8Bk0e6/W+VMUKUpxs0B1LHJ+A2MU3J/dwPlK3v+ZPI3tTvhDLw2uRe25N7/UpyXlnSfxOSvrRBe/ZPjp8LzAWWAlcBDalx86mkbxYBZw/x/CnoP0pAhgxmB9QnN3UlcDQwNji2DXB4MkAnAvcBP0l13qNJh4wDXgLOSI4dlXTAzsngvob8CXcwsEsyIHZNzj1hKARI7I+i7XwNOBPYC+gMB2My6Fcmg7kCt3BcFxy3SV8ciROo+6SPJa9/ghOE44AxwK3Ahb3cz+lAF3AWUAmchBNK45Lj9wK/xE2k3XGT79Dk2HeAR4BJyXN5CPhu0K8LBqPPUs85VFK7gP9NxsWo9dzP6fStpC4CDkxejwX2TF7viROY+wLlwEeT+6gO7ulpYDq9LFxxvgz/H70s0LjF8TO4ubYaeEfSllrgCZzSUwVsBcwGjky+9zDw4eR1HbBf8vrTuPlVm4yPvYD6kW7/W2WMEOXpBs+B4PiFOIW7Mvk7EDD9eP5590IRGVjst4H9gId7Gwe4zc5ruLlXB9wI/D51/rW4MbdL0ne9tm8QxlbR/iPjMmSwO2GHpKELkoF9C0U0aOAE4KlU550WvL8I+FXy+nLgB8GxbQkmXJFr/wT4cW8DZzj/NvX+wO3WO4EJyfuXgbOC478Dfhu8PwZ4OXhvga/hdpq7pK4tgWtwu7qQMdgfeKOXezodtzM1wWePAh/GCZ1uYExw7ELgd8nr14FjgmNHAnOS1wcz9EpqB/nsTl/3czp9K6nzcMKiPnXOJSQLRfDZK8BBwT19PM6XkZcfvY2V1OePAN9I+u2q4PN9gXmpc78GXJG8vg9nKp+QOufjpNj1LP1tymOEKE8HNAeC498Bbi723Nbz/PPuhSIysNhvA98FzuttHAD/As4M3m+XPN+K4PztU/d02RDOnaL9R8ZlyKA6zFprX7LWnm6t3Ry3K50K/MQYM8kYc50x5k1jzBocFTwh9fXFwes2nGZOco35wbG54ZeMMfsaY+42xiwzxqwGzihy7RHBW6A/Pgr83Vq7PHl/TfJZiN7aIXwRuN5a+1wvvzGRZEeXOHs3AXcmn/eGN20yWxLMxfXbVGCltbY5dWxa8noq+f2p7w0Xlllr1wbvN+Z+3o9bxOYaY+41xuyffD4DOFt9mfTn9NR15zMCeAvMl6HANBy7BvntnAFMTT3nrwOTk+P/hVPGXjbGPGaMOTb5/PfA34DrjDELjTEXGWMqh7wV/cQmPkaiPO0njDFbhEFVycf/h2Mu/26MmW2M+Wrqa+vruxD9kYHr80ct1v4KcnMw/TvDvd4ImZYhQxbVZa19GaeZ74zbXVmcZl0PnIbb0fUHi3CLqLBF6vg1uN30dGttA47u7++1hw2bWn8YY0YBJwIHGWMWG2MW40xCuxljdtuAS30QOMEY88Veji/H+QLtZK1tTP4arHOk7w3TjDFhm7cg5xc1zhgzJnXszeT1QtzETH8P3PMaaqR/o6/7acUtNgAYY6bkXcjax6y1x+NMbTcB1yeH5gMXBH3ZaK2ttdZe28d9DDs2tfkyFEii2qcBShEUPrf5OHYsfM5jrLXHAFhrX7XWfgg3Pv4XuMEYM9pa22mtPd9auyPwdpz/8keGrVEbgE1pjER5umGw1s6z+UFVWGubrbVnW2u3Ao4DvmSMOXSgP9HX+0TebgY82cv5ULz9XTh3ESE97hYyjCgFGTKY0f3bG2PONsZsnryfDnwIRyWPwTkTNxljpuGc1PuL64HTjTE7GmNqgW+ljo/B7ebWGmP2AU7Z2LYMBt4C/XECztSzI84XaXecKe5+NmxALgQOBT5vjDkzfdBa2wP8BvixMWYSgDFmmjHmyD6uOSm5XqUx5oPJff3VWjsfZ4a40BhTY4zZFbcbVJTotcC5xpiJxpgJOF+cq5NjS4DxxpiGDWjbxqKv+3kG2MkYs7sxpgb4tr5kjKkyxpxqjGmw1nbiHNu7k8O/Ac5I2CFjjBltjHl3aqEZdrwF5sugwRhTn7AW1wFX98KaPQqsMcacY4wZZYwpN8bsnCxKGGNOM8ZMTOZXU/KdbmPMIcaYXYyL7F2DM092F7n+sGMTHyMnEOXpRsEYc6wxZptEoZbMG6yxuwTnkykcA9wZMMzLcAFI4TnXAmcZY2YaY+qA7wN/tNZ2BeecZ4ypNcbsBHwMF9A15CglGTKYTGozzofh38aYVpzgeB44G+e3sCfOKfd2nANxv2CtvQPnA3QXjsq/K3XKmcB3jDHNuElwPdnApt4fH8X5psyz1i7WH/AL4FSzAemLrLXzcIL1HGPMJ4qccg6urY8YZ8r7J86/pzf8G5iFYw0uAD5grV2RHPsQzh9oIfAX4FvW2n8kx76Hi1Z8FngOt0v+XnKPL+OEzmzjTB/DYZbp637+g/PB+ifwKrmdsPBhYE7SX2fgmCWstY8Dn8Q9p1W4fj19iNvRH2zq82UwcGtyn/NxPmQX4xa2Alhru3Fs0u64qNzlwG8BKQVHAS8YZyr9KXBy4moyBbgBt7i8hAuMuZpsYFMeI1Gebjxm/f/2zjw6qvL849/MTEJCIAkQBBKRKIsLLqi4Vq3VqkWp9bR6rLaKWq1a1MpxPWpdTj2tWtG6VK2ctloqFdGfImqrIBVFsOKOqIQlYggGIYEwSSaZycz8/rh+n/vOO5eQhJnJDX0+/wxM7szc5V2/z/bttTTDCep5JJlMvpGB7wUcpf6Wb8/1Wlim/mQy2Qrn3rz97TFHwvF1ngnHd7MGQBuAK63vXQTnWbwO4N5kMvlahs53e/S5MYSRb4qiKIqiKEonfLthqIcTfNbUw++ogrPwy7eUVcXC15UGFEVRFEVRfMRgOFH9PVqgKt1DlVRFURRFUZQcoUpq19FFqqIoiqIoiuI71NyvKIqiKIqi+I4uRwx60Ncl2EznQtT7kYrej1R6dD+efvppFBYWAgAKCgoAAIlEIu24QCAgr7SO9OvXL+VvbW1t+MEPftCT0wCykztU20gq3bofjY1O/u1NmzZhyZIlAIDmZiev+ZVX2kHEqdx6660AgEmTJgEAIpEIAGDChAkYPHhwd07DxBd9xkfo/UilV+8H23hraysWL3aSoVRUOEkFDjvssC59R0ODk9Rg+XInY9Po0aMRCjnLqBEjRnTndAAftQ9e16pVqwAAzz//PADgoosuwt57pyZ+mDNnDt577z0AwKWXXgoA2GuvvZABPO+HKqmKoiiKoiiK79gZn1Td1aWi9yMVvR+pdOt+fPXVVwCA22+/HeXlTgVGUy0l/HfetwVhksmk/JtKan6+U5GuubkZV199NQBgyJAh3T1/VVLT6ZU2cueddwIA4nEnP3ZlZSWCwSAAYMaMGQCAgw5yihRNmjRJlNGioiIAwLRp0/DTn/4UAHDiiU5Bng8//FC+f5999gHgqKrdRMeQVPR+pJLz+9Hc3IyamhoAkD4yaNAgxGIxAG5/oaJ69NFH409/+hMAIBx2qr2OGzcOlZVOpVcqhytXrgQADB8+HBs2OEWi2tqcitaVlZUYOrSzKrOCL9rHNddcg08//RSAO+9s3rxZXqmk9u/vFDhMJpOoq3OKih1xxBEAIMrqokWLMG7cOACuxc+cr3aA5/3YGXO/ouQcbqry8tLb87vvvgsAaGpyMoMUFBRgwACn2t/IkU71ud12263T7/b63t6Ag8XQoUPl3Gnu5+IkPz9fBkYuSAHIAMyFKP+/ZcsWbNq0KeVvir/hs+YEu3LlSpkQJk6cCADYfffd0dHhBAhfddVVABw3EQBYsmQJ9ttvPwDAY489BsCZWC++2Mnxzj7DhWk8Hkd9vVPinK/Dh6dU3FWUPsOGDRtQXFwMABg40CmqF4/HZfy78EInj/1dd90FwNmsrVmzBoDjFsDj6VrzzTffAIDMK+FwGGVlZQCArVu3AgBqa2u7ukjtVTh3zJo1C6WlTn5+LizZ5/Pz83HuuU6BtUWLFgEAampqRDipra1N+c4rrrgCr73m1CPoxuK0U9TcryiKoiiKovgOVVKVPkM8HhdFiSxcuBD/939OBcRt27YBcM2ao0aNkkAS7nJLSkqw7777AgDOP98piU311C8qKuCa6IuKiuTfVJHNe0CnfdvsD7gKKo8JhUKiMv+v05kiDwCff/45AODFF18EANxwww25OTELu72/9dZbEqDx2WefAQD23ntvaee77747ADcgavXq1RIwcsghhwAAfvWrX4m5kt8fjUYBOH2M/YfBIUOHDpXjbGVXUfwIx/vW1lZRTdnGA4GABAqxvzz++OMAgDVr1shnydixY1FSUgLAbf9UVBOJhIyzVGw7OjrkO6iy+pEFCxYAcNRgBufa88jmzZux//77A3BN+vF4XCx3VGP5+S1btmT8PFVJVRRFURRFUXyHKqlKn8FUb+bMmQPASZVBX8099tgDgOsEX19fL35F3CFu27YNL730EgDg1VdfBeCmH5k2bVq2L6HLUP0qLi4WXyq+x2uJRqOy4+W9icViory2t7enfGcwGJRdf19nR0rojvAKNCM1NTXi20mFkr5rnfk0ZxJbsaRP3JIlSzB+/HgAwN///ncAQFVVlfid8vhjjz0WgHP+bOcMpopEIvJ9DKri70WjUWlnVJ6++uor7Lnnnlm5zr7I9ddfL1YYqkyqMPuLlpYWAE6wD8cKjn39+/eXPk9Flc+tqqoq7RlGo1Hx5bfHHfNY+nMWFRVJ//Kzkvrf//4XgHNf7LSGHANGjx6NqVOnAnBjIoqLi6W900pHJbWurg5ffvklAOdeZgJVUhVFURRFURTf4TsllSt0c2fa3d3pQw89BMCN5rvgggsAODudTEWcKb3L0qVLAThRiIxMpOr1/vvvA3AiDxmFyZ31oEGDJFqefPHFFwCcpOh+ico0MxQwcttWSM30cXbaKX4WcHf4BQUF4kPU18mU/7D5PXPnzgUATJ8+XcYJ3jsWQfjggw8y8rs7wh7zGIU/cOBASRt1zz33AADmz5+Pgw8+GIAbdUyF9IgjjsBzzz0HALj88svTvptthKppQUGBqChk9erVoqTu6kqhl0L/xhtvAADuu+8+AI4fI1MSkV1tXumupcI+nhHyjz/+OO6+++4snGHXCAaD0oc5fprWJmIqq1x78HPBYFCOt9cngUBA/saxNR6P+yq+YXtwngwEAjKn8Fo45/Tv31/WUXwvEomIj+7XX38NwF1rxWIxmZszpaT6bpHKQdBrMORN4t+8GsLatWvx6KOPAnAHjtNPPx2AM3CrWWbXgJNmOBwWJ3Wac5jfrqysTBYXNPE3NTXJonbYsGEAIP+n47sfYDstKiqShSfbuznocnDhtQeDQTHBmO8BzgKWixHF5bzzzgPgpv0aPHiwBOHx9Zxzzumdk/uWp556CgDw3e9+N81U39DQIIFQTCXF9FGlpaW48cYbAUA2YI2NjdLmbXeC0tJSWbiS9vZ2uTd0qdlVseeUuXPn4sEHHwTg9slHHnlE/m7PJ35KY9dVvBak/DfHF7anPfbYw/P67PdGjx4NAHj55Zfx4x//GICbUzMXmGOfV4U+O4eneQ84fpJkMinHca7hfamoqBABhPegqKhI2oWfWb16NQDnvDkv2HnzQ6GQXLu5QOfxFIZo7k8kEnjrrbcAZG7M3LW2f4qiKIqiKMougS+UVCqkoVBIqkO8+eabAIApU6bIcfYOx4spU6aIKsBgByoOiURCFdQ+jKlSMI3Um2++KdUxaG5hsNTxxx+PI488EgAkTVVRUZEorXylOsSKGn6AO/1QKJTmpG4qXew7pqJjmqIApKQL6Qs7/J3FVgM6U7buvPNOGXMY5DBq1Cgx69NEzkCqXGCmWqOCxbRQu+22G9avXw/AVe94/gDSgp7i8bgk5jaDo/hvjpVsUy+99JK4DlAtKisrk9/YlZRUqm226RdwU5C9/PLLUnHnD3/4Q9px9nzS11RUIN3iYl7TcccdB8BN2l5eXi5tkvXaKysrJXCPaunkyZMBAA8//DDWrVuX8rdswnZtBklxXuA8MWLECPm7PVbm5eWljR/mcZwj+BqPx7Fx40YArsl78ODBEpDlZ8stn2kwGExxEwOQUiSGYw/Hg/79+4uCas+ZiURCAqcyhSqpiqIoiqIoiu/oVSXVKzn5b37zGwCuU+/s2bPFp+WYY44B4PpdmTCN0Pr16yVp9e9///ssnXnvYQZ/UW3jzqW1tVV8Zvi3NWvWiP/mAQccAMB1dmb6lL5MJBKRZM3cDbJk26BBg1BdXQ3ATdw/c+ZM8UVlcJJfgqVMqJAGAgF53lTJzMTq7EN83qb/FT9Hn6lgMNgnlZ7uYgY8bI/XX38dgONzyH7Bzz3xxBO49tprAeRWQSXmeTNgimpeZWWlBPpR4Zg8eTLWrl0LAKJaMUl5Y2OjfJ/tawq4bYpq67hx40Sppco6adIkLFmyBIDjE9uXsP0tTWtMZwoq67efccYZOPXUU3fqN/0O2wWVsmAwKOmJmLSe7SMajUoxCY4ra9eulfYxb948AG4J3rq6Ovztb3/LxWUAcH3IOReYAW0rVqwA4FjQ6DPL9k8r1faemR1MxQDFlStXirLMgFxabvlbgD9TUTGdXm1trcTt8D7MnDkTgFP8xlaWA4GArDO41uJc2tzcjFWrVmX0PH2xSGVD+uabb2Rw5QC8du1a3HvvvQCAf/7znwDcBnLTTTdJ5KopudPRnXDCN+lr0Zi8Vx0dHTKovPLKKwAg0ZNVVVUi09PcF4lEZFHKxVhdXR0Ap4PZDuR+xnTX4AQaj8fx85//HIB7DTRFVFdXy4TLdjV16lSMGzcOgFtlxMu809vwGTc3N8vAyevjQBIMBmVi4fMuLCyU4+yKU/8r2ItTc2Hy4YcfAgB+9KMfAQDGjx8vbYl/+8UvfiGbZdJbZjsuEjjx1dXVyaT4n//8B4AzHnLjxQ098zqWlpamVZUC3Ovh93788ccAIH0JcKNzDzzwQOlTfjZfemEvOsz/Mwo5mUzihRdeAACJWqb5mq+Au6ApLCxMWfTa399XFqeEc4Bp8r344osBOBt985h4PC7zLwNNS0tLRQiZMGECAPfebtmyRd7LBRwPOecXFxdjw4YNAFyRKxgMikuY10bFFoFM+Ly5+KyoqJDFKSsy7bvvvrJ+YZvx0yKV4x3XCslkEieddBIAt4odCQQCchxN+21tbTKWfOc73wHgCl8rV67M+Hzj/5WJoiiKoiiK8j9Hr0ostnq322674a677kp5r66uTlb+3MWwcko4HJZasVSNTjjhBIwZMyblO/g5r12TnzEVIL6aJjvK9TS7tLe3pzkyH3nkkaIiUgVZuHCh/L0vKKheUPHYunWrVN7hro4UFBTINdMlYp999sETTzwBAFi2bBkA4Oabb87BGXcPpgjasGGD/NtWaAYOHChKMQNbDjnkELlmthXubBOJhKfJd1cnLy8PH330EQDgqKOOAuAE1QGOOkCT+uGHHw7AzYdpQuWwra1NVEW6lWQDKqFUYhjM9MUXX4jrChWtG2+8URQ/9n+aaw844IAU5Z3fyc/STEfV1AzauuWWWwA4/YQmXqai6qsVqJYvX45nnnkGgHsNVVVVMpYeeOCBAIBPPvkEAFJyxjLNjklfU029sOeAp59+WtITca6ledecX7zyiLI90VqX60BNO1g0EAhIm2UficViMmd2dU1gp2HitQ8ZMkQCpmjhaGpqkj5n5xz2A7SamJYVtmPOJ6StrU1UaarBgUBA1ltUpA899FAAwJNPPinv8X7QVaSn9M0ViqIoiqIoirJL4ztnNdvpvLKyMq26B4856aSTUlIlAMBvf/vbtO/kbikcDosqO2rUqCycvTdejvR8z9xpmmkw7OPp7zJjxgz8+c9/BpCu/HgFxgSDQVF+GFTh5WvjF7qaDJs7+rKyMtnlL1iwAIBbt3zTpk2illBd//zzzyX1Bv3xTB8av/jcUSk2E0kT3p9wOIwTTjgBAPCvf/0LgKNg2Cm1uJvPy8vzVIP8SCaDT5YvX45JkyYBcCtHUUl8++23xbeOacpMeO/uuOMOAI7/N4NCLr300p0+t+3BcYqvZgoq28dvzJgxYhVgcAivLxKJpFlSgsGgKOp8j33IbPf0S7zoooukLXEs4St/x6/Y/fmVV14RBYkplLZs2SJBpPbYWFtbK+nuvNoifSBpqbn//vslKOe6667L5KVkBTMQl8Ey559/vswtVMx4XyKRiCiHfI1EItKHqLax31ChzhVUcjnnb9y4UcZ7vse221WSyaS0H94H3pdoNCp/ozq7bt06jB07FoB3PExvQ2WZfaO0tFRU5ltvvRWAO/8UFhbK/aIfbnFxsVj3Xn31VQBuQGVJSYn0LwYhqpKqKIqiKIqi7HL4Skk1IyXt1DpAurq1ePFiUQmoEj733HO4+uqrATgKCuBGcc+fPx9nn302AFcZyQVmJKidHqezSLhEIiHZC6iA5efnS81u3qMnn3wSgKMIcHfLHf6IESNkZ0PVg/9vbGxMSZfhF7qSjN2M7mcKKu7u6F83dOhQUaD4apY+raioAJBbVb2r2LWigXQf08bGRklNxCjwF198USwPdnoVv9WUZl/wKsdol4AFUksY2gUOvLJUzJ8/HwBw9tlnS1EH9jv6fK5fv16UFrJy5UrcdtttAFy/ZZb4mz17drdTEvUE/i6fJdu7VzL9iy++WFL2UfWgzy3gXjP7gFnwgW1k/Pjx2z2XRCIh38vj6W9m+//7DXvOuOGGGzyPY6J3Wqw4Lk6ZMgWzZ88G4Ca2b2hokGIz9HWmcjZhwgTPFIm9SWfWKbO/0Nd53333lXGSkfGcM0pLS9MyGwwaNEjGK7YPWjg5P+cKzgFmOVeeG8eKtra2tJRTvBZzbDHhe5yHqdiax3IeWrVqlcwpnI/9BNPvURktLy+X1F0cCznuJBIJuX/0Nc3LyxN/fJZj5ncFg0GZi7h2+d73vrdT5+urRapXRzIHVPLpp58CcEwJNEOxmsW2bdskxRDzdfGGh0IhXHbZZdk5+U4wJ2PbbLBixQqsWbMGgNtAaDoKhULSKdjo99lnn5T0MoBTNQdw8juyc/L7w+GwfB/Nd+yQ77//vqSeyDQ9Ndd29XgOnrFYTCZQmuw4oD700EOysLvgggsAAMOGDUtzgueA6ic4uHV0dKRU+gDciaWjo0PaEwNbgNSFOOAubsPhsK8GTS+3FsLJjgsrG/MeAKmbPQZf0g3m2GOPlWfNAZSfO/PMM+X+cAP77rvv4qKLLgLgVhniILxs2TI5t2yauh944AEAwK9//WsArjneTIlEmpqaZNLktdDsv/vuu8uCyz7GhIEyXgFRV155JR566CEA7v3j/fTrItWeM3bkvsNJl4F1dB36yU9+IoGWzKe7cOFCCdg95ZRTALiBI9Fo1Hcp33Y0pnKjyw1QVVWVLFo4tpoLPJr0acrv37+/mIf5am6kc4ntXjBy5MiUDRvpbtpBW1ziK83+gDvHtLe3+9qtyt44nHnmmbLpIlyYtrS0yBjMa+J8BLhulv/+978BOC5QTOc2ceLEjJyvmvsVRVEURVEU35HzLV9XA2NM7OOZ3iIWi4kKxp3fPffcI0oS02eQQCAgSa9zgV2sAICkS+LO/ZhjjhF1iyY37ljKy8vFDPW73/0OgKOesqgBlTWaHzs6OkQtoTp71lln4emnnwbgmsFZj3zGjBlZU1K7+4w7U169gpnMtGRUtpjcnNVPCgsLxQRz4YUXAnBUA6oe3BFSFbF/ozdhO43FYnJ93N2aydm5k6W1oL29XdQPtiPe046ODlE6/IBp0reDw7h7b25uluswTXR2gQMqnZdccomkX2Ly7ra2NglqoIpIJXXp0qVyHBP833DDDWkpWahkDhw4MCcqCVU7jhMsxOEVhHDzzTfL9XvRWSJ+3g+6Sy1fvlx+m7C/mN/FfuUnzDFke/142bJlYqLkGGnWLqeaSIX49NNPl6CQm266CYDjGsCxlHMRrVtHHXXUdtX/3iKRSIgSyD5Ea9PgwYPlXtEs+/nnn0v/oArP5x6NRuU9Wm/eeecdmbtY+ZFWPqY78hOxWKzH4zzXG17jKMcMP6uogLuW4CvgWgS4FuG4YKbcY7s2iz5QVaebzKxZs1K+NxOokqooiqIoiqL4jp1WUjtTRhOJhPhscPXdk8ANW2Whf1R7e7vs3LiznTlzpuzqGhoaALh+I5FIJOvJ65PJpKeCCjgqz4knngjATYUza9YsSfdBX1oTllyjctjS0iL+t3TaZ4DI8uXLRTGkj4npf/bII48AcMs/jh07VsqZmT6NvUFn7cLc9S5evBiAqwqNHj0ab7zxBgA3tQafd15enijsbBPRaFQUFCru1dXVACDBNX6A/o4jR44UHyK2Z96PkSNHShvjjrasrExUVapr3NkXFxf7SkklXn2S6v91110n/th89oDrszpr1iwAbnDk8OHDZUygAtDQ0CDjDz/3xRdfAHD8VVlWmEpBdXW1KE+8r1SgiouL0wpmZBpaQwBXkWL/j0ajaUpdNBqVNsL+TqVs/fr18jeqYwUFBWmlUtn/6+vr05RUwH1GDJjiM6mvr9/pFDOZwivFHws1UF0vLCwU32PeWy/4DBKJhPjWUWVatGhRWhJ4tqFDDz1UVO9sYvvcdqYiBwKBtFKfDPQaP368BHrxHg0YMCDFjx1ASv+h5YnFU2pqarBo0SIA7txCxXGvvfYSK0QuS4OaPqdeJWx5PbSmmffHazyyS1KTziwYfQnOgWwfnDcBVzXm2BmLxdKCeFlMxiRTaQQzuki1c3+GQqEUabgr8LP8rlAoJKY6muX4/+uvv16iNbkoe/DBB1MizQA3Ki0Xg0dntZs/+ugjMQ8xSKq+vl4eMOuFez1c5nl86qmnJCqdJjde51dffSWLWhM6/jO/IwfdRCIhC7beXqSSeDwuk6nddj799FPJZcmFwieffCIdZuPGjQDcxWdra2tacEtVVZXUo+aiz65X7CcWLFggC4mrrroKgJu14pe//KUsyDlpfv3117j99tsBQIIE2e7nzJnjq4W4GVBo9xlG15900knSRufMmQPAmQi5YGVwJPtAY2OjDJxcPA0fPlzM2Qwi/OMf/wjACRpg0BAnLDNY0678NHz48Ky7hCxdulSeK02rvAdeQU/BYFDaNM/brDrG8ZD3JRwOS9+yI/+//PJLuWZzvGRACo/neTQ2NvbqItVrMbJ8+XIJ3uCGnhuXIUOG4C9/+QsA4NlnnwXgBJQyUI6uQhQAFi1aJJW3uLj1gmNyOBzOWgaNrrgzeLF+/XpMnz4dACTHNoOlhg0bJi4tZt5YjqXc6PEZRyIRrF27FoC7QMvPz5eFDINX2ZdWrlwp7hV8Frmgs2cQCASkP9tZhMz2ZC5W7fy5Zv7YHQV59iXszVckEkmrmpWfny/jC4/nRtjMGGQHm/UUNfcriqIoiqIovmOnlVRzt8Hdi5mugg61V1xxBQAncIj1kW0VCEhVAABnZ0+HbqpATz31VNpvm2ZMKk/8Lv4/m+l3uBv94IMPxHxCFY+vgwcPTqu1PmbMGDFTU/GlSmiaHpjDbt68eXLfmI5m8uTJABzzrx0cEQ6HRR1gMIBZgSsX2Ok+vHJfkmAwmLbzmjdvHgBHKeW1U5E26w/zPpimB9tcO3LkSElhRpWA992PbN68Wc6PVaVo+h0/fnya+Wnz5s1iXqN6yPY0b948SWmUC6vCjvAyq3Gc4HMbOXKkmJipro4YMUKumymT2Ma9aGlpkQAk1m2nNWHFihWiKvI7+/XrJ0oT+yaVzFxQWVmZFrDC8/dSJT7++GOcccYZKe9x/PQ63qviHMeNfv36pfQpwupaVOKI17G5xEsxe/bZZzF16lQA3hWP6BI1Y8YMAMDtt98uVaUeffRRAO4YMnfu3LQgMS8XN7ocDRgwQL4r05i/yby4H3zwAQDXlaO0tFRM76wgNWLECHnmVJSpvFdXV6e1kdbWVmk/tMzx88OGDRPFkK42HR0d0l/ozsa5dunSpVl3sesqvIZ4PJ6WCpLk5eV1er62apqfny+qcV9RUr0stQzQtl2ZzGuyc8sC7hjOe5CN8cAfrUdRFEVRFEVRDHqspHLn3d7eLqtv7ua4myouLhYna66+P/zwQ1FSbf8HwFUAqGAcdthh+NnPfgbA9SPzgvWSAXc1b6tM2Uw/RWWqqKgIb7/9NgD3fvB3TznlFFHFWFGmtrZWfGyZlJ+pcOjMDKTuVKiAMtCKibuXLVsmKht3OAUFBfIMqDbzvBoaGnJSW9lWHTrzUUkmk+Ij+NZbb6V8vqGhQe6fGQzE9scUVFSrJ06cKEn/qYw0NTWJ+ka1jm2uvb292z7U2Wb69Om45pprALjpy9gWTj755LTjzz33XFELmaqM1zRx4kTfVcMhN954IwBI36EatWrVKnnWPPdQKCR9gM+XlgbeI5OKigq8/PLLAFzrA/tfSUmJ9BUGfYTDYekjtIJQecqFKtTU1CRtksqNV6UpBvcUFRVJm2b/91JSeU1eBVLMCnhetc35/Qw2sv3U/ADPacyYMZ32Yz5L1hYHIH2M/uxsR0OGDEmzTnmpt3w+9OXMJpdccgn++te/AnDHMM6l0WhUxnumYBw9erQ8e1pZeJ7Dhg2T5001raOjQ+ZOfi/H2EgkIkFRbH/5+fni682k7qafsl+KG7B9JBKJLvlJeimG/BzvJ9D71oTu4qWkMiaFbcFM1WdXBjQD4tku+J1NTU0Z91FXJVVRFEVRFEXxHT3e4nBHYfowcMdEf6p169al+fNcfvnlmDJlyna/lzs9prc466yzOlVQCX1gTH8g24cim1Go3LmbyfF5LXzdc889RTU9+uijATjRw9zhmX6kgBOJTp8Q3ufzzjuvU5WAkZTc6YRCIdnp8XPc9WzatMkz7VWm4fVxN8r/NzY2iupJ5by+vl7UASpn77zzDgAn6pTplZhCaNOmTXLNVLN5r+i3BbhtsqKiIi2hO30em5ubfaekNjQ0SMQsM0Lw+swk62Tbtm2ijvMesS1kqkxdpnn33XfFt47tkX2msbFR0ssxLUoymRRFj1HVzO4xduxY8TWcNm0aACfjB33x6DtIhchMz8N+sccee0hqNrvGfS7Kyq5YsSIlmhpwizWYcGwYNWqUnJfd10wVy478NzGjdc0UWDYcmxjhneva7MRUg6je8bzPPffcNDW4s3Q4kydPFnX1/vvvB+D6AANIax9e30EFNpulcnlNL7zwgviKMiKfY0FFRYX0F1oGqqurZd6xVb9YLCbP1MzKQ4sV+xytGfRzB7xLi3Kspo8qkF6mubcwsxGw//OaTX9VUyUFUq0ndiovwJ9ltbvDtm3b0uIyaK0rKChIKwARj8fTxhfex9ra2pRnnwl6vEh97rnnADiO9DQFMfcaB8xkMikXxkZx0EEHeaY4AZxORVM3000xtyeQHmjl5cBeVFQkHZINyaw1m0vM3JW5ojsNJBem37Vr10qaIJqYmPLpm2++kcGWi42ysjLJwfjaa68BcCtClZeXS8AUJ4Py8nIxcdLlg//fsmWLuFow3VQ4HJZBhRMT28eGDRt8V0knHA7L4pKBYYTmOft4bpR++MMfAnBTtuViQ9IduDG57LLLZCIzc3nylc+Hx7S0tEib4PPi37Zu3SqBlldeeSUAJxfq7NmzAbjBgxxkm5ubZeFqpqyy06d88sknKZ/PJl5ppryCMnhu5kaXY42Z55CYaac4LvO3zMW41yKWsDINJ3yvxXOmSSaTac/DK+jjtNNOk/eWLl0KwM1H7bWwvOOOOwA4k+/1118PIHVxSrzybHpV7wKcMS1b0O0tFovJppvnxHGxvb1dng0339FoVBaZ3Fzw/FtaWuTecn5NJpPSVthPOGbuv//+OOSQQwC498Xr3vL3KioqxIWnt8cfM+2U7bZjbuDs6/FKS2Wa/9mX7D7VV2hra5MxlgII/2+unXgf+vXrl2L6N//GuTeTqLlfURRFURRF8R09VlKp2JWXl6ckPgZchWTUqFGeMjJ3t6yJzACPsrIynHnmmQCA++67Tz7D1bpXoJVNXV1dWkAMA4ayGTilePPee++J2sBk2Az0Wr9+vZhVqWDk5+eLyYg7e7a11tZWUZRo2tu0aZOoF3T1oMr22WefyXF8LxAIyHfYqkl1dbVntZ3eZODAgZK83wzwAtxrMikrKxOlmgGMvP/ZVHl6Aq/n+OOPl3GCLgpUviORiJw320N5ebkcT6sMzf81NTW4+eabAbjBMHPmzBGVlAo8FdtEIiEKD9WU5uZmUaqoSrEd5cIqwhRJO4LKUENDQ1qSfTutFpCq+vFa7cIZ8Xi8UyWVY3Yu2VHyegZMfv/73weQqm5R8WEKrcceewz33nsvAEgquqlTp3ap33eWIJ73OZvVyI4//ngAzrhmF3eg21R5ebmoWqZJm22F7Z9zqumeQPUzGAympWbimNPc3CzzOy1xkUhE2hF/m8+rsLCwU/eRXMBzMosN2Up4Z2kRd1ScgZ+l2tzXlNStW7fK8+O12i5x5nvJZDLFndCE7dD8rp1FlVRFURRFURTFd/RYSWUwBxP6mlB9qK2tFRWE6ZTq6upkF8hV97XXXgvA8bnxCm7aXtoXr5X6a6+9Jrs+OvVzF0nfWSX7MJipsLBQnvfDDz8MwN2Rtba2yi6U6qZZ1pIBQFTLVq1aJf6t9H2JxWLyWaonbC/9+vVL28UzIAdIV5G8/NF6G1MZYbvmjt3LslBcXCx/5z3iNfdWkMv2oIpz2mmniR8yU0pxbGhqapL0NhxXtm7dKtfEtsRnPn369JT0VUBqkQuzJjvgqCr0Z6XfaSgUEj+6ww8/HIDr89re3t6rgSBmInKOa/X19XK/mAqJfchMN+XlR8nj2Ie2Fzi4PR/MbMLnvXr1arnnpkUEcJ4jFT2mrkskEmI9u/XWWwG4Svvzzz8vQXannnoqADflX3ew5yQqqNkMrGMg4LRp0/D6668DAB544AEAbkAg74FJKBRKU7xMP9uuBP6YwWP0f6XPq+mjaKcm2rhxo6Sc7C1sa25RUZGcJzHbtV0qtbO0c4FAQI63v7Ov4KWkmvE/vH7T+sLj7JRcZvvLlJKalQRm7Kj77bef5CWkqSLb9HaHUBwYrW1W6mHD5+KpoaFBJg8GVTU0NMhChQE/ZjYCLszMQZd/t2uwMzAKcDvRoEGDZALj53hcripwdYeSkpKUqFsgNSeijTlhkO64y+QSns/o0aMlcpnPZsKECQCcZ8IIZjPQkotN06zI99kOeHy/fv3SolDZFgcMGCDtgBkABgwYIHkD+dvcMPkp+wMX+S0tLWmLbxIIBNIWmOZ77Bdc8HZ0dHguRLe3ODUXzZmGLh8vvviiLFJ5nRwbCgsLZRHCBVtlZaVEoTMwkwF2y5Ytw9133w0AGa0MRTFm/vz5OOecczL2vduDrjx8JW1tbRI0RqFg3bp10r9s83Z7e7sEPHOTXlJSInM4Ny/sP4FAQMYdfsfq1avl3/wc3WWKiookk01vYS/CvRadZiCUnbXArELl5QpjL+z8jn19NTU1aVkOSEdHR0p+ZcBpC3zPvh9ewbw7i5r7FUVRFEVRFN/hj1IQyi4H1YTVq1eLaYomWu7E29vbRfXkjiwvL0/UVcJdfGlpqfybu2OzQo6domzIkCGisHHnV1JSImodd438/z/+8Q8cccQRAPxR2x5INU1RPeqM4uLitLQgfOW98Atm3l7bUd9MO2U/CzOwyVaN+/fvL8dz55+fny9mYipDbGOJRCKl7jngmAfZRplrku0zW3XZu4qpWvJaCgoKRAnlfeO9NVNK8T2zspoZMMXje3o+mYb5Pm+77bas/UZPsdvdLbfc0ktnkkphYaGkYONrtjnuuONy8js9heOnqR6bgZOA245jsZinkkrs9p5IJDpVWfsCW7duTcv/aprz7WvOy8uT8dp2iWAub/M7dhZVUhVFURRFURTfoUqqklXGjBkjCdBN31LASTfEdCbcgYXD4TQnf+7aCgsLRQ2k+jlixIiUxO9Aag1qqk1mvWn6nlJFMpU6v6mNpaWlogxz92/XSzbxqpnNHa3fro2YAY1UMKkaNzc3i8+hWRjEToFi+ufyOnl/ioqK0lJH8dl3dHSkpeVZsGBBmi8e73k2UwxlAl4nFVVTiWc7CgaDaeoP1ZJoNCoqNcmm36miZBu2f7PN23MM8RpTTUXQq+JUX/NJtZk7d66MsfTdtuMgzPeSyWRaqjGOi9u7rzuDKqmKoiiKoiiK71AlVckqZp1f7jgZKc3XbPwmsRWjSCQiqqq5M+T55aI2e3ehqsj7R9XQK3VMNBqV97mz56tfamh3hq2KmxkackVPUhL1JsFgUFJmMZsK0wSZNezNEqZ8n6opFVh+TlF2FeziBmapT3sOSCQSopKa/pacR2ilMcuj2mVl/Y6tFl999dVSVIfp/roaB8Fxg/dx8eLFGTxTB12kKlmlN8yEXr9JM8TAgQN9uRDtDC7m7br2tlkWcNI50WTDQZmuEdnaFCi9y6WXXopnnnkGgLvINIOquKnhwrSxsTElRRDgBjUefPDBkmtVUXYF7MWp6fZEtx8ek0gkZMFliiu22GEuSO1cw37HNsmffPLJOPnkkwFAqhsuXLgQgOMex6BTBlUGAgG5b9z4csxgNdFMouZ+RVEURVEUxXfkeTkKK4qiKIqiKEpvokqqoiiKoiiK4jt0kaooiqIoiqL4Dl2kKoqiKIqiKL5DF6mKoiiKoiiK79BFqqIoiqIoiuI7dJGqKIqiKIqi+I7/B2soDiyhIuPpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-jamaica",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API\n",
    "#### A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "Now let’s build the neural network! Here is a classification MLP with two hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "worse-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) #Flatten layer\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) #Hidden layer\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) #Hidden layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) #Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-intelligence",
   "metadata": {},
   "source": [
    "Let’s go through this code line by line:\n",
    "- The first line creates a Sequential model. \n",
    "    - This is the simplest kind of Keras model for neural networks that are just composed of a single stack of layers connected sequentially. \n",
    "    - This is called the Sequential API.\n",
    "- Next, we build the first layer and add it to the model. \n",
    "    - It is a **Flatten layer** whose role is to convert each input image into a 1D array: if it receives input data X, it computes X.reshape(-1, 1).\n",
    "    - This layer does not have any parameters; it is just there to do some simple preprocessing. \n",
    "    - Since it is the first layer in the model, you should specify the input_shape, which doesn’t include the batch size, only the shape of the instances. \n",
    "        - Alternatively, you could add a keras.layers.InputLayer as the first layer, setting input_shape=[28,28].\n",
    "- Next we add a **Dense hidden layer** with 300 neurons. \n",
    "    - It will use the **ReLU activation function**. \n",
    "    - Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. \n",
    "    - It also manages a vector of bias terms (one per neuron).\n",
    "- Then we add a **second Dense hidden layer** with 100 neurons, also using the **ReLU activation function**.\n",
    "- **Finally, we add a Dense output layer with 10 neurons (one per class), using the softmax activation function (because the classes are exclusive).**\n",
    "\n",
    "### TIP\n",
    "Specifying **activation=\"relu\"** is equivalent to specifying **activation=keras.activations.relu**.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-stage",
   "metadata": {},
   "source": [
    "#### Instead of adding the layers one by one as we just did, you can pass a list of layers when creating the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "thermal-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "secure-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-pittsburgh",
   "metadata": {},
   "source": [
    "Note that Dense layers often have a lot of parameters. \n",
    "- For example, the first hidden layer has 784 × 300 connection weights, plus 300 bias terms, which adds up to 235,500 parameters! \n",
    "    - This gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-controversy",
   "metadata": {},
   "source": [
    "- The model’s summary() method displays all the model’s layers, including each layer’s name (which is automatically generated unless you set it when creating the layer), its output shape (**None means the batch size can be anything**), and its number of parameters. \n",
    "- The summary ends with the total number of parameters, including trainable and non-trainable parameters.\n",
    "    - Here we only have trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "scientific-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sticky-bread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-blocking",
   "metadata": {},
   "source": [
    "You can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch it by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "heated-identifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x11f6bcb2488>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x11f6bcb2848>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x11f6bbfe108>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x11f50e76488>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "executive-separate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "living-postcard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-correction",
   "metadata": {},
   "source": [
    "- All the parameters of a layer can be accessed using its **get_weights()** and **set_weights()** methods. \n",
    "    - For a Dense layer, this includes both the connection weights and the bias terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "measured-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "unlimited-given",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dutch-bible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "equipped-cartoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pacific-filling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-female",
   "metadata": {},
   "source": [
    "- Notice that the **Dense layer initialized the connection weights randomly** (which is needed to break symmetry, as we discussed earlier), and the **biases were initialized to zeros**, which is fine. \n",
    "- If you ever want to use a different initialization method, you can set **kernel_initializer** (kernel is another name for the matrix of connection weights) or **bias_initializer** when creating the layer.\n",
    "### NOTE\n",
    "- The shape of the weight matrix depends on the number of inputs. \n",
    "    - This is why it is recommended to specify the input_shape when creating the first layer in a Sequential model. \n",
    "    - However, if you do not specify the input shape, it’s OK: Keras will simply wait until it knows the input shape before it actually builds the model. \n",
    "    - This will happen either when you feed it actual data (e.g., during training), or when you call its build() method. \n",
    "    - Until the model is really built, the layers will not have any weights, and you will not be able to do certain things (such as print the model summary or save the model). \n",
    "    - So, if you know the input shape when creating the model, it is best to specify it.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-geometry",
   "metadata": {},
   "source": [
    "### Compiling the model\n",
    "- After a model is created, you must call its **compile() method to specify the loss function and the optimizer to use.** \n",
    "- Optionally, you can specify a list of extra metrics to compute during training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "regular-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "             optimizer=\"sgd\", \n",
    "             metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-framing",
   "metadata": {},
   "source": [
    "This is equivalent to:\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              \n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-exhaust",
   "metadata": {},
   "source": [
    "This code requires some explanation. \n",
    "- First, we use the **\"sparse_categorical_crossentropy\" loss because we have sparse labels(i.e., for each instance, there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. **\n",
    "    - If instead we had **one target probability per class for each instance** (such as one-hot vectors, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need to use the **\"categorical_crossentropy\" loss** instead. \n",
    "    - If we were doing **binary classification (with one or more binary labels)**, then we would use the **\"sigmoid\" (i.e., logistic) activation function in the output layer instead of the \"softmax\" activation function**, and we would use the **\"binary_crossentropy\"** loss.\n",
    "- Regarding the **optimizer, \"sgd\" means that we will train the model using simple Stochastic Gradient Descent.** \n",
    "    - In other words, Keras will perform the backpropagation algorithm described earlier (i.e., reverse-mode autodiff plus Gradient Descent).\n",
    "\n",
    "### TIP\n",
    "If you want to **convert sparse labels (i.e., class indices) to one-hot vector labels**, use the **keras.utils.to_categorical()** function. \n",
    "\n",
    "**To go the other way round, use the np.argmax() function with axis=1.**\n",
    "### NOTE\n",
    "- **When using the SGD optimizer, it is important to tune the learning rate.** \n",
    "- So, you will generally want to use **optimizer=keras.optimizers.SGD(lr=???)** to set the learning rate, rather than optimizer=\"sgd\", which defaults to lr=0.01.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-jewel",
   "metadata": {},
   "source": [
    "Finally, since this is a classifier, it’s useful to measure its \"accuracy\" during training and evaluation.\n",
    "## Training and evaluating the model\n",
    "Now the model is ready to be trained. For this we simply need to call its fit() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "confident-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 13s 5ms/step - loss: 1.0187 - accuracy: 0.6805 - val_loss: 0.5213 - val_accuracy: 0.8226\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5027 - accuracy: 0.8262 - val_loss: 0.4353 - val_accuracy: 0.8526\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4483 - accuracy: 0.8426 - val_loss: 0.5329 - val_accuracy: 0.7986\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4207 - accuracy: 0.8528 - val_loss: 0.3917 - val_accuracy: 0.8658\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4060 - accuracy: 0.8581 - val_loss: 0.3744 - val_accuracy: 0.8700\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3754 - accuracy: 0.8673 - val_loss: 0.3712 - val_accuracy: 0.8734\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3653 - accuracy: 0.8714 - val_loss: 0.3617 - val_accuracy: 0.8736\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3481 - accuracy: 0.8753 - val_loss: 0.3851 - val_accuracy: 0.8620\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3485 - accuracy: 0.8757 - val_loss: 0.3579 - val_accuracy: 0.8724\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3295 - accuracy: 0.8834 - val_loss: 0.3424 - val_accuracy: 0.8776\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3218 - accuracy: 0.8839 - val_loss: 0.3446 - val_accuracy: 0.8778\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3120 - accuracy: 0.8876 - val_loss: 0.3307 - val_accuracy: 0.8836\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3051 - accuracy: 0.8894 - val_loss: 0.3272 - val_accuracy: 0.8880\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2990 - accuracy: 0.8921 - val_loss: 0.3417 - val_accuracy: 0.8778\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2932 - accuracy: 0.8949 - val_loss: 0.3216 - val_accuracy: 0.8848\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2859 - accuracy: 0.8983 - val_loss: 0.3101 - val_accuracy: 0.8894\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2777 - accuracy: 0.9009 - val_loss: 0.3562 - val_accuracy: 0.8724\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2775 - accuracy: 0.9001 - val_loss: 0.3149 - val_accuracy: 0.8892\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2741 - accuracy: 0.9024 - val_loss: 0.3116 - val_accuracy: 0.8918\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2696 - accuracy: 0.9041 - val_loss: 0.3277 - val_accuracy: 0.8806\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2672 - accuracy: 0.9052 - val_loss: 0.3067 - val_accuracy: 0.8940\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2615 - accuracy: 0.9053 - val_loss: 0.2965 - val_accuracy: 0.8964\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2551 - accuracy: 0.9073 - val_loss: 0.2990 - val_accuracy: 0.8942\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2452 - accuracy: 0.9118 - val_loss: 0.3077 - val_accuracy: 0.8884\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2492 - accuracy: 0.9115 - val_loss: 0.2971 - val_accuracy: 0.8944\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2426 - accuracy: 0.9138 - val_loss: 0.3050 - val_accuracy: 0.8906\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2374 - accuracy: 0.9162 - val_loss: 0.3011 - val_accuracy: 0.8948\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2317 - accuracy: 0.9167 - val_loss: 0.2996 - val_accuracy: 0.8942\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2285 - accuracy: 0.9179 - val_loss: 0.3030 - val_accuracy: 0.8940\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2254 - accuracy: 0.9203 - val_loss: 0.3011 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-debate",
   "metadata": {},
   "source": [
    "### TIP\n",
    "- Instead of passing a validation set using the validation_data argument, you could set validation_split to the ratio of the training set that you want Keras to use for validation. \n",
    "    - For example, validation_split=0.1 tells Keras to use the last 10% of the data (before shuffling) for validation.\n",
    "***\n",
    "- If the training set was very skewed, with some classes being overrepresented and others underrepresented, it would be useful to set the **class_weight argument when calling the fit()** method, which would give a larger weight to underrepresented classes and a lower weight to overrepresented classes. \n",
    "- These weights would be used by Keras when computing the loss. \n",
    "- If you need per-instance weights, set the **sample_weight** argument (it supersedes class_weight). \n",
    "    - Per-instance weights could be useful if some instances were labeled by experts while others were labeled using a crowdsourcing platform: you might want to give more weight to the former. \n",
    "    - You can also provide sample weights (but not class weights) for the validation set by adding them as a third item in the validation_data tuple.\n",
    "- The fit() method returns a History object containing the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "least-bumper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "intended-asset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "future-indie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "personal-collective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-packet",
   "metadata": {},
   "source": [
    "#### Learning curves: the mean training loss and accuracy measured over each epoch, and the mean validation loss and accuracy measured at the end of each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-perth",
   "metadata": {},
   "source": [
    "- The validation error is computed at the end of each epoch, while the training error is computed using a running mean during each epoch. \n",
    "    - So the training curve should be shifted by half an epoch to the left. \n",
    "    - If you do that, you will see that the training and validation curves overlap almost perfectly at the beginning of training.\n",
    "\n",
    "### TIP\n",
    "When plotting the training curve, it should be shifted by half an epoch to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-account",
   "metadata": {},
   "source": [
    "- The training set performance ends up beating the validation performance, as is generally the case when you train for long enough. \n",
    "- You can tell that the model has not quite converged yet, as the validation loss is still going down, so you should probably continue training. \n",
    "- It’s as simple as calling the fit() method again, since Keras just continues training where it left off (you should be able to reach close to 89% validation accuracy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "defensive-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3356936573982239, 0.8827999830245972]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-shade",
   "metadata": {},
   "source": [
    "### Using the model to make predictions\n",
    "Next, we can use the model’s predict() method to make predictions on new instances. Since we don’t have actual new instances, we will just use the first three instances of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "yellow-shooting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-absorption",
   "metadata": {},
   "source": [
    "- As you can see, for each instance the model estimates one probability per class, from class 0 to class 9. \n",
    "    - For example, for the first image it estimates that the probability of class 9 (ankle boot) is 96%, the probability of class 5 (sandal) is 3%, the probability of class 7 (sneaker) is 1%, and the probabilities of the other classes are negligible. \n",
    "    - In other words, it “believes” the first image is footwear, most likely ankle boots but possibly sandals or sneakers. \n",
    "    - If you only care about the class with the highest estimated probability (even if that probability is quite low), then you can use the predict_classes() method instead:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-malaysia",
   "metadata": {},
   "source": [
    "**Warning:** model.predict_classes(X_new) is deprecated. It is replaced with np.argmax(model.predict(X_new), axis=-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "stainless-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_new) # deprecated\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "accepted-property",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "monetary-transfer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-excerpt",
   "metadata": {},
   "source": [
    "Here, the classifier actually classified all three images correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "canadian-desperate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-franchise",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API\n",
    "#### A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "Let's load, split and scale the California housing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "certified-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sharp-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-advertising",
   "metadata": {},
   "source": [
    "- Using the Sequential API to build, train, evaluate, and use a regression MLP to make predictions is quite similar to what we did for classification.\n",
    "- The main differences are the fact that the **output layer has a single neuron (since we only want to predict a single value) and uses no activation function**, and the **loss function is the mean squared error.** \n",
    "- Since the dataset is quite noisy, we just use a single hidden layer with fewer neurons than before, to avoid overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "danish-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 2.2656 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7413 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6604 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6245 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5770 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5609 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5500 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5200 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5051 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4910 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4656 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4693 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4537 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4586 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4612 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4449 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4407 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4184 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4128 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]), \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "first-excuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "coated-desert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3885665],\n",
       "       [1.6792021],\n",
       "       [3.1022792]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-bosnia",
   "metadata": {},
   "source": [
    "- As you can see, the Sequential API is quite easy to use. \n",
    "- However, although Sequential models are extremely common, it is sometimes useful to build neural networks with more complex topologies, or with multiple inputs or outputs. \n",
    "    - For this purpose, Keras offers the Functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-conversation",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API\n",
    "#### Not all neural network models are simply sequential. Some may have complex topologies. Some may have multiple inputs and/or multiple outputs. For example, a Wide & Deep neural network connects all or part of the inputs directly to the output layer.\n",
    "<img src=\"10-14.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "seeing-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "periodic-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-poland",
   "metadata": {},
   "source": [
    "Let’s go through each line of this code:\n",
    "- First, we need to create an Input object. \n",
    "    - This is a specification of the kind of input the model will get, including its shape and dtype. \n",
    "- Next, we create a Dense layer with 30 neurons, using the ReLU activation function. \n",
    "    - As soon as it is created, notice that we call it like a function, passing it the input. \n",
    "    - This is why this is called the Functional API. \n",
    "    - Note that we are just telling Keras how it should connect the layers together; no actual data is being processed yet.\n",
    "- We then create a second hidden layer, and again we use it as a function. \n",
    "    - Note that we pass it the output of the first hidden layer.\n",
    "- Next, we create a Concatenate layer, and once again we immediately use it like a function, to concatenate the input and the output of the second hidden layer. \n",
    "- Then we create the output layer, with a single neuron and no activation function, and we call it like a function, passing it the result of the concatenation.\n",
    "- Lastly, we create a Keras Model, specifying which inputs and outputs to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "relevant-employment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "monetary-herald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.9731 - val_loss: 3.3940\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7638 - val_loss: 0.9360\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6045 - val_loss: 0.5649\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5862 - val_loss: 0.5712\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5452 - val_loss: 0.5045\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5243 - val_loss: 0.4831\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5185 - val_loss: 0.4639\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4947 - val_loss: 0.4638\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4782 - val_loss: 0.4421\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4708 - val_loss: 0.4313\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4585 - val_loss: 0.4345\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4481 - val_loss: 0.4168\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4476 - val_loss: 0.4230\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4361 - val_loss: 0.4047\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4392 - val_loss: 0.4078\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.3938\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4277 - val_loss: 0.3952\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4216 - val_loss: 0.3860\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4033 - val_loss: 0.3827\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3939 - val_loss: 0.4054\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4032\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-workshop",
   "metadata": {},
   "source": [
    "What if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path? \n",
    "- In this case, one solution is to use multiple inputs. \n",
    "    - For example, suppose we want to send five features through the wide path (features 0 to 4), \n",
    "    - and six features through the deep path (features 2 to 7):\n",
    "    \n",
    "Note that 3 features will go through both (features 2, 3 and 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "honey-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-marker",
   "metadata": {},
   "source": [
    "<img src=\"10-15.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-exemption",
   "metadata": {},
   "source": [
    "- Now we can compile the model as usual, but **when we call the fit() method, instead of passing a single input matrix X_train, we must pass a pair of matrices (X_train_A, X_train_B): one per input.** \n",
    "- **The same is true for X_valid, and also for X_test and X_new when you call evaluate() or predict():**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "continued-terrorism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.9131 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8125 - val_loss: 0.6710\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6876 - val_loss: 0.6169\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6241 - val_loss: 0.5710\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5770 - val_loss: 0.5420\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5416 - val_loss: 0.5176\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5449 - val_loss: 0.5065\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5136 - val_loss: 0.4790\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4917 - val_loss: 0.4564\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4781 - val_loss: 0.4451\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4719 - val_loss: 0.4295\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4598 - val_loss: 0.4228\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4609 - val_loss: 0.4181\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4579 - val_loss: 0.4147\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4570 - val_loss: 0.4125\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4603 - val_loss: 0.4095\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4482 - val_loss: 0.4111\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4091\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4233 - val_loss: 0.4097\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4182 - val_loss: 0.4174\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4295\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-relation",
   "metadata": {},
   "source": [
    "There are many use cases in which you may want to have multiple outputs:\n",
    "- The task may demand it. \n",
    "    - For instance, you may want to locate and classify the main object in a picture. \n",
    "    - This is both a regression task (finding the coordinates of the object’s center, as well as its width and height) and a classification task.\n",
    "- Similarly, you may have multiple independent tasks based on the same data. \n",
    "    - Sure, you could train one neural network per task, but in many cases you will get better results on all tasks by training a single neural network with one output per task. \n",
    "    - This is because the neural network can learn features in the data that are useful across tasks. \n",
    "    - For example, you could perform multitask classification on pictures of faces, using one output to classify the person’s facial expression (smiling, surprised, etc.) and another output to identify whether they are wearing glasses or not.\n",
    "- Another use case is as a regularization technique (i.e., a training constraint whose objective is to reduce overfitting and thus improve the model’s ability to generalize). \n",
    "    - For example, you may want to add some auxiliary outputs in a neural network architecture (see Figure 10-16) to ensure that the underlying part of the network learns something useful on its own, without relying on the rest of the network.\n",
    "\n",
    "<img src=\"10-16.png\">\n",
    "\n",
    "#### Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fiscal-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "behind-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-pregnancy",
   "metadata": {},
   "source": [
    "- Each output will need its own loss function. Therefore, when we compile the model, we should pass a list of losses (if we pass a single loss, Keras will assume that the same loss must be used for all outputs). \n",
    "    - By default, Keras will compute all these losses and simply add them up to get the final loss used for training.\n",
    "- We care much more about the main output than about the auxiliary output (as it is just used for regularization), so we want to give the main output’s loss a much greater weight. \n",
    "    - Fortunately, it is possible to set all the loss weights when compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "julian-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "third-solid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 3.4633 - main_output_loss: 3.3289 - aux_output_loss: 4.6732 - val_loss: 1.6233 - val_main_output_loss: 0.8468 - val_aux_output_loss: 8.6117\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9807 - main_output_loss: 0.7503 - aux_output_loss: 3.0537 - val_loss: 1.5163 - val_main_output_loss: 0.6836 - val_aux_output_loss: 9.0109\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7742 - main_output_loss: 0.6290 - aux_output_loss: 2.0810 - val_loss: 1.4639 - val_main_output_loss: 0.6229 - val_aux_output_loss: 9.0326\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6952 - main_output_loss: 0.5897 - aux_output_loss: 1.6449 - val_loss: 1.3388 - val_main_output_loss: 0.5481 - val_aux_output_loss: 8.4552\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6469 - main_output_loss: 0.5508 - aux_output_loss: 1.5118 - val_loss: 1.2177 - val_main_output_loss: 0.5194 - val_aux_output_loss: 7.5030\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6120 - main_output_loss: 0.5251 - aux_output_loss: 1.3943 - val_loss: 1.0935 - val_main_output_loss: 0.5106 - val_aux_output_loss: 6.3396\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6114 - main_output_loss: 0.5256 - aux_output_loss: 1.3833 - val_loss: 0.9918 - val_main_output_loss: 0.5115 - val_aux_output_loss: 5.3151\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5765 - main_output_loss: 0.5024 - aux_output_loss: 1.2439 - val_loss: 0.8733 - val_main_output_loss: 0.4733 - val_aux_output_loss: 4.4740\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5535 - main_output_loss: 0.4811 - aux_output_loss: 1.2057 - val_loss: 0.7832 - val_main_output_loss: 0.4555 - val_aux_output_loss: 3.7323\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5456 - main_output_loss: 0.4708 - aux_output_loss: 1.2189 - val_loss: 0.7170 - val_main_output_loss: 0.4604 - val_aux_output_loss: 3.0262\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5297 - main_output_loss: 0.4587 - aux_output_loss: 1.1684 - val_loss: 0.6510 - val_main_output_loss: 0.4293 - val_aux_output_loss: 2.6468\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5181 - main_output_loss: 0.4501 - aux_output_loss: 1.1305 - val_loss: 0.6051 - val_main_output_loss: 0.4310 - val_aux_output_loss: 2.1722\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5100 - main_output_loss: 0.4487 - aux_output_loss: 1.0620 - val_loss: 0.5644 - val_main_output_loss: 0.4161 - val_aux_output_loss: 1.8992\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5064 - main_output_loss: 0.4459 - aux_output_loss: 1.0503 - val_loss: 0.5354 - val_main_output_loss: 0.4119 - val_aux_output_loss: 1.6466\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5027 - main_output_loss: 0.4452 - aux_output_loss: 1.0207 - val_loss: 0.5124 - val_main_output_loss: 0.4047 - val_aux_output_loss: 1.4812\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5057 - main_output_loss: 0.4480 - aux_output_loss: 1.0249 - val_loss: 0.4934 - val_main_output_loss: 0.4034 - val_aux_output_loss: 1.3035\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4931 - main_output_loss: 0.4360 - aux_output_loss: 1.0075 - val_loss: 0.4801 - val_main_output_loss: 0.3984 - val_aux_output_loss: 1.2150\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4922 - main_output_loss: 0.4352 - aux_output_loss: 1.0053 - val_loss: 0.4694 - val_main_output_loss: 0.3962 - val_aux_output_loss: 1.1279\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4658 - main_output_loss: 0.4139 - aux_output_loss: 0.9323 - val_loss: 0.4580 - val_main_output_loss: 0.3936 - val_aux_output_loss: 1.0372\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4589 - main_output_loss: 0.4072 - aux_output_loss: 0.9243 - val_loss: 0.4655 - val_main_output_loss: 0.4048 - val_aux_output_loss: 1.0118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, \n",
    "                   validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-seven",
   "metadata": {},
   "source": [
    "- Now when we train the model, we need to provide labels for each output. \n",
    "- In this example, the main output and the auxiliary output should try to predict the same thing, so they should use the same labels. \n",
    "    - So instead of passing y_train, we need to pass (y_train, y_train) (and the same goes for y_valid and y_test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "urban-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4668 - main_output_loss: 0.4178 - aux_output_loss: 0.9082\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000011F4A8075E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-bunch",
   "metadata": {},
   "source": [
    "## Using the Subclassing API to Build Dynamic Models\n",
    "- **Both the Sequential API and the Functional API are declarative:** you start by declaring which layers you want to use and how they should be connected, and only then can you start feeding the model some data for training or inference. \n",
    "    - This has many advantages: the model can easily be saved, cloned, and shared; its structure can be displayed and analyzed; the framework can infer shapes and check types, so errors can be caught early (i.e., before any data ever goes through the model). \n",
    "    - It’s also fairly easy to debug, since the whole model is a static graph of layers. \n",
    "- But the flip side is just that: it’s static. Some models involve loops, varying shapes, conditional branching, and other dynamic behaviors. \n",
    "    - **For such cases, or simply if you prefer a more imperative programming style, the Subclassing API is for you.**\n",
    "- Simply subclass the Model class, create the layers you need in the constructor, and use them to perform the computations you want in the call() method. \n",
    "    - **For example, creating an instance of the following WideAndDeepModel class gives us an equivalent model to the one we just built with the Functional API.** \n",
    "    - You can then compile it, evaluate it, and use it to make predictions, exactly like we just did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "christian-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "unavailable-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 3.3855 - output_1_loss: 3.3304 - output_2_loss: 3.8821 - val_loss: 2.1435 - val_output_1_loss: 1.1581 - val_output_2_loss: 11.0117\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.0790 - output_1_loss: 0.9329 - output_2_loss: 2.3942 - val_loss: 1.7567 - val_output_1_loss: 0.8205 - val_output_2_loss: 10.1825\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8644 - output_1_loss: 0.7583 - output_2_loss: 1.8194 - val_loss: 1.5664 - val_output_1_loss: 0.7913 - val_output_2_loss: 8.5419\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7850 - output_1_loss: 0.6979 - output_2_loss: 1.5689 - val_loss: 1.3088 - val_output_1_loss: 0.6549 - val_output_2_loss: 7.1933\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7294 - output_1_loss: 0.6499 - output_2_loss: 1.4452 - val_loss: 1.1357 - val_output_1_loss: 0.5964 - val_output_2_loss: 5.9898\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6880 - output_1_loss: 0.6092 - output_2_loss: 1.3974 - val_loss: 1.0036 - val_output_1_loss: 0.5937 - val_output_2_loss: 4.6933\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6918 - output_1_loss: 0.6143 - output_2_loss: 1.3899 - val_loss: 0.8904 - val_output_1_loss: 0.5591 - val_output_2_loss: 3.8714\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6504 - output_1_loss: 0.5805 - output_2_loss: 1.2797 - val_loss: 0.8009 - val_output_1_loss: 0.5243 - val_output_2_loss: 3.2903\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6270 - output_1_loss: 0.5574 - output_2_loss: 1.2533 - val_loss: 0.7357 - val_output_1_loss: 0.5144 - val_output_2_loss: 2.7275\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6160 - output_1_loss: 0.5456 - output_2_loss: 1.2495 - val_loss: 0.6849 - val_output_1_loss: 0.5014 - val_output_2_loss: 2.3370\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5841 - output_1_loss: 0.5188 - output_2_loss: 1.1722\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000011F4B0E44C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10, \n",
    "                   validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "compact-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-screening",
   "metadata": {},
   "source": [
    "- This example looks very much like the Functional API, except we do not need to create the inputs; we just use the input argument to the call() method, and we separate the creation of the layers in the constructor from their usage in the call() method. \n",
    "    - The big difference is that you can do pretty much anything you want in the call() method: for loops, if statements, low-level TensorFlow operations—your imagination is the limit.\n",
    "- This extra flexibility does come at a cost: your **model’s architecture is hidden within the call() method, so Keras cannot easily inspect it; it cannot save or clone it; and when you call the summary() method,** you only get a list of layers, without any information on how they are connected to each other. \n",
    "    - Moreover, Keras cannot check types and shapes ahead of time, and it is easier to make mistakes. \n",
    "    - **So unless you really need that extra flexibility, you should probably stick to the Sequential API or the Functional API.**\n",
    "### TIP\n",
    "#### Keras models can be used just like regular layers, so you can easily combine them to build complex architectures.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-applicant",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model\n",
    "When using the Sequential API or the Functional API, saving a trained Keras model is as simple as it gets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "nearby-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "governing-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]), \n",
    "    keras.layers.Dense(30, activation=\"relu\"), \n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "confirmed-greece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "universal-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-developer",
   "metadata": {},
   "source": [
    "- Keras will use the HDF5 format to save both the model’s architecture (including every layer’s hyperparameters) and the values of all the model parameters for every layer (e.g., connection weights and biases). \n",
    "    - It also saves the optimizer (including its hyperparameters and any state it may have).\n",
    "- You will typically have a script that trains a model and saves it, and one or more scripts (or web services) that load the model and use it to make predictions. \n",
    "    - Loading the model is just as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "surgical-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "periodic-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000011F496F04C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.54002357],\n",
       "       [1.6505971 ],\n",
       "       [3.009824  ]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-purse",
   "metadata": {},
   "source": [
    "### WARNING\n",
    "- **This will work when using the Sequential API or the Functional API**, but unfortunately not when using model subclassing. \n",
    "- You can use save_weights() and load_weights() to at least save and restore the model parameters, but you will need to save and restore everything else yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "embedded-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "expensive-mention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x11f6b90ec48>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-hearing",
   "metadata": {},
   "source": [
    "But what if training lasts several hours? \n",
    "- This is quite common, especially when training on large datasets. \n",
    "    - **In this case, you should not only save your model at the end of training, but also save checkpoints at regular intervals during training, to avoid losing everything if your computer crashes.**\n",
    "    - But how can you tell the fit() method to save checkpoints? \n",
    "        - **Use callbacks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-potato",
   "metadata": {},
   "source": [
    "## Using Callbacks during Training\n",
    "- The fit() method accepts a callbacks argument that lets you specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing each batch. \n",
    "    - For example, the **ModelCheckpoint** callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch:\n",
    "- Moreover, **if you use a validation set during training**, you can set **save_best_only=True** when creating the ModelCheckpoint. \n",
    "    - In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "packed-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "patent-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]), \n",
    "    keras.layers.Dense(30, activation=\"relu\"), \n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-funds",
   "metadata": {},
   "source": [
    "The following code is a simple way to implement **early stopping.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "empirical-defensive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, \n",
    "                   validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-cedar",
   "metadata": {},
   "source": [
    "- Another way to implement early stopping is to simply use the **EarlyStopping callback**. \n",
    "    - It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the **patience** argument), and it will optionally roll back to the best model. \n",
    "    - You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources):\n",
    "- The number of epochs can be set to a large value since training will stop automatically when there is no more progress. \n",
    "    - **In this case, there is no need to restore the best model saved because the EarlyStopping callback will keep track of the best weights and restore them for you at the end of training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dated-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4578 - val_loss: 0.4110\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4376 - val_loss: 0.3996\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4361 - val_loss: 0.3939\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4204 - val_loss: 0.3889\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.3866\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4226 - val_loss: 0.3860\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4135 - val_loss: 0.3793\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4039 - val_loss: 0.3746\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.3723\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.3697\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3912 - val_loss: 0.3669\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3939 - val_loss: 0.3661\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3868 - val_loss: 0.3631\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3878 - val_loss: 0.3660\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3935 - val_loss: 0.3625\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.3592\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3801 - val_loss: 0.3563\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3679 - val_loss: 0.3535\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3709\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.3512\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3605 - val_loss: 0.3699\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.3476\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3561\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.3527\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3700\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3432\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3592\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.3521\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3687 - val_loss: 0.3626\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.3431\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3765\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.3374\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3407\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.3573\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3474 - val_loss: 0.3367\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3689 - val_loss: 0.3425\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3369\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.3515\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3426\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.3677\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3564\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3457\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3623 - val_loss: 0.3433\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3659\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.3286\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3560 - val_loss: 0.3268\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.3439\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3263\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3468 - val_loss: 0.3910\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3337 - val_loss: 0.3275\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3561\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.3237\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3242\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3315 - val_loss: 0.3765\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3289\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3378 - val_loss: 0.3502\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3456\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3473 - val_loss: 0.3445\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3427 - val_loss: 0.3290\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3212 - val_loss: 0.3217\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3351\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3323 - val_loss: 0.3232\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.3566\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3257\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3354 - val_loss: 0.3348\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3560\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3583\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3201 - val_loss: 0.3287\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3203\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3268 - val_loss: 0.3233\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3322 - val_loss: 0.3475\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3224 - val_loss: 0.3407\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.3462\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3310 - val_loss: 0.3347\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.3354\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3297 - val_loss: 0.3274\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3441 - val_loss: 0.3167\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3369 - val_loss: 0.3280\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3635\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3176\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3184 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3528\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3264 - val_loss: 0.3258\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3210 - val_loss: 0.3628\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3192 - val_loss: 0.3376\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3237 - val_loss: 0.3212\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3281 - val_loss: 0.3456\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 0.3158\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3209 - val_loss: 0.3408\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3230 - val_loss: 0.3380\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3341 - val_loss: 0.3214\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                   validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-blink",
   "metadata": {},
   "source": [
    "- If you need extra control, you can easily write your own custom callbacks.\n",
    "    - As an example of how to do that, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect overfitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "wrapped-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "angry-postage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3302 - val_loss: 0.3557\n",
      "\n",
      "val/train: 1.08\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-inside",
   "metadata": {},
   "source": [
    "## Using TensorBoard for Visualization\n",
    "- TensorBoard is a great interactive visualization tool that you can use to view the learning curves during training, compare learning curves between multiple runs, visualize the computation graph, analyze training statistics, view images generated by your model, visualize complex multidimensional data projected down to 3D and automatically clustered for you, and more!\n",
    "- To use it, you must modify your program so that it outputs the data you want to visualize to special binary log files called **event files.**\n",
    "- Each binary data record is called a **summary.**\n",
    "- The TensorBoard server will monitor the log directory, and it will automatically pick up the changes and update the visualizations: **this allows you to visualize live data (with a short delay), such as the learning curves during training.** \n",
    "- In general, you want to point the TensorBoard server to a root log directory and configure your program so that it writes to a different subdirectory every time it runs. \n",
    "    - This way, the same TensorBoard server instance will allow you to visualize and compare data from multiple runs of your program, without getting everything mixed up.\n",
    "- Let’s start by defining the root log directory we will use for our TensorBoard logs, plus a small function that will generate a subdirectory path based on the current date and time so that it’s different at every run.\n",
    "- You may want to include extra information in the log directory name, such as hyperparameter values that you are testing, to make it easier to know what you are looking at in TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "accomplished-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "anonymous-pitch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_03_03-15_01_56'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "valuable-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "alien-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]), \n",
    "    keras.layers.Dense(30, activation=\"relu\"), \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-bowling",
   "metadata": {},
   "source": [
    "The good news is that Keras provides a nice TensorBoard() callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "expensive-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4416 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4295 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4326 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4207 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4248 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4105 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3864 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4042 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3800 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3839 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3843 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                   validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-beverage",
   "metadata": {},
   "source": [
    "- And that’s all there is to it! It could hardly be easier to use. If you run this code, the TensorBoard() callback will take care of creating the log directory for you (along with its parent directories if needed), and during training it will create event files and write summaries to them.\n",
    "- There’s one directory per run, each containing one subdirectory for training logs and one for validation logs. Both contain event files, but the training logs also include profiling traces: this allows TensorBoard to show you exactly how much time the model spent on each part of your model, across all your devices, which is great for locating performance bottlenecks.\n",
    "- Next you need to start the TensorBoard server. \n",
    "    - One way to do this is by running a command in a terminal. If you installed TensorFlow within a virtualenv, you should activate it. \n",
    "    - Next, run the following command at the root of the project (or from anywhere else, as long as you point to the appropriate log directory):\n",
    "\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "- **Alternatively, you can use TensorBoard directly within Jupyter, by running the following commands. The first line loads the TensorBoard extension, and the second line starts a TensorBoard server on port 6006 (unless it is already started) and connects to it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "million-windsor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10880), started 1 day, 5:20:45 ago. (Use '!kill 10880' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3af1421e1ab622f4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3af1421e1ab622f4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "inner-master",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_03_03-15_02_26'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "exact-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "flying-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "theoretical-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7645 - val_loss: 302.8552\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 235170214440035.6875 - val_loss: 1.3230\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3439 - val_loss: 1.3176\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3546 - val_loss: 1.3261\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3513 - val_loss: 1.3154\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3274 - val_loss: 1.3203\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3639 - val_loss: 1.3149\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3487 - val_loss: 1.3157\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3445 - val_loss: 1.3150\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3697 - val_loss: 1.3172\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3622 - val_loss: 1.3174\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3389 - val_loss: 1.3150\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3336 - val_loss: 1.3270\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3429 - val_loss: 1.3195\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3275 - val_loss: 1.3157\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3669 - val_loss: 1.3182\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3645 - val_loss: 1.3223\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3839 - val_loss: 1.3154\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3078 - val_loss: 1.3168\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3215 - val_loss: 1.3151\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3344 - val_loss: 1.3174\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3269 - val_loss: 1.3204\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3590 - val_loss: 1.3164\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3381 - val_loss: 1.3157\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3265 - val_loss: 1.3180\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3532 - val_loss: 1.3195\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3552 - val_loss: 1.3157\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3447 - val_loss: 1.3222\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3379 - val_loss: 1.3267\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3583 - val_loss: 1.3174\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "advanced-typing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10880), started 1 day, 5:21:14 ago. (Use '!kill 10880' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-869b5b97c4c241db\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-869b5b97c4c241db\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-office",
   "metadata": {},
   "source": [
    "- Notice that the training loss went down nicely during both runs, but the second run went down much faster. \n",
    "- Indeed, we used a learning rate of 0.05 (optimizer=keras.optimizers.SGD(lr=0.05)) instead of 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-disclaimer",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters\n",
    "- The flexibility of neural networks is also one of their main drawbacks: there are many hyperparameters to tweak. Not only can you use any imaginable network architecture, but even in a simple MLP you can change the number of layers, the number of neurons per layer, the type of activation function to use in each layer, the weight initialization logic, and much more. \n",
    "    - How do you know what combination of hyperparameters is the best for your task?\n",
    "- **One option is to simply try many combinations of hyperparameters and see which one works best on the validation set (or use K-fold cross-validation).**\n",
    "    - For example, we can use **GridSearchCV or RandomizedSearchCV** to explore the hyperparameter space.\n",
    "    - To do this, we need to wrap our Keras models in objects that mimic regular Scikit-Learn regressors.\n",
    "    - The first step is to create a function that will build and compile a Keras model, given a set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "palestinian-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "three-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-criterion",
   "metadata": {},
   "source": [
    "- This function creates a simple Sequential model for univariate regression (only one output neuron), with the given input shape and the given number of hidden layers and neurons, and it compiles it using an SGD optimizer configured with the specified learning rate. \n",
    "- It is good practice to provide reasonable defaults to as many hyperparameters as you can, as Scikit-Learn does.\n",
    "- Next, **let’s create a KerasRegressor based on this build_model() function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fancy-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-there",
   "metadata": {},
   "source": [
    "- The KerasRegressor object is a thin wrapper around the Keras model built using build_model(). Since we did not specify any hyperparameters when creating it, it will use the default hyperparameters we defined in build_model(). \n",
    "- Now we can use this object like a regular Scikit-Learn regressor: we can train it using its fit() method, then evaluate it using its score() method, and use it to make predictions using its predict() method, as you can see in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "vocational-lexington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 1.5673 - val_loss: 20.7721\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3216 - val_loss: 5.0266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5972 - val_loss: 0.5490\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4985 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4608 - val_loss: 0.4188\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4410 - val_loss: 0.4129\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4463 - val_loss: 0.4004\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4283 - val_loss: 0.3944\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4139 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.4071\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3992 - val_loss: 0.3855\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4136\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 0.3997\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.3818\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3948 - val_loss: 0.3829\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3981 - val_loss: 0.3739\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.4022\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3873\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.3768\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3634 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.3927\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.4237\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.3523\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3676 - val_loss: 0.3842\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.4162\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.3980\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.3474\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3920\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.3566\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.4191\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3721\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.3948\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3423\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3547 - val_loss: 0.3453\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.4068\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3417\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3786 - val_loss: 0.3787\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3540 - val_loss: 0.3379\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.3419\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3705 - val_loss: 0.3660\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.3804\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3765\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3443 - val_loss: 0.3813\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3326\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.3385\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3663 - val_loss: 0.3656\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3578\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3359\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3616 - val_loss: 0.3318\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3562\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3427 - val_loss: 0.3523\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.4585\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3811\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3539\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3725\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.3337\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.4006\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3264\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.3271\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3621 - val_loss: 0.3347\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3493\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3484 - val_loss: 0.3402\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3299 - val_loss: 0.3274\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.3297\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3364 - val_loss: 0.3307\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3558 - val_loss: 0.3252\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3372 - val_loss: 0.3242\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3254\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3656\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3381\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3261 - val_loss: 0.3272\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3409 - val_loss: 0.3241\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3654\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3286 - val_loss: 0.3286\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3391 - val_loss: 0.3241\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3293 - val_loss: 0.3378\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3372 - val_loss: 0.3364\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3364 - val_loss: 0.3224\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3607\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.3438\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3481 - val_loss: 0.3224\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.3336\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3240 - val_loss: 0.4148\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3287\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3264 - val_loss: 0.3407\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3482 - val_loss: 0.3789\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3310 - val_loss: 0.3233\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3283 - val_loss: 0.4185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11f5132ecc8>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, \n",
    "             validation_data=(X_valid, y_valid), \n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "reverse-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3378\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "apparent-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000011F6BD19558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-information",
   "metadata": {},
   "source": [
    "- Note that any extra parameter you pass to the fit() method will get passed to the underlying Keras model. \n",
    "    - Also note that the **score will be the opposite of the MSE because Scikit-Learn wants scores, not losses (i.e., higher should be better).**\n",
    "- We don’t want to train and evaluate a single model like this, though we want to train hundreds of variants and see which one performs best on the validation set. \n",
    "    - Since there are many hyperparameters, **it is preferable to use a randomized search** rather than grid search.\n",
    "\n",
    "- **Let’s try to explore the number of hidden layers, the number of neurons, and the learning rate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "herbal-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "yellow-tribune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458 .....\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 1.3827 - val_loss: 0.4703\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4880 - val_loss: 0.4247\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4541 - val_loss: 0.4052\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4518 - val_loss: 0.3975\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4337 - val_loss: 0.3991\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4263 - val_loss: 0.4031\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4385 - val_loss: 0.4043\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4301 - val_loss: 0.3929\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.4040\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4200 - val_loss: 0.3886\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4099 - val_loss: 0.3999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.4085\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4265 - val_loss: 0.3922\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.3918\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.3886\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4032 - val_loss: 0.3933\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4212 - val_loss: 0.3907\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.3955\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3935\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4146 - val_loss: 0.3891\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4251\n",
      "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458, total=  12.0s\n",
      "[CV] n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458 .....\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3852 - val_loss: 0.4860\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4722 - val_loss: 0.4280\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.5791\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4422 - val_loss: 0.4549\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4527 - val_loss: 0.5250\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.5486\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4246 - val_loss: 0.5871\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4382 - val_loss: 0.4759\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4299 - val_loss: 0.7523\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4390 - val_loss: 0.7478\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.8981\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4234 - val_loss: 0.8543\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4537\n",
      "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458, total=   7.3s\n",
      "[CV] n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 13.5522 - val_loss: 4.2492\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2460 - val_loss: 0.5794\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5520 - val_loss: 0.4357\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4507 - val_loss: 0.4169\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4365 - val_loss: 0.4135\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4283 - val_loss: 0.4206\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4100\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4636 - val_loss: 0.4155\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4411 - val_loss: 0.4111\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4840 - val_loss: 0.4076\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4626 - val_loss: 0.4062\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4326 - val_loss: 0.4078\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4226 - val_loss: 0.4160\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4260 - val_loss: 0.4158\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4551 - val_loss: 0.4137\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4552 - val_loss: 0.4069\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4343 - val_loss: 0.4119\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4453 - val_loss: 0.4149\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4530 - val_loss: 0.4081\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4502 - val_loss: 0.4141\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4473\n",
      "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458, total=  12.7s\n",
      "[CV] n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.7737 - val_loss: 6.2480\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5899 - val_loss: 5.2166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5147 - val_loss: 0.4474\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4477 - val_loss: 0.3901\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.3736\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.3803\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3701 - val_loss: 0.3813\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.3961\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3512 - val_loss: 0.3988\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3891\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3870\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3252 - val_loss: 0.3769\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3770\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3848\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3769\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3561\n",
      "[CV]  n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343, total=  10.6s\n",
      "[CV] n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.5396 - val_loss: 3.5738\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5129 - val_loss: 0.7767\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4283 - val_loss: 0.5515\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.5335\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3926 - val_loss: 0.5336\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.6750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.8462\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.8724\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.9645\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3560 - val_loss: 0.7225\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3517 - val_loss: 0.7257\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3367 - val_loss: 0.7217\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.8443\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3244 - val_loss: 0.7065\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3650\n",
      "[CV]  n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343, total=   9.8s\n",
      "[CV] n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7832 - val_loss: 2.9433\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5594 - val_loss: 4.2557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4797 - val_loss: 2.8526\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4774 - val_loss: 1.6798\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 0.4322\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.4172\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3719 - val_loss: 0.3769\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.3688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3652 - val_loss: 0.4032\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3587 - val_loss: 0.3418\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.4452\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.3454\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3258 - val_loss: 0.3395\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.4354\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.3386\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.4038\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3302\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3386 - val_loss: 0.3580\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.3545\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3459\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3245\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3256\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3435\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.3385\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3660\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3209 - val_loss: 0.3963\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3146\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3305 - val_loss: 0.3195\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3255 - val_loss: 0.4239\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3205 - val_loss: 0.3232\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3093 - val_loss: 0.3139\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3294 - val_loss: 0.4327\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3112\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3035 - val_loss: 0.4071\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.4369\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3007 - val_loss: 0.5954\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3117 - val_loss: 0.6059\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3293 - val_loss: 0.9648\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3218 - val_loss: 0.4027\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3110 - val_loss: 1.1111\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3287 - val_loss: 0.5600\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3030 - val_loss: 1.0534\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 1.1762\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3187\n",
      "[CV]  n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343, total=  26.7s\n",
      "[CV] n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.2328 - val_loss: 13.3699\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4156 - val_loss: 10.8972\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4953 - val_loss: 7.7330\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1092 - val_loss: 5.0744\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8935 - val_loss: 3.2363\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8194 - val_loss: 2.1597\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7802 - val_loss: 1.4840\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7285 - val_loss: 1.1083\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6921 - val_loss: 0.8942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6951 - val_loss: 0.7687\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6599 - val_loss: 0.6947\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6237 - val_loss: 0.6524\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6619 - val_loss: 0.6234\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6487 - val_loss: 0.6061\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6429 - val_loss: 0.5933\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6103 - val_loss: 0.5819\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6492 - val_loss: 0.5733\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6227 - val_loss: 0.5650\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6024 - val_loss: 0.5578\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5992 - val_loss: 0.5508\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5874 - val_loss: 0.5446\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5653 - val_loss: 0.5384\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5863 - val_loss: 0.5326\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5639 - val_loss: 0.5266\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5689 - val_loss: 0.5214\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5438 - val_loss: 0.5166\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5653 - val_loss: 0.5116\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5540 - val_loss: 0.5076\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5635 - val_loss: 0.5035\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5438 - val_loss: 0.4989\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.4946\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5238 - val_loss: 0.4915\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5159 - val_loss: 0.4883\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5200 - val_loss: 0.4856\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5080 - val_loss: 0.4828\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4939 - val_loss: 0.4789\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5136 - val_loss: 0.4780\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.4742\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5037 - val_loss: 0.4729\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4797 - val_loss: 0.4714\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4870 - val_loss: 0.4686\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5008 - val_loss: 0.4666\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4892 - val_loss: 0.4646\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4786 - val_loss: 0.4636\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4812 - val_loss: 0.4616\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4710 - val_loss: 0.4582\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4787 - val_loss: 0.4581\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4574 - val_loss: 0.4573\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4752 - val_loss: 0.4560\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4641 - val_loss: 0.4544\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4536 - val_loss: 0.4525\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4800 - val_loss: 0.4527\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4622 - val_loss: 0.4522\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4648 - val_loss: 0.4509\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4387 - val_loss: 0.4509\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4897 - val_loss: 0.4513\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4494 - val_loss: 0.4496\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4645 - val_loss: 0.4510\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4580 - val_loss: 0.4502\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4478\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4271 - val_loss: 0.4485\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4362 - val_loss: 0.4488\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4499 - val_loss: 0.4477\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4377 - val_loss: 0.4497\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 0.4512\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4718 - val_loss: 0.4484\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4375 - val_loss: 0.4483\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4390 - val_loss: 0.4494\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4460 - val_loss: 0.4492\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4546 - val_loss: 0.4476\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4346 - val_loss: 0.4481\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.4503\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4463 - val_loss: 0.4486\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4312 - val_loss: 0.4491\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4328 - val_loss: 0.4496\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4235 - val_loss: 0.4483\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.4474\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4187 - val_loss: 0.4490\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4158 - val_loss: 0.4495\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4270 - val_loss: 0.4468\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3977 - val_loss: 0.4492\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4071 - val_loss: 0.4525\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.4504\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4320 - val_loss: 0.4525\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4495\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.4548\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4512\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4150 - val_loss: 0.4481\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4045 - val_loss: 0.4472\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.4506\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4209\n",
      "[CV]  n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145, total=  51.4s\n",
      "[CV] n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 4.4546 - val_loss: 7.5238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7950 - val_loss: 8.6120\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1115 - val_loss: 8.4896\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 7.7423\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8253 - val_loss: 6.8202\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7837 - val_loss: 5.9344\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7711 - val_loss: 5.1492\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7292 - val_loss: 4.4548\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7279 - val_loss: 3.9122\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7055 - val_loss: 3.4233\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6956 - val_loss: 2.9997\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6640 - val_loss: 2.6082\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6539 - val_loss: 2.2766\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6447 - val_loss: 1.9984\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6831 - val_loss: 1.7447\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6364 - val_loss: 1.5300\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6425 - val_loss: 1.3410\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6340 - val_loss: 1.1762\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6140 - val_loss: 1.0345\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6101 - val_loss: 0.9174\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5938 - val_loss: 0.8153\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5975 - val_loss: 0.7363\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5956 - val_loss: 0.6696\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5714 - val_loss: 0.6187\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5535 - val_loss: 0.5778\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5553 - val_loss: 0.5491\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 0.5299\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5688 - val_loss: 0.5199\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5619 - val_loss: 0.5172\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5510 - val_loss: 0.5206\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5401 - val_loss: 0.5312\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5370 - val_loss: 0.5447\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5423 - val_loss: 0.5639\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5211 - val_loss: 0.5821\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5081 - val_loss: 0.6039\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 0.6306\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.6564\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4928 - val_loss: 0.6820\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5096 - val_loss: 0.7087\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5160\n",
      "[CV]  n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145, total=  25.2s\n",
      "[CV] n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.8993 - val_loss: 7.4460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4173 - val_loss: 5.2071\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4701 - val_loss: 2.9554\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1716 - val_loss: 1.7752\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 1.1201\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8307 - val_loss: 0.8519\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7780 - val_loss: 0.7512\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7632 - val_loss: 0.7064\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7361 - val_loss: 0.6896\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6859 - val_loss: 0.6760\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7064 - val_loss: 0.6687\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6826 - val_loss: 0.6577\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6416 - val_loss: 0.6454\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6539 - val_loss: 0.6355\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6736 - val_loss: 0.6256\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6529 - val_loss: 0.6213\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 0.6120\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6484 - val_loss: 0.6024\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.5998\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.5901\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5912 - val_loss: 0.5822\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.5763\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5804 - val_loss: 0.5664\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5735 - val_loss: 0.5574\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5793 - val_loss: 0.5527\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5576 - val_loss: 0.5452\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5786 - val_loss: 0.5437\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - val_loss: 0.5366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5475 - val_loss: 0.5322\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5471 - val_loss: 0.5264\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5281 - val_loss: 0.5234\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5547 - val_loss: 0.5175\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5437 - val_loss: 0.5137\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5113 - val_loss: 0.5078\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5125 - val_loss: 0.5045\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5127 - val_loss: 0.4970\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5158 - val_loss: 0.4911\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5132 - val_loss: 0.4887\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.4847\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4995 - val_loss: 0.4815\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4795 - val_loss: 0.4776\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4838 - val_loss: 0.4736\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4966 - val_loss: 0.4706\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.4673\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4810 - val_loss: 0.4655\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4737 - val_loss: 0.4625\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4866 - val_loss: 0.4576\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4719 - val_loss: 0.4554\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4859 - val_loss: 0.4525\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4618 - val_loss: 0.4495\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4862 - val_loss: 0.4468\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4576 - val_loss: 0.4446\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4641 - val_loss: 0.4420\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4641 - val_loss: 0.4394\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4560 - val_loss: 0.4373\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4620 - val_loss: 0.4349\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4542 - val_loss: 0.4330\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4659 - val_loss: 0.4311\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4584 - val_loss: 0.4291\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4684 - val_loss: 0.4277\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4678 - val_loss: 0.4257\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.4241\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4224\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.4208\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.4193\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.4180\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.4151\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.4141\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.4124\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.4112\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.4101\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4088\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.4081\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 0.4073\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4070\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4056\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.4040\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4034\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.4033\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.4019\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.4008\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4002\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4320 - val_loss: 0.3996\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.3983\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4110 - val_loss: 0.3980\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.3981\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.3969\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.3978\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.3961\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.3951\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.3938\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.3938\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.3935\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.3934\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.3932\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.3939\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.3913\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 0.3916\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4052 - val_loss: 0.3918\n",
      "121/121 [==============================] - 0s 956us/step - loss: 0.4139\n",
      "[CV]  n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145, total=  51.6s\n",
      "[CV] n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.4453 - val_loss: 1.3536\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7645 - val_loss: 0.7463\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6590 - val_loss: 0.5899\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.5366\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5580 - val_loss: 0.5063\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5150 - val_loss: 0.4813\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.4639\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.4427\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4477 - val_loss: 0.4393\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.4137\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4204 - val_loss: 0.4071\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.3983\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.3933\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.3972\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4041 - val_loss: 0.3852\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.3830\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.3947\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.3713\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3829 - val_loss: 0.3752\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.3741\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3800 - val_loss: 0.3782\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3686 - val_loss: 0.3637\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.3723\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3707\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.4047\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3839\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.4167\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3500\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3666 - val_loss: 0.3792\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3629 - val_loss: 0.3636\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3586 - val_loss: 0.3476\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3566\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3517 - val_loss: 0.3611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3521 - val_loss: 0.3414\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.3474\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.3944\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.4402\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.4722\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.3722\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.4019\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3408 - val_loss: 0.3376\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3377\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.3354\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3430 - val_loss: 0.3737\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3563\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 0.3546\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3262 - val_loss: 0.3399\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.3304\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3849\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3431\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3495 - val_loss: 0.3362\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3387\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.3294\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3260 - val_loss: 0.3656\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.3310\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.3728\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.3375\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3402\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3199 - val_loss: 0.3441\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3275 - val_loss: 0.3582\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.3304\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3222 - val_loss: 0.3680\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3294\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3275\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3555\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3300\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.3449\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3550\n",
      "[CV]  n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363, total=  34.6s\n",
      "[CV] n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.2276 - val_loss: 3.4090\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7673 - val_loss: 1.6754\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6369 - val_loss: 0.9319\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6042\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 0.5061\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.5058\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4977 - val_loss: 0.5272\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5600\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.5367\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.5220\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4878\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.4531\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4182\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.3877\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.3818\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4023\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4348\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.4935\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3895 - val_loss: 0.5341\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.5982\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.6541\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.7245\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.8047\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.8588\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.9091\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3885\n",
      "[CV]  n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363, total=  12.4s\n",
      "[CV] n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.3058 - val_loss: 2.1643\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7651 - val_loss: 0.6141\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.5601\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5596 - val_loss: 0.5241\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.5017\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.4749\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.4558\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.4297\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4463 - val_loss: 0.4464\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.4189\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 0.4438\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.4250\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4009\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.4403\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.4014\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3992 - val_loss: 0.4247\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.3964\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.3974\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4229\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.4053\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3989\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3974 - val_loss: 0.3957\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3864\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.4022\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3729\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3645\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4107\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.3925\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4265\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3879\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.3789\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.4080\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3873\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.4232\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3550 - val_loss: 0.3718\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3663\n",
      "121/121 [==============================] - 0s 996us/step - loss: 0.3555\n",
      "[CV]  n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363, total=  17.3s\n",
      "[CV] n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9995 - val_loss: 297.3653\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2481 - val_loss: 539.0366\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.5441 - val_loss: 3736.4517\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7.4651 - val_loss: 12227.6943\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 22.4715 - val_loss: 61529.0664\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2537.2814 - val_loss: 268363.5000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2132.8530 - val_loss: 1210516.7500\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 32696.8215 - val_loss: 5411000.5000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 28036.2789 - val_loss: 24506660.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 910064.7031 - val_loss: 119812760.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1721894.2076 - val_loss: 529729824.0000\n",
      "121/121 [==============================] - 0s 948us/step - loss: 1402362.2500\n",
      "[CV]  n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035, total=   5.5s\n",
      "[CV] n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2323 - val_loss: 15.8284\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 22.4892\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 24.7894\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 22.4864\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5095 - val_loss: 21.9009\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 21.2895\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 19.9064\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 22.5013\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 20.0987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 10.7128\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 19.7319\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 24.3237\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 25.9485\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 10.5277\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 17.1916\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 21.8346\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 11.7743\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 14.1555\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 20.9814\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 12.3621\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 25.9146\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 16.0461\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5148 - val_loss: 19.4877\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 12.1054\n",
      "121/121 [==============================] - 0s 924us/step - loss: 0.7813\n",
      "[CV]  n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035, total=  10.5s\n",
      "[CV] n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9669 - val_loss: 307.7497\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0908 - val_loss: 76.3016\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8437 - val_loss: 795.2293\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 41.8219 - val_loss: 704.0454\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0379 - val_loss: 2668.0293\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6.1716 - val_loss: 1446.2605\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.3018 - val_loss: 1540.5377\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 71.5700 - val_loss: 1396.7118\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6.0212 - val_loss: 1334.0856\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.0299 - val_loss: 216.7273\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 21.3465 - val_loss: 125.2068\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7510 - val_loss: 2.2902\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 790.5425\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.4409 - val_loss: 468.7426\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0499 - val_loss: 1073.9148\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 45.2524 - val_loss: 865.6384\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7760 - val_loss: 1128.1508\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7236 - val_loss: 499.5194\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 34.6840 - val_loss: 309.7943\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3475 - val_loss: 354.6346\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4646 - val_loss: 559.4492\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.0812 - val_loss: 393.8701\n",
      "121/121 [==============================] - 0s 969us/step - loss: 0.6226\n",
      "[CV]  n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035, total=   9.8s\n",
      "[CV] n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331 ......\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.9862 - val_loss: 1.4543\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6404 - val_loss: 0.9557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5532 - val_loss: 0.4628\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.4214\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.3984\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.4056\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.3741\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.3926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3832\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3929\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3570\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3790\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3840\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3560 - val_loss: 0.3950\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3751\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3955\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3559 - val_loss: 0.3900\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3621 - val_loss: 0.3905\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3365 - val_loss: 0.3944\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.3811\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.3906\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3624\n",
      "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331, total=  10.8s\n",
      "[CV] n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331 ......\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7235 - val_loss: 0.5822\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5852 - val_loss: 0.4873\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.4420\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4139\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 0.4132\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.4464\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.4717\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.5331\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.6951\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.6944\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3646 - val_loss: 0.8506\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.7660\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3419 - val_loss: 0.8731\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3305 - val_loss: 0.9306\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3605 - val_loss: 0.9345\n",
      "121/121 [==============================] - 0s 980us/step - loss: 0.3685\n",
      "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331, total=   7.8s\n",
      "[CV] n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331 ......\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7434 - val_loss: 0.6796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5868 - val_loss: 0.4957\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5017 - val_loss: 0.4633\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.4565\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.4150\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.4331\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.3887\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.3785\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4233\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.3652\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4336\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3635 - val_loss: 0.3763\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3632\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.4460\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3555\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3554 - val_loss: 0.3947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.3623\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.3774\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3807\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.3420\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3427 - val_loss: 0.3452\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3273\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3386 - val_loss: 0.3279\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3312 - val_loss: 0.4346\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3432\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3227\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.4466\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3323\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.3991\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3434\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3188 - val_loss: 0.3349\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3639\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.3461\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3591\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3142 - val_loss: 0.3140\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3092 - val_loss: 0.3636\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3214 - val_loss: 0.3380\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3190 - val_loss: 0.5245\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3297 - val_loss: 0.3326\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.4047\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3022 - val_loss: 0.3339\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3030 - val_loss: 0.3659\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3221 - val_loss: 0.3318\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3244 - val_loss: 0.3677\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3087\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3076 - val_loss: 0.3860\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3173\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3052 - val_loss: 0.3008\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3110 - val_loss: 0.4150\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3004\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3178 - val_loss: 0.4005\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3023 - val_loss: 0.3069\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3063 - val_loss: 0.3191\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3022 - val_loss: 0.3023\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2998 - val_loss: 0.3037\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.3540\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3104\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3081 - val_loss: 0.2976\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3028\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3073 - val_loss: 0.3555\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3134 - val_loss: 0.3575\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.2913\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3077\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.3016\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.3743\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2894 - val_loss: 0.3472\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2995 - val_loss: 0.3130\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3273\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.2918\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2914 - val_loss: 0.3171\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.2936\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2808 - val_loss: 0.2926\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3060\n",
      "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331, total=  33.9s\n",
      "[CV] n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.4800 - val_loss: 29.5063\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8491 - val_loss: 33.7785\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8416 - val_loss: 4.0125\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.5556\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5755 - val_loss: 0.5119\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.4888\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.4729\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4973 - val_loss: 0.4559\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.4601\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.4303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.4205\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.4242\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4107\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4231\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.4221\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.4084\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.4209\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.4017\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4322\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.4001\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4041 - val_loss: 0.4263\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.4032\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.4039\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.3764\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.4241\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3779\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4126\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.3967\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4045\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3748\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3717\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3676\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4054\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.3924\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.3611\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4182\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.3539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4403\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.3551\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 0.4125\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3665\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.3591\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.3570\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.4125\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3743 - val_loss: 0.3547\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3585 - val_loss: 0.3779\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3886\n",
      "121/121 [==============================] - 0s 966us/step - loss: 0.3877\n",
      "[CV]  n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545, total=  21.8s\n",
      "[CV] n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.3075 - val_loss: 0.7805\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7479 - val_loss: 1.1550\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 1.8115\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5885 - val_loss: 2.6113\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 3.2626\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 3.5247\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 3.5926\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 3.5562\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 2.9541\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 2.5606\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4424 - val_loss: 2.1560\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4866\n",
      "[CV]  n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545, total=   5.9s\n",
      "[CV] n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9276 - val_loss: 2.5834\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7344 - val_loss: 3.5564\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6461 - val_loss: 1.7895\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 1.7436\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.6344\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 0.8713\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 0.5604\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5012 - val_loss: 0.4695\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.4942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.4375\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.4536\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.4276\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.4084\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4219 - val_loss: 0.4897\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4018\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.5505\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 0.4602\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4347\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.3835\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.4115\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4025 - val_loss: 0.3817\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.3737\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4011 - val_loss: 0.3720\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4318\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.4158\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 0.3821\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4040 - val_loss: 0.4069\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.4024\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.5904\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4027\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.4216\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.3603\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4134\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3633\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3542\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3568\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.4216\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.5522\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.5648\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3818 - val_loss: 0.6416\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3847\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3616 - val_loss: 0.5255\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.7023\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.7508\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.5608\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3745\n",
      "[CV]  n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545, total=  21.2s\n",
      "[CV] n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6933 - val_loss: 6.4183\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6124 - val_loss: 16.7917\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5548 - val_loss: 4.7823\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4575 - val_loss: 8.6077\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 1.8033\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4075 - val_loss: 0.3655\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3664 - val_loss: 0.3784\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.4055\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3909\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.3910\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3554\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3169 - val_loss: 0.3611\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3652\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3630\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3563\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3238 - val_loss: 0.3563\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.3557\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3388 - val_loss: 0.3493\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3133 - val_loss: 0.3542\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3205 - val_loss: 0.3409\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3155 - val_loss: 0.3366\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3060 - val_loss: 0.3572\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3151 - val_loss: 0.3323\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3082 - val_loss: 0.3080\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3104 - val_loss: 0.3479\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2952 - val_loss: 0.3066\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3113 - val_loss: 0.3281\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3055 - val_loss: 0.3460\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2990 - val_loss: 0.3291\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2987 - val_loss: 0.2959\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2951 - val_loss: 0.3074\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2848 - val_loss: 0.2926\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2895 - val_loss: 0.3199\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.3186\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2853 - val_loss: 0.2909\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2862 - val_loss: 0.3584\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2760 - val_loss: 0.2999\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2921 - val_loss: 0.3454\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2784 - val_loss: 0.2914\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2663 - val_loss: 0.3375\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2757 - val_loss: 0.2931\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2764 - val_loss: 0.2864\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2781 - val_loss: 0.2902\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2744 - val_loss: 0.3099\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.3065\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2667 - val_loss: 0.3301\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2681 - val_loss: 0.2939\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2658 - val_loss: 0.2881\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2787 - val_loss: 0.2900\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2650 - val_loss: 0.3446\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2591 - val_loss: 0.3227\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2768 - val_loss: 0.3172\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3151\n",
      "[CV]  n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024, total=  29.2s\n",
      "[CV] n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4417 - val_loss: 0.7368\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5298 - val_loss: 0.4429\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4285 - val_loss: 0.3919\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4018 - val_loss: 0.3836\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3836 - val_loss: 0.3940\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.4655\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.6429\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3530 - val_loss: 0.7346\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3418 - val_loss: 0.9168\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.7004\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.7045\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.7750\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3186 - val_loss: 0.8549\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3124 - val_loss: 0.8272\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3523\n",
      "[CV]  n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024, total=   8.1s\n",
      "[CV] n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6879 - val_loss: 0.9196\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4943 - val_loss: 2.1025\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4287 - val_loss: 3.5511\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4621 - val_loss: 1.5867\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3738 - val_loss: 0.4227\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3738\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.3350\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.3384\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3477 - val_loss: 0.3720\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3506 - val_loss: 0.3274\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3651 - val_loss: 0.3955\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3326\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3092 - val_loss: 0.3226\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.3679\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.3193\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3522\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3125 - val_loss: 0.3211\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3226 - val_loss: 0.3546\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3344 - val_loss: 0.3427\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3573\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3150 - val_loss: 0.3203\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3264 - val_loss: 0.3244\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.3785\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3029 - val_loss: 0.3022\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.3118\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2994 - val_loss: 0.3203\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3137 - val_loss: 0.3236\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3598\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3155 - val_loss: 0.4574\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.2992\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2896 - val_loss: 0.3241\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3079 - val_loss: 0.3060\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2980 - val_loss: 0.3306\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2850 - val_loss: 0.3083\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2835 - val_loss: 0.2935\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2785 - val_loss: 0.4065\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2902 - val_loss: 0.3340\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2937 - val_loss: 0.3678\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3006 - val_loss: 0.2961\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2852 - val_loss: 0.3428\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2697 - val_loss: 0.3101\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2794 - val_loss: 0.3111\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2929 - val_loss: 0.2830\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2923 - val_loss: 0.3288\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2745 - val_loss: 0.3003\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2764 - val_loss: 0.3239\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2773 - val_loss: 0.2820\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2723 - val_loss: 0.2856\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2821 - val_loss: 0.3628\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2805 - val_loss: 0.2932\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2822 - val_loss: 0.3403\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2689 - val_loss: 0.2952\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2787 - val_loss: 0.2931\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2744 - val_loss: 0.2959\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2666 - val_loss: 0.2803\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2762 - val_loss: 0.3103\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2723 - val_loss: 0.3365\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2793 - val_loss: 0.2911\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2756 - val_loss: 0.3142\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2751 - val_loss: 0.2778\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2769 - val_loss: 0.3371\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2678 - val_loss: 0.2751\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2640 - val_loss: 0.3406\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2788 - val_loss: 0.2831\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2640 - val_loss: 0.3107\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2558 - val_loss: 0.2859\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2684 - val_loss: 0.2867\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2750 - val_loss: 0.2972\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2600 - val_loss: 0.2819\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2585 - val_loss: 0.3031\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2736 - val_loss: 0.2742\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2502 - val_loss: 0.2758\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2656 - val_loss: 0.2900\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2631 - val_loss: 0.2802\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2613 - val_loss: 0.2968\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2555 - val_loss: 0.3260\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2738 - val_loss: 0.2791\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2638 - val_loss: 0.3509\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2611 - val_loss: 0.2775\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2573 - val_loss: 0.2719\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2463 - val_loss: 0.2912\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2482 - val_loss: 0.2806\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2523 - val_loss: 0.3181\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2650 - val_loss: 0.2746\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2572 - val_loss: 0.2891\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2497 - val_loss: 0.2818\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2574 - val_loss: 0.3160\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2448 - val_loss: 0.2708\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2591 - val_loss: 0.2884\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2497 - val_loss: 0.2924\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2658 - val_loss: 0.2815\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2519 - val_loss: 0.2710\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2476 - val_loss: 0.3213\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2585 - val_loss: 0.2719\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2582 - val_loss: 0.3196\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2460 - val_loss: 0.2965\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2470 - val_loss: 0.2814\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2454 - val_loss: 0.2941\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2865\n",
      "[CV]  n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024, total=  50.8s\n",
      "[CV] n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.5786 - val_loss: 10.9250\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5353 - val_loss: 3.3912\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4521 - val_loss: 0.4039\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4084 - val_loss: 0.3693\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3670 - val_loss: 0.3554\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3874\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.3635\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3985\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3333 - val_loss: 0.3793\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3706\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3208 - val_loss: 0.3313\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3109 - val_loss: 0.3509\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3795\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3224 - val_loss: 0.3319\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3174 - val_loss: 0.3484\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3483\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3260 - val_loss: 0.3254\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3304 - val_loss: 0.3426\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3066 - val_loss: 0.3363\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3129 - val_loss: 0.3213\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3087 - val_loss: 0.3825\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3029 - val_loss: 0.3093\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3063 - val_loss: 0.3637\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3614\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3097 - val_loss: 0.3272\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.3066\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3084 - val_loss: 0.3323\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2998 - val_loss: 0.3399\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2929 - val_loss: 0.3575\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2949 - val_loss: 0.3344\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2955 - val_loss: 0.3104\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2826 - val_loss: 0.2869\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2858 - val_loss: 0.3228\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2809 - val_loss: 0.3021\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2806 - val_loss: 0.2952\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2821 - val_loss: 0.3609\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2731 - val_loss: 0.4446\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3001 - val_loss: 0.3627\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2803 - val_loss: 0.3028\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2644 - val_loss: 0.3271\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2774 - val_loss: 0.3042\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2775 - val_loss: 0.3021\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3163\n",
      "[CV]  n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885, total=  23.9s\n",
      "[CV] n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5488 - val_loss: 0.6551\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4745 - val_loss: 0.4129\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.6097\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3959 - val_loss: 0.6571\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3826 - val_loss: 0.6378\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3631 - val_loss: 0.8581\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 1.0643\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3562 - val_loss: 1.1255\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 1.2214\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3463 - val_loss: 0.7989\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.8265\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3264 - val_loss: 0.7604\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3593\n",
      "[CV]  n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885, total=   7.0s\n",
      "[CV] n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4295 - val_loss: 2.2007\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5148 - val_loss: 3.3028\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4423 - val_loss: 0.9130\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4027 - val_loss: 0.5328\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 0.3609\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.4151\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.3580\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.3516\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3488 - val_loss: 0.3983\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3323\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3567 - val_loss: 0.4228\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.3283\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3110 - val_loss: 0.3463\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3199 - val_loss: 0.4040\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3270\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3264 - val_loss: 0.3791\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3131 - val_loss: 0.3214\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3198 - val_loss: 0.3288\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.3903\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3249 - val_loss: 0.3257\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3153 - val_loss: 0.3925\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3276 - val_loss: 0.3142\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3095 - val_loss: 0.3457\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3215\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3091\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3103\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3127 - val_loss: 0.3981\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3127 - val_loss: 0.3312\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3630\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2998 - val_loss: 0.3683\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2888 - val_loss: 0.2977\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 0.3694\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2970 - val_loss: 0.3591\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2873 - val_loss: 0.3011\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2845 - val_loss: 0.3172\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.3463\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2894 - val_loss: 0.3851\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2960 - val_loss: 0.4378\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.2923\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2854 - val_loss: 0.3362\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2702 - val_loss: 0.3379\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2764 - val_loss: 0.3390\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2911 - val_loss: 0.2885\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2928 - val_loss: 0.3244\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2768 - val_loss: 0.2990\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2753 - val_loss: 0.3453\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2767 - val_loss: 0.2860\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2715 - val_loss: 0.2989\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2769 - val_loss: 0.4632\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2778 - val_loss: 0.3121\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2824 - val_loss: 0.5314\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2668 - val_loss: 0.3149\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2750 - val_loss: 0.3113\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2717 - val_loss: 0.3496\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2658 - val_loss: 0.2869\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2727 - val_loss: 0.4470\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2696 - val_loss: 0.3097\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2928\n",
      "[CV]  n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885, total=  29.4s\n",
      "[CV] n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.1527 - val_loss: 0.5753\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5713 - val_loss: 8.9878\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 11.0986\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 1.1306\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 0.5256\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 0.4498\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4056\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.3999\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3957\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3904\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3540 - val_loss: 0.3688\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.3651\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 0.3709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3816\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3620\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3670\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.3671\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.3605\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3552\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3444 - val_loss: 0.3538\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.3520\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3477\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3509\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.3304\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.3683\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3262 - val_loss: 0.3246\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3389\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.3366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3387\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3212\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3219\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.3151\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3229 - val_loss: 0.3458\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3197 - val_loss: 0.3163\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3166 - val_loss: 0.3140\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3178 - val_loss: 0.3897\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.3819\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3264 - val_loss: 0.3408\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3117 - val_loss: 0.3145\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3380\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3159\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.3136\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.3109\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3092 - val_loss: 0.3381\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3166 - val_loss: 0.3052\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3267\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3051 - val_loss: 0.3288\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2948 - val_loss: 0.3231\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3180 - val_loss: 0.3022\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.3631\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2901 - val_loss: 0.3299\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3165 - val_loss: 0.3159\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2995 - val_loss: 0.3144\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2969 - val_loss: 0.3048\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2973 - val_loss: 0.3649\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.3003\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3058 - val_loss: 0.3706\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3215\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3066 - val_loss: 0.3029\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 0.3241\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2892 - val_loss: 0.3549\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2931 - val_loss: 0.3470\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3365\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2896 - val_loss: 0.3587\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2805 - val_loss: 0.3023\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3092 - val_loss: 0.3047\n",
      "121/121 [==============================] - 0s 997us/step - loss: 0.3341\n",
      "[CV]  n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438, total=  30.9s\n",
      "[CV] n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2993 - val_loss: 0.8898\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5586 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.4844\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 0.4250\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.3735\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.3859\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.4576\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.4926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 0.6246\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.5262\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.5952\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3472 - val_loss: 0.6355\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.7437\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.7102\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.6823\n",
      "121/121 [==============================] - 0s 986us/step - loss: 0.3613\n",
      "[CV]  n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438, total=   7.6s\n",
      "[CV] n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.1229 - val_loss: 2.8528\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 2.3412\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5163 - val_loss: 0.9015\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.8313\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.5217\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.4956\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3878 - val_loss: 0.3745\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4012\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4169\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.3843\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.6122\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.3579\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.3497\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.5161\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4273\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.5739\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3435 - val_loss: 0.4975\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 0.4886\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3371\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3536 - val_loss: 0.4118\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.3311\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3579 - val_loss: 0.3289\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3287\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3355 - val_loss: 0.5230\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.7683\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3355 - val_loss: 0.8921\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.4875\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.6193\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.3481\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.5801\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3229 - val_loss: 0.3675\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3461 - val_loss: 1.0207\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.6377\n",
      "121/121 [==============================] - 0s 983us/step - loss: 0.3366\n",
      "[CV]  n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438, total=  15.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4030 - val_loss: 1.8036\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5715 - val_loss: 2.0827\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.3796\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4007 - val_loss: 0.4283\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.3617\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.4566\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3732 - val_loss: 0.3573\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3580 - val_loss: 0.3380\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3458 - val_loss: 0.3757\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3433 - val_loss: 0.4069\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3312 - val_loss: 0.5469\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3457 - val_loss: 0.6487\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3108\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3259 - val_loss: 0.3198\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3223 - val_loss: 0.3064\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3277 - val_loss: 0.3231\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3095 - val_loss: 0.4048\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3108 - val_loss: 0.2984\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3062 - val_loss: 0.3147\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3004 - val_loss: 0.4279\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3085 - val_loss: 0.3251\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2947 - val_loss: 0.5099\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3122 - val_loss: 0.5561\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3028 - val_loss: 0.5783\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2995 - val_loss: 0.3097\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2990 - val_loss: 0.5740\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2999 - val_loss: 0.6429\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3057 - val_loss: 0.5299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000011F50F16F88>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3], \n",
    "    \"n_neurons\": np.arange(1, 100).tolist(), \n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, \n",
    "                 validation_data=(X_valid, y_valid), \n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-injection",
   "metadata": {},
   "source": [
    "#### Note that RandomizedSearchCV uses K-fold crossvalidation, so it does not use X_valid and y_valid, which are only used for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "portable-vertical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 74, 'n_hidden': 3, 'learning_rate': 0.005803602934201024}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "regional-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3179815113544464"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "optimum-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x11f5116e488>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "acknowledged-supervisor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3029102087020874"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "broad-mitchell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x11f51241588>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "addressed-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3029102087020874"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-scheme",
   "metadata": {},
   "source": [
    "- You can now save this model, evaluate it on the test set, and, if you are satisfied with its performance, deploy it to production. \n",
    "- Using randomized search is not too hard, and it works well for many fairly simple problems.\n",
    "- When training is slow, however (e.g., for more complex problems with larger datasets), this approach will only explore a tiny portion of the hyperparameter space. \n",
    "    - You can partially alleviate this problem by assisting the search process manually: **first run a quick random search using wide ranges of hyperparameter values, then run another search using smaller ranges of values centered on the best ones found during the first run, and so on.** \n",
    "    - This approach will hopefully zoom in on a good set of hyperparameters.\n",
    "    - However, it’s very time consuming, and probably not the best use of your time.\n",
    "- Fortunately, there are many techniques to explore a search space much more efficiently than randomly. \n",
    "    - Their core idea is simple: when a region of the space turns out to be good, it should be explored more. \n",
    "    - Such techniques take care of the “zooming” process for you and lead to much better solutions in much less time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-transcript",
   "metadata": {},
   "source": [
    "## Exercise 10.\n",
    "\n",
    "Exercise: Train a deep MLP on the MNIST dataset (you can load it using keras.datasets.mnist.load_data(). See if you can get over 98% precision. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Try adding all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard.\n",
    "\n",
    "Let's load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "possible-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 9s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-organizer",
   "metadata": {},
   "source": [
    "Just like for the Fashion MNIST dataset, the MNIST training set contains 60,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "parental-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-thumb",
   "metadata": {},
   "source": [
    "Each pixel intensity is also represented as a byte (0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "sticky-period",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-mauritius",
   "metadata": {},
   "source": [
    "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255, just like we did for Fashion MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "reserved-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-spider",
   "metadata": {},
   "source": [
    "Let's plot an image using Matplotlib's imshow() function, with a 'binary' color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fluid-ballot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-catalog",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9. Conveniently, the class IDs correspond to the digits represented in the images, so we don't need a class_names array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "generous-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "adopted-beginning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "noble-verse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "impressive-monaco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-engineer",
   "metadata": {},
   "source": [
    "Let's take a look at a sample of the images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dress-aaron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(y_train[index], fontsize=12)\n",
    "        \n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-dubai",
   "metadata": {},
   "source": [
    "Let's build a simple dense network and find the optimal learning rate. We will need a callback to grow the learning rate at each iteration. It will also record the learning rate and the loss at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "enabling-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "informational-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "perfect-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-resource",
   "metadata": {},
   "source": [
    "We will start with a small learning rate of 1e-3, and grow it by 0.5% at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "loving-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "             optimizer=keras.optimizers.SGD(lr=1e-3), \n",
    "             metrics=[\"accuracy\"])\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-dispatch",
   "metadata": {},
   "source": [
    "Now let's train the model for just 1 epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "authentic-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 9s 5ms/step - loss: 2.8410 - accuracy: 0.4894 - val_loss: 2.3944 - val_accuracy: 0.1126\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1, \n",
    "                   validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-blair",
   "metadata": {},
   "source": [
    "We can now plot the loss as a function of the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "placed-daisy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-loading",
   "metadata": {},
   "source": [
    "The loss starts shooting back up violently when the learning rate goes over 6e-1, so let's try using half of that, at 3e-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "exposed-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "assigned-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "peaceful-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=3e-1),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "material-architecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_mnist_logs\\\\run_001'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 1 # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "confident-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4200 - accuracy: 0.8678 - val_loss: 0.1022 - val_accuracy: 0.9696\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0939 - accuracy: 0.9700 - val_loss: 0.0928 - val_accuracy: 0.9720\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0672 - accuracy: 0.9779 - val_loss: 0.0817 - val_accuracy: 0.9768\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.0808 - val_accuracy: 0.9770\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0370 - accuracy: 0.9876 - val_loss: 0.0911 - val_accuracy: 0.9746\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0299 - accuracy: 0.9907 - val_loss: 0.0809 - val_accuracy: 0.9802\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0710 - val_accuracy: 0.9832\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0887 - val_accuracy: 0.9800\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0905 - val_accuracy: 0.9812\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0809 - val_accuracy: 0.9830\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0935 - val_accuracy: 0.9822\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.1243 - val_accuracy: 0.9766\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.1044 - val_accuracy: 0.9814\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0800 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0818 - val_accuracy: 0.9844\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 5.4068e-04 - accuracy: 0.9999 - val_loss: 0.0812 - val_accuracy: 0.9850\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 4.7789e-04 - accuracy: 0.9999 - val_loss: 0.0828 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.3055e-04 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9852\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 8.8521e-05 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9862\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 7.0908e-05 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9864\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 6.1527e-05 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9866\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 5.5448e-05 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9860\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 5.0383e-05 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9862\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.4566e-05 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9860\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.2104e-05 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9862\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6303e-05 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9860\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.3913e-05 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                   validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "rational-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07211431115865707, 0.9818000197410583]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-portable",
   "metadata": {},
   "source": [
    "We got over 98% accuracy. Finally, let's look at the learning curves using TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "solar-catch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10472), started 0:07:43 ago. (Use '!kill 10472' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-187cbb63cdc57d86\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-187cbb63cdc57d86\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_mnist_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-birmingham",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
